{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 合并与分割\n",
    "tf.concat +     合并：要求除了拼接以外所有维度相等\n",
    "tf.split -      分裂：\n",
    "\n",
    "tf.stack +      堆：要求所有维度相等\n",
    "tf.unstack -    不堆叠："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 8)\n",
      "(4, 35, 8)\n",
      "(4, 35, 16)\n",
      "(2, 4, 35, 8)\n",
      "(4, 35, 8, 2)\n",
      "(4, 2, 35, 8)\n",
      "(4, 35, 8) (4, 35, 8)\n",
      "(4, 2, 35) 8\n",
      "(4, 2, 35, 4) 2\n",
      "(4, 2, 35, 2) (4, 2, 35, 2) (4, 2, 35, 4)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([4,35,8])\n",
    "b = tf.ones([2,35,8])\n",
    "c = tf.concat([a,b],axis=0)\n",
    "print(c.shape) # (6,35,8)\n",
    "\n",
    "a1 = tf.ones([4,32,8])\n",
    "b1 = tf.ones([4,3,8])\n",
    "c1 = tf.concat([a1,b1],axis=1)\n",
    "print(c1.shape) #(4,35,8)\n",
    "\n",
    "\n",
    "a2 = tf.ones([4,35,8])\n",
    "b2 = tf.ones([4,35,8])\n",
    "c2 = tf.concat([a2,b2],axis=-1)\n",
    "print(c2.shape) #(4,35,16)\n",
    "d2 = tf.stack([a2,b2],axis=0)\n",
    "print(d2.shape) #(2,4,35,8)\n",
    "d3 = tf.stack([a2,b2],axis=3)\n",
    "print(d3.shape) #(4,35,8,2)\n",
    "d4 = tf.stack([a2,b2],axis=1)\n",
    "print(d4.shape) #(4,2,35,8)\n",
    "\n",
    "aa,bb = tf.unstack(d4,axis=1)\n",
    "print(aa.shape,bb.shape) #(4,35,8) (4,35,8)\n",
    "\n",
    "# 拆分出了8个  (4, 2, 35)\n",
    "res = tf.unstack(d4,axis=3)\n",
    "print(res[0].shape,len(res)) # (4, 2, 35) 8\n",
    "\n",
    "res2 = tf.split(d4,axis=3,num_or_size_splits=2)\n",
    "print(res2[0].shape,len(res2)) # (4, 2, 35,4) 2\n",
    "\n",
    "res3 = tf.split(d4,axis=3,num_or_size_splits=[2,2,4])\n",
    "print(res3[0].shape,res3[1].shape,res3[2].shape) # (4, 2, 35,2) (4, 2, 35,2) (4, 2, 35,4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据统计\n",
    "tf.norm  范数\n",
    "\n",
    "tf.reduce_min/max  最大最小\n",
    "\n",
    "tf.argmax/argmin 最大最小的index\n",
    "\n",
    "tf.equal\n",
    "tf.unique 去重"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,2])\n",
    "print(tf.norm(a)) # 2 元素平方的和开根号\n",
    "print(tf.sqrt(tf.reduce_sum(tf.square(a)))) # 2 同上"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.4142135 1.4142135], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,2])\n",
    "print(tf.norm(a,ord=2,axis=1)) # 对某一维度求范数\n",
    "# ord=2 是2范数：平方和开根号(默认)\n",
    "# ord=1,1范数：绝对值求和\n",
    "\n",
    "print(tf.norm(a,ord=1))  # 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-3.097243, shape=(), dtype=float32) tf.Tensor(1.3584898, shape=(), dtype=float32) tf.Tensor(-0.47285947, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[-1.4835898  -2.1389592  -1.179907   -3.097243   -2.0984085  -0.85453296\n",
      " -1.4654832  -1.3538884  -1.1631044  -1.9023842 ], shape=(10,), dtype=float32)\n",
      "tf.Tensor([-1.179907  -2.0984085 -3.097243  -1.9023842], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal([4,10])\n",
    "print(tf.reduce_min(a),tf.reduce_max(a),tf.reduce_mean(a))\n",
    "print(tf.reduce_min(a,axis=0))\n",
    "print(tf.reduce_min(a,axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 0 3 3 3 1 1 2 2 2], shape=(10,), dtype=int64)\n",
      "tf.Tensor([1 6 0 3], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal([4,10])\n",
    "print(tf.argmax(a))\n",
    "print(tf.argmax(a,axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32) tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor([False False False False False], shape=(5,), dtype=bool)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2,3,4,5])\n",
    "b = tf.range(5)\n",
    "print(a,b)\n",
    "\n",
    "res = tf.equal(a,b)\n",
    "print(res)\n",
    "print(tf.reduce_sum(tf.cast(res,dtype=tf.int32)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 0], shape=(2,), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0.5, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "a = tf.constant([[0.1,0.2,0.7],[0.9,0.05,0.05]]) # shape (2,3)\n",
    "\n",
    "pred = tf.cast(tf.argmax(a,axis=1),dtype=tf.int32)\n",
    "print(pred)\n",
    "\n",
    "y = tf.constant([2,1])\n",
    "\n",
    "correct_count = tf.reduce_sum(tf.cast(tf.equal(y,pred),dtype=tf.int32))\n",
    "print(correct_count)\n",
    "print(correct_count/len(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique(y=<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>, idx=<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>)\n",
      "Unique(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([4, 2, 3])>, idx=<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 0, 2])>)\n",
      "tf.Tensor([4 2 2 4 3], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.range(5)\n",
    "print(tf.unique(a))\n",
    "\n",
    "a = tf.constant([4,2,2,4,3])\n",
    "b = tf.unique(a)\n",
    "print(b )\n",
    "# 还原\n",
    "print(tf.gather(b.y,b.idx))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 张量排序\n",
    "sort/argsort\n",
    "\n",
    "topk\n",
    "\n",
    "top-5 acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 0 3 2 1], shape=(5,), dtype=int32)\n",
      "tf.Tensor([4 3 2 1 0], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 2 3 4 1], shape=(5,), dtype=int32)\n",
      "tf.Tensor([4 3 2 1 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.shuffle(tf.range(5))\n",
    "print(a)\n",
    "\n",
    "print(tf.sort(a,direction=\"DESCENDING\"))\n",
    "idx = tf.argsort(a,direction=\"DESCENDING\")\n",
    "print(idx)\n",
    "print(tf.gather(a,idx))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 0 6]\n",
      " [3 6 7]\n",
      " [7 3 3]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 3 6]\n",
      " [3 6 7]\n",
      " [3 3 7]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 0 2]\n",
      " [0 1 2]\n",
      " [1 2 0]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform([3,3],maxval=10,dtype=tf.int32)\n",
    "print(a)\n",
    "\n",
    "print(tf.sort(a)) # 对最后一个维度排序\n",
    "print(tf.argsort(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[8 7 8]\n",
      " [1 4 6]\n",
      " [6 7 9]], shape=(3, 3), dtype=int32)\n",
      "TopKV2(values=<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "array([[8, 8],\n",
      "       [6, 4],\n",
      "       [9, 7]])>, indices=<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "array([[0, 2],\n",
      "       [2, 1],\n",
      "       [2, 1]])>)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform([3,3],maxval=10,dtype=tf.int32)\n",
    "res = tf.math.top_k(a,2)\n",
    "print(a)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 填充与复制\n",
    "pad\n",
    "\n",
    "tile\n",
    "\n",
    "broadcast"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]], shape=(4, 3), dtype=int32)\n",
      "(4, 28, 28, 3) (4, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "a = tf.reshape(tf.range(9),[3,3])\n",
    "print(a)\n",
    "\n",
    "print(tf.pad(a,[[0,0],[0,0]])) # 不填充\n",
    "# 对于二维来说：【【上面填充行数，下面填充行数】，【左面填充行数，右边填充行数】】\n",
    "print(tf.pad(a,[[1,0],[0,0]])) # 上面填充一行\n",
    "\n",
    "# image padding\n",
    "b = tf.random.normal([4,28,28,3])\n",
    "c = tf.pad(b,[[0,0],[2,2],[2,2],[0,0]])\n",
    "print(b.shape,c.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 1 2 0 1 2]\n",
      " [3 4 5 3 4 5]\n",
      " [6 7 8 6 7 8]], shape=(3, 6), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [3 4 5]\n",
      "  [6 7 8]]], shape=(1, 3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [3 4 5]\n",
      "  [6 7 8]]\n",
      "\n",
      " [[0 1 2]\n",
      "  [3 4 5]\n",
      "  [6 7 8]]], shape=(2, 3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [3 4 5]\n",
      "  [6 7 8]]\n",
      "\n",
      " [[0 1 2]\n",
      "  [3 4 5]\n",
      "  [6 7 8]]], shape=(2, 3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.reshape(tf.range(9),[3,3])\n",
    "print(a)\n",
    "\n",
    "# [1,2]  1表示axis=0 不复制，2表示axis=1 复制一次\n",
    "print(tf.tile(a,[1,2]))\n",
    "\n",
    "aa = tf.expand_dims(a,axis=0)\n",
    "print(aa)\n",
    "print(tf.tile(aa,[2,1,1]))\n",
    "\n",
    "print(tf.broadcast_to(aa,[2,3,3]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 张量限幅\n",
    "clip_by_value\n",
    "\n",
    "relu\n",
    "\n",
    "clip_by_norm 等比例放缩\n",
    "\n",
    "gradient clipping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 2 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 8], shape=(10,), dtype=int32)\n",
      "tf.Tensor([2 2 2 3 4 5 6 7 8 8], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.range(10)\n",
    "\n",
    "print(tf.maximum(a,2))\n",
    "print(tf.minimum(a,8))\n",
    "print(tf.clip_by_value(a,2,8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-5 -4 -3 -2 -1  0  1  2  3  4], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 0 0 1 2 3 4], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 0 0 0 0 0 1 2 3 4], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = a-5\n",
    "print(a)\n",
    "\n",
    "print(tf.nn.relu(a))\n",
    "print(tf.maximum(a,0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 8.997876  10.502432 ]\n",
      " [ 8.71957   10.4255085]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(19.390333, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[6.960589  8.124486 ]\n",
      " [6.7452965 8.064979 ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(14.999999, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal([2,2],mean=10)\n",
    "print(a)\n",
    "\n",
    "print(tf.norm(a)) # 平方和开根号\n",
    "\n",
    "aa = tf.clip_by_norm(a,15) # 等比例放缩（不会改变向量的方向）\n",
    "\"\"\"\n",
    "防止梯度爆炸\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "# MUST clip gradient here or it will disconverge!\n",
    "grads = [ tf.clip_by_norm(g, 15) for g in grads]\n",
    "\"\"\"\n",
    "print(aa)\n",
    "print(tf.norm(aa))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 高阶特性\n",
    "where\n",
    "\n",
    "scatter_nd\n",
    "\n",
    "meshgrid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.08510873 -0.30872864  1.9884948 ]\n",
      " [-0.3645098   1.0775615   0.25092733]\n",
      " [-0.90860075  2.2727058   1.3190372 ]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ True False  True]\n",
      " [False  True  True]\n",
      " [False  True  True]], shape=(3, 3), dtype=bool)\n",
      "tf.Tensor([0.08510873 1.9884948  1.0775615  0.25092733 2.2727058  1.3190372 ], shape=(6,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0 0]\n",
      " [0 2]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [2 1]\n",
      " [2 2]], shape=(6, 2), dtype=int64)\n",
      "tf.Tensor([0.08510873 1.9884948  1.0775615  0.25092733 2.2727058  1.3190372 ], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal([3,3])\n",
    "print(a)\n",
    "\n",
    "mask = a > 0\n",
    "print(mask)\n",
    "\n",
    "print(tf.boolean_mask(a,mask))\n",
    "\n",
    "indices = tf.where(mask)\n",
    "print(indices)\n",
    "\n",
    "print(tf.gather_nd(a,indices))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones([3,3])\n",
    "B = tf.zeros([3,3])\n",
    "\n",
    "print(tf.where(mask,A,B))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0 11  0 10  9  0  0 12], shape=(8,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[4],[3],[1],[7]])\n",
    "updates = tf.constant([9,10,11,12])\n",
    "shape = tf.constant([8])\n",
    "\n",
    "print(tf.scatter_nd(indices,updates,shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[5 5 5 5]\n",
      "  [6 6 6 6]\n",
      "  [7 7 7 7]\n",
      "  [8 8 8 8]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[5 5 5 5]\n",
      "  [6 6 6 6]\n",
      "  [7 7 7 7]\n",
      "  [8 8 8 8]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]], shape=(4, 4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[0],[2]])\n",
    "updates = tf.constant([[[5,5,5,5],[6,6,6,6],[7,7,7,7],[8,8,8,8]],\n",
    "                       [[5,5,5,5],[6,6,6,6],[7,7,7,7],[8,8,8,8]]])\n",
    "# updates.shape(2,4,4)\n",
    "shape = tf.constant([4,4,4])\n",
    "print(tf.scatter_nd(indices,updates,shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-2. -1.  0.  1.  2.], shape=(5,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-2. -1.  0.  1.  2.]\n",
      " [-2. -1.  0.  1.  2.]\n",
      " [-2. -1.  0.  1.  2.]\n",
      " [-2. -1.  0.  1.  2.]\n",
      " [-2. -1.  0.  1.  2.]], shape=(5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-2. -2. -2. -2. -2.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 2.  2.  2.  2.  2.]], shape=(5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-2. -2.]\n",
      "  [-1. -2.]\n",
      "  [ 0. -2.]\n",
      "  [ 1. -2.]\n",
      "  [ 2. -2.]]\n",
      "\n",
      " [[-2. -1.]\n",
      "  [-1. -1.]\n",
      "  [ 0. -1.]\n",
      "  [ 1. -1.]\n",
      "  [ 2. -1.]]\n",
      "\n",
      " [[-2.  0.]\n",
      "  [-1.  0.]\n",
      "  [ 0.  0.]\n",
      "  [ 1.  0.]\n",
      "  [ 2.  0.]]\n",
      "\n",
      " [[-2.  1.]\n",
      "  [-1.  1.]\n",
      "  [ 0.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 2.  1.]]\n",
      "\n",
      " [[-2.  2.]\n",
      "  [-1.  2.]\n",
      "  [ 0.  2.]\n",
      "  [ 1.  2.]\n",
      "  [ 2.  2.]]], shape=(5, 5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y = tf.linspace(-2.,2,5)\n",
    "print(y)\n",
    "\n",
    "x = tf.linspace(-2.,2,5)\n",
    "\n",
    "points_x,points_y = tf.meshgrid(x,y)\n",
    "\n",
    "print(points_x) # x轴\n",
    "print(points_y)\n",
    "\n",
    "\n",
    "points = tf.stack([points_x,points_y],axis=2)\n",
    "print(points)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}