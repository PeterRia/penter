{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorFlow基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据类型\n",
    "\n",
    "### 数值类型\n",
    "\n",
    "一、张量的数据形式\n",
    "\n",
    "标量(scalar)：数据单独的一个数，零维张量，其形状如：shape=()\n",
    "\n",
    "向量(vector) ：一维数组，一维张量，其形状如：shape=(3,)\n",
    "\n",
    "矩阵(matrix)：二维数组，二维张量，其形状如：shape=(3,3)\n",
    "\n",
    "多维数组(n-d array)：多维数组，多维张量，其形状如：shape=(1,3,3)\n",
    "\n",
    "\n",
    "标量在 TensorFlow 是如何创建的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(float, tensorflow.python.framework.ops.EagerTensor, True)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python 语言方式创建标量\n",
    "a = 1.2 \n",
    "# TF 方式创建标量\n",
    "aa = tf.constant(1.2)\n",
    "\n",
    "type(a), type(aa), tf.is_tensor(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要使用 TensorFlow 提供的功能函数， 须通过 TensorFlow 规定的方式去创建张量，而不能使用 Python 语言的标准变量创建方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1. , 2. , 3.3], dtype=float32)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1,2.,3.3])\n",
    "# 打印 TF 张量的相关信息                \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1. , 2. , 3.3], dtype=float32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将 TF 张量的数据导出为 numpy 数组格式\n",
    "x.numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与标量不同，向量的定义须通过 List 容器传给 tf.constant()函数。\n",
    "\n",
    "创建一个元素的向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.2], dtype=float32)>,\n TensorShape([1]))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个元素的向量\n",
    "a = tf.constant([1.2]) \n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 3 个元素的向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>,\n TensorShape([3]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 创建 3 个元素的向量\n",
    "a = tf.constant([1,2, 3.])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n array([[1, 2],\n        [3, 4]])>,\n TensorShape([2, 2]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 2 行 2 列的矩阵\n",
    "a = tf.constant([[1,2],[3,4]]) \n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三维张量可以定义为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\narray([[[1, 2],\n        [3, 4]],\n\n       [[5, 6],\n        [7, 8]]])>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 3 维张量\n",
    "tf.constant([[[1,2],[3,4]],[[5,6],[7,8]]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过传入字符串对象即可创建字符串类型的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'Hello, Deep Learning.'>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建字符串\n",
    "a = tf.constant('Hello, Deep Learning.') \n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串类型\n",
    "\n",
    "通过传入字符串对象即可创建字符串类型的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'Hello, Deep Learning.'>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建字符串\n",
    "a = tf.constant('Hello, Deep Learning.') \n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 tf.strings 模块中，提供了常见的字符串类型的工具函数，如小写化 lower()、 拼接\n",
    "join()、 长度 length()、 切分 split()等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'hello, deep learning.'>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 小写化字符串\n",
    "tf.strings.lower(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 布尔类型\n",
    "布尔类型的张量只需要传入 Python 语言的布尔类型数据，转换成 TensorFlow 内部布尔型即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建布尔类型标量\n",
    "tf.constant(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建布尔类型的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 创建布尔类型向量\n",
    "tf.constant([True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是， TensorFlow 的布尔类型和 Python 语言的布尔类型并不等价，不能通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# 创建 TF 布尔张量\n",
    "a = tf.constant(True) \n",
    "# TF 布尔类型张量与 python 布尔类型比较\n",
    "print(a is True) \n",
    "# 仅数值比较\n",
    "print(a == True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数值精度\n",
    "\n",
    "在创建张量时，可以指定张量的保存精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int16, numpy=-13035>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建指定精度的张量\n",
    "tf.constant(123456789, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=123456789>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(123456789, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于浮点数， 高精度的张量可以表示更精准的数据，例如采用 tf.float32 精度保存π时，实际保存的数据为 3.1415927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=3.1415927>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 从 numpy 中导入 pi 常量\n",
    "np.pi \n",
    "# 32 位\n",
    "tf.constant(np.pi, dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果采用 tf.float64 精度保存π，则能获得更高的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float64, numpy=3.141592653589793>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.pi, dtype=tf.float64) # 64 位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取精度\n",
    "\n",
    "通过访问张量的 dtype 成员属性可以判断张量的保存精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: <dtype: 'float16'>\n",
      "after : <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(np.pi, dtype=tf.float16)\n",
    "\n",
    "# 读取原有张量的数值精度\n",
    "print('before:',a.dtype) \n",
    "# 如果精度不符合要求，则进行转换\n",
    "if a.dtype != tf.float32: \n",
    "    # tf.cast 函数可以完成精度转换\n",
    "    a = tf.cast(a,tf.float32) \n",
    "# 打印转换后的精度\n",
    "print('after :',a.dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类型转换\n",
    "系统的每个模块使用的数据类型、 数值精度可能各不相同， 对于不符合要求的张量的类型及精度， 需要通过 tf.cast 函数进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float64, numpy=3.140625>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 tf.float16 低精度张量\n",
    "a = tf.constant(np.pi, dtype=tf.float16) \n",
    "# 转换为高精度张量\n",
    "tf.cast(a, tf.double) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行类型转换时，需要保证转换操作的合法性， 例如将高精度的张量转换为低精度的张量时，可能发生数据溢出隐患："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int16, numpy=-13035>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(123456789, dtype=tf.int32)\n",
    "# 转换为低精度整型\n",
    "tf.cast(a, tf.int16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "布尔类型与整型之间相互转换也是合法的， 是比较常见的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0])>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([True, False])\n",
    "# 布尔类型转整型\n",
    "tf.cast(a, tf.int32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般默认 0 表示 False， 1 表示 True，在 TensorFlow 中，将非 0 数字都视为 True，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False,  True,  True])>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([-1, 0, 1, 2])\n",
    "# 整型转布尔类型\n",
    "tf.cast(a, tf.bool) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 待优化张量\n",
    "\n",
    "TensorFlow 增加了一种专门的数据类型来支持梯度信息的记录： tf.Variable。 tf.Variable 类型在普通的张量类型基础上添加了 name， trainable 等属性来支持计算图的构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('Variable:0', True)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 TF 张量\n",
    "a = tf.constant([-1, 0, 1, 2]) \n",
    "# 转换为 Variable 类型\n",
    "aa = tf.Variable(a) \n",
    "# Variable 类型张量的属性\n",
    "aa.name, aa.trainable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name 属性用于命名计算图中的变量，这套命名体系是 TensorFlow 内部维护的， 一般不需要用户关注 name 属性；   \n",
    "trainable属性表征当前张量是否需要被优化，创建 Variable 对象时是默认启用优化标志，可以设置trainable=False 来设置张量不需要优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]])>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接创建 Variable 张量\n",
    "tf.Variable([[1,2],[3,4]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建张量\n",
    "\n",
    "### 从数组、列表对象创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.convert_to_tensor 函数可以创建新 Tensor，并将保存在 Python List 对象或者Numpy Array 对象中的数据导入到新 Tensor 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从列表创建张量\n",
    "tf.convert_to_tensor([1,2.]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\narray([[1., 2.],\n       [3., 4.]])>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从数组中创建张量\n",
    "tf.convert_to_tensor(np.array([[1,2.],[3,4]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建全0或全1张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 0，全 1 的标量\n",
    "tf.zeros([]),tf.ones([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 0，全 1 的向量\n",
    "tf.zeros([1]),tf.ones([1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全 0 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[0., 0.],\n       [0., 0.]], dtype=float32)>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 0 矩阵，指定 shape 为 2 行 2 列\n",
    "tf.zeros([2,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全 1 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.]], dtype=float32)>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 1 矩阵，指定 shape 为 3 行 2 列\n",
    "tf.ones([3,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.zeros_like, tf.ones_like 可以方便地新建与某个张量 shape 一致， 且内容为全 0 或全 1 的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个矩阵\n",
    "a = tf.ones([2,3]) \n",
    "# 创建一个与 a 形状相同，但是全 0 的新矩阵\n",
    "tf.zeros_like(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建与张量A形状一样的全 1 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.]], dtype=float32)>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个矩阵\n",
    "a = tf.zeros([3,2]) \n",
    "# 创建一个与 a 形状相同，但是全 1 的新矩阵\n",
    "tf.ones_like(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建自定义数值张量\n",
    "\n",
    "通过 tf.fill(shape, value)可以创建全为自定义数值 value 的张量，形状由 shape 参数指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=-1>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建-1 的标量\n",
    "tf.fill([], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([-1])>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建-1 的向量\n",
    "tf.fill([1], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[99, 99],\n       [99, 99]])>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 2 行 2 列，元素全为 99 的矩阵\n",
    "tf.fill([2,2], 99) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建已知分布的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.random.normal(shape, mean=0.0, stddev=1.0)可以创建形状为 shape，均值为mean，标准差为 stddev 的正态分布$\\mathcal{N}(mean, stddev^2)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[-0.46067753, -0.80162954],\n       [ 2.0413775 , -0.704497  ]], dtype=float32)>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建标准正态分布的张量\n",
    "tf.random.normal([2,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[0.9105985, 1.4723796],\n       [0.6097573, 1.8325226]], dtype=float32)>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建均值为 1，标准差为 2 的正态分布的张量\n",
    "tf.random.normal([2,2], mean=1,stddev=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32)可以创建采样自[minval, maxval)区间的均匀分布的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\narray([[0.40507984, 0.2936803 ],\n       [0.10381484, 0.23867631],\n       [0.63906336, 0.05123353]], dtype=float32)>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建采样自[0,1)均匀分布的矩阵\n",
    "tf.random.uniform([3,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[4.8819246, 9.214917 ],\n       [8.908993 , 2.9890501]], dtype=float32)>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建采样自[0,10)均匀分布的矩阵\n",
    "tf.random.uniform([2,2],maxval=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要均匀采样整形类型的数据，必须指定采样区间的最大值 maxval 参数，同时指定数据类型为 tf.int*型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[35, 45],\n       [73, 53]])>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建采样自[0,100)均匀分布的整型矩阵\n",
    "tf.random.uniform([2,2],maxval=100,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建序列\n",
    "\n",
    "tf.range(limit, delta=1)可以创建[0, limit)之间，步长为 delta 的整型序列，不包含 limit 本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~10，不包含 10\n",
    "tf.range(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 2, 4, 6, 8])>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 0~10，步长为 2 的整形序列\n",
    "tf.range(10,delta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 3, 5, 7, 9])>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(1,10,delta=2) # 1~10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的典型应用\n",
    "\n",
    "### 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.3142045, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 随机模拟网络输出\n",
    "out = tf.random.uniform([4,10]) \n",
    "# 随机构造样本真实标签\n",
    "y = tf.constant([2,3,2,0]) \n",
    "# one-hot 编码\n",
    "y = tf.one_hot(y, depth=10) \n",
    "# 计算每个样本的 MSE\n",
    "loss = tf.keras.losses.mse(y, out) \n",
    "# 平均 MSE,loss 应是标量\n",
    "loss = tf.reduce_mean(loss) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量\n",
    "\n",
    "考虑 2 个输出节点的网络层， 我们创建长度为 2 的偏置向量b，并累加在每个输出节点上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\narray([[-1.0551764 , -0.7158551 ],\n       [ 0.6540193 ,  0.03449329],\n       [ 1.4088888 ,  0.3975852 ],\n       [-0.3390571 , -1.5231084 ]], dtype=float32)>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z=wx,模拟获得激活函数的输入 z\n",
    "z = tf.random.normal([4,2])\n",
    "# 创建偏置向量\n",
    "b = tf.zeros([2])\n",
    "# 累加上偏置向量\n",
    "z = z + b \n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建输入节点数为 4，输出节点数为 3 的线性层网络，那么它的偏置向量 b 的长度应为 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一层 Wx+b，输出节点为 3\n",
    "fc = tf.keras.layers.Dense(3) \n",
    "# 通过 build 函数创建 W,b 张量，输入节点为 4\n",
    "fc.build(input_shape=(2,4))\n",
    "# 查看偏置向量\n",
    "fc.bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[-0.68012226, -0.68012226, -0.68012226],\n       [ 3.877089  ,  3.877089  ,  3.877089  ]], dtype=float32)>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 个样本，特征长度为 4 的张量\n",
    "x = tf.random.normal([2,4]) \n",
    "# 定义 W 张量\n",
    "w = tf.ones([4,3])\n",
    "# 定义 b 张量\n",
    "b = tf.zeros([3]) \n",
    "# X@W+b 运算\n",
    "o = x@w+b \n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'kernel:0' shape=(4, 3) dtype=float32, numpy=\narray([[ 0.2448467 , -0.30665004, -0.01243961],\n       [ 0.03833795, -0.36021662,  0.3461665 ],\n       [-0.02943492, -0.18655735, -0.39552897],\n       [-0.12379485, -0.56200117,  0.03996301]], dtype=float32)>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义全连接层的输出节点为 3\n",
    "fc = tf.keras.layers.Dense(3) \n",
    "# 定义全连接层的输入节点为 4\n",
    "fc.build(input_shape=(2,4)) \n",
    "# 查看权值矩阵 W\n",
    "fc.kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(25000, 80)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动加载 IMDB 电影评价数据集\n",
    "(x_train,y_train),(x_test,y_test)=keras.datasets.imdb.load_data(num_words=10000)\n",
    "# 将句子填充、截断为等长 80 个单词的句子\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen=80)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 x_train 张量的 shape 为[25000,80]，其中 25000 表示句子个数， 80 表示每个句子共 80 个单词，每个单词使用数字编码方式表示。\n",
    "\n",
    "我们通过 layers.Embedding 层将数字编码的单词转换为长度为 100 个词向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([25000, 80, 100])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建词向量 Embedding 层类\n",
    "embedding = tf.keras.layers.Embedding(10000, 100)\n",
    "# 将数字编码的单词转换为词向量\n",
    "out = embedding(x_train)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，经过 Embedding 层编码后，句子张量的 shape 变为[25000,80,100]，其中 100 表示每个单词编码为长度是 100 的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 30, 30, 16])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 32x32 的彩色图片输入，个数为 4\n",
    "x = tf.random.normal([4,32,32,3])\n",
    "# 创建卷积神经网络\n",
    "layer = layers.Conv2D(16, kernel_size=3)\n",
    "# 前向计算\n",
    "out = layer(x) \n",
    "# 输出大小\n",
    "out.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([3, 3, 3, 16])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问卷积核张量\n",
    "layer.kernel.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引与切片\n",
    "### 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建4维张量\n",
    "x = tf.random.normal([4,32,32,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(32, 32, 3), dtype=float32, numpy=\narray([[[-1.7450261 , -0.7572388 , -1.0334352 ],\n        [-1.1375818 , -0.24446957,  0.65341866],\n        [-0.6467867 , -0.33060476,  0.20179671],\n        ...,\n        [-0.4285335 ,  1.9864025 , -1.030697  ],\n        [-0.3670462 ,  0.62237525, -1.158764  ],\n        [ 0.926135  , -0.09735158, -0.6583162 ]],\n\n       [[ 0.7422131 , -0.05145269, -0.75104904],\n        [-0.21416299, -1.5760541 ,  0.179844  ],\n        [ 1.1409987 ,  0.21907268,  0.25540105],\n        ...,\n        [-0.5650806 , -0.03417177,  0.60237026],\n        [ 0.22042844, -0.43259314,  0.7654637 ],\n        [ 0.20122151,  1.3466872 ,  1.4180492 ]],\n\n       [[-0.22506309, -0.71598977,  0.26109946],\n        [-1.3896623 , -0.1084232 ,  1.2113979 ],\n        [ 0.32082868, -1.9174163 , -1.1264993 ],\n        ...,\n        [-1.5208955 ,  0.8980872 , -1.0759847 ],\n        [ 0.38827342,  0.00699212, -0.9972251 ],\n        [ 1.6310918 ,  1.2874713 , -1.3846053 ]],\n\n       ...,\n\n       [[-1.1634533 , -0.18452547, -0.34046653],\n        [ 0.9975529 ,  1.9456109 ,  0.2774178 ],\n        [ 0.77721006,  0.7728076 , -1.1344324 ],\n        ...,\n        [-0.49568617, -1.1677974 ,  0.02051311],\n        [ 0.28934243,  2.245025  ,  0.21593052],\n        [ 0.4263347 , -0.12201909,  2.5278049 ]],\n\n       [[ 0.7475556 , -1.6608233 , -0.20252326],\n        [-0.65272206,  0.21155125,  0.9266878 ],\n        [ 1.1438402 ,  2.1340575 , -1.3823898 ],\n        ...,\n        [ 1.4297782 , -0.63303506,  0.08336689],\n        [ 0.03379599, -0.5688773 ,  1.1053498 ],\n        [-0.47816986, -0.774703  , -0.67739844]],\n\n       [[-0.20204139, -1.1368082 , -1.0731658 ],\n        [-1.3716999 , -1.3257134 ,  0.35282165],\n        [-1.3553604 ,  1.128853  , -1.2206942 ],\n        ...,\n        [ 0.23753197,  1.2050335 ,  1.9654385 ],\n        [ 2.1084867 ,  0.17265609,  1.6043708 ],\n        [ 0.99037576, -1.0338455 ,  0.2889374 ]]], dtype=float32)>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 1 张图片的数据\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(32, 3), dtype=float32, numpy=\narray([[ 0.7422131 , -0.05145269, -0.75104904],\n       [-0.21416299, -1.5760541 ,  0.179844  ],\n       [ 1.1409987 ,  0.21907268,  0.25540105],\n       [-1.0115812 ,  0.05704358, -1.0794528 ],\n       [ 0.2881808 ,  0.5391571 ,  0.05286413],\n       [-0.8382589 ,  0.58902544, -0.7153479 ],\n       [ 2.1875176 , -0.14989942, -2.5793183 ],\n       [-1.7482921 , -0.27966794,  1.0802065 ],\n       [ 0.6097452 ,  0.05305016,  0.46549168],\n       [-0.43974707, -0.33738297,  0.9995111 ],\n       [ 0.04269314,  0.4440102 ,  0.29092273],\n       [ 1.5975004 , -0.70367974,  2.9514217 ],\n       [ 2.393892  , -0.40354803,  0.11187057],\n       [ 1.9373498 ,  0.05829722,  0.7606074 ],\n       [ 1.2094123 , -1.9018784 ,  0.27969465],\n       [-0.6300282 ,  0.12909369,  0.32354122],\n       [-0.29742804, -1.2199006 , -1.1213259 ],\n       [-0.6155078 , -1.0320498 , -1.7355599 ],\n       [-1.1949977 ,  1.2732787 , -0.10690398],\n       [-0.9667211 , -1.9602499 , -0.87217486],\n       [-0.08442669, -0.15084992, -1.3777144 ],\n       [-0.83648956, -0.5157247 , -1.0159314 ],\n       [-1.809475  , -0.5910657 ,  0.72975767],\n       [-0.9777058 , -1.1237601 , -0.5039527 ],\n       [ 1.4491264 ,  0.73651165, -0.69566995],\n       [-0.61125433, -0.71452767, -0.10132359],\n       [ 0.05103232, -0.32112065, -2.3210793 ],\n       [ 1.4266856 ,  1.9875896 , -0.6421266 ],\n       [-0.13468932,  0.48726392,  1.3982381 ],\n       [-0.5650806 , -0.03417177,  0.60237026],\n       [ 0.22042844, -0.43259314,  0.7654637 ],\n       [ 0.20122151,  1.3466872 ,  1.4180492 ]], dtype=float32)>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 1 张图片的第 2 行\n",
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.1409987 , 0.21907268, 0.25540105], dtype=float32)>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 1 张图片，第 2 行，第 3 列的数据\n",
    "x[0][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=-0.8613874>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 3 张图片，第 2 行，第 1 列的像素， B 通道(第 2 个通道)颜色强度值\n",
    "x[2][1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-1.1750896 , -0.14908317,  0.29494122], dtype=float32)>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 2 张图片，第 10 行，第 3 列的数据\n",
    "x[1,9,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 32, 32, 3), dtype=float32, numpy=\narray([[[[ 3.75269502e-01,  1.08738494e+00, -1.19178498e+00],\n         [-7.59101510e-01, -1.18816829e+00, -1.64365315e+00],\n         [-3.82422864e-01,  7.30894744e-01,  1.61891490e-01],\n         ...,\n         [-3.25597972e-01, -4.47040945e-02,  9.57851827e-01],\n         [-2.41981220e+00, -2.93832142e-02,  4.88606632e-01],\n         [ 1.17362626e-01,  1.09279013e+00,  9.93007123e-01]],\n\n        [[ 5.63674510e-01, -1.25167632e+00,  4.20372225e-02],\n         [ 1.15782154e+00,  5.74528635e-01,  2.08755350e+00],\n         [-1.46936619e+00,  3.45582962e-01, -1.42393457e-02],\n         ...,\n         [ 3.52954902e-02,  6.16750598e-01, -8.58375728e-01],\n         [-1.90039463e-02,  4.89505194e-02,  5.45632839e-01],\n         [-7.45874420e-02,  2.50217527e-01,  7.86766410e-01]],\n\n        [[ 2.30238819e+00, -8.31172168e-01, -2.40907431e+00],\n         [ 1.44522929e+00,  1.57444406e+00,  1.93837631e+00],\n         [ 4.72356826e-02, -3.10419559e+00,  5.57069123e-01],\n         ...,\n         [-1.12959790e+00, -5.89910328e-01,  5.30698061e-01],\n         [ 3.00451070e-01,  3.66122484e-01, -6.12003326e-01],\n         [-1.41753443e-02, -5.89414656e-01,  1.11277151e+00]],\n\n        ...,\n\n        [[ 2.69440889e-01,  7.31112584e-02,  7.01080084e-01],\n         [-5.44791520e-01,  1.50376689e+00,  2.60156840e-01],\n         [-1.52984893e+00,  9.90660369e-01,  9.58037283e-03],\n         ...,\n         [-4.88851547e-01, -4.09569025e-01,  2.46765718e-01],\n         [ 1.06858838e+00,  1.58410001e+00,  2.56220132e-01],\n         [ 2.86875933e-01, -1.37167943e+00, -4.83867496e-01]],\n\n        [[-3.44830424e-01, -3.54169667e-01,  1.59023857e+00],\n         [ 2.03190804e-01, -1.84323859e+00, -4.41217691e-01],\n         [ 4.77166891e-01, -1.63062084e+00,  8.64292741e-01],\n         ...,\n         [ 2.63248849e+00, -3.12534243e-01,  1.41454637e-01],\n         [ 1.40936220e+00, -7.62602538e-02,  5.77157080e-01],\n         [-2.77038723e-01, -4.46875125e-01, -1.07459724e+00]],\n\n        [[ 2.66047478e+00,  5.79480708e-01,  1.54182136e+00],\n         [ 1.31297469e-01, -3.95926714e-01,  2.41524607e-01],\n         [ 4.18882638e-01,  1.12426734e+00,  3.16418320e-01],\n         ...,\n         [ 2.41673827e+00, -3.36460263e-01,  5.07908225e-01],\n         [-1.05227423e+00, -1.54717171e+00, -8.96587297e-02],\n         [-8.65549874e-03,  1.22040939e+00,  4.62636445e-03]]],\n\n\n       [[[-1.26698047e-01, -1.64240301e-01, -3.33054930e-01],\n         [ 7.43447943e-03,  3.24052162e-02, -4.03657824e-01],\n         [-1.51751697e-01, -7.89454162e-01, -1.11602592e+00],\n         ...,\n         [ 2.71237463e-01, -7.89059043e-01, -6.78079605e-01],\n         [ 5.68033993e-01,  1.65627325e+00,  1.17109370e+00],\n         [-1.23308063e+00, -3.09246659e-01,  5.82660660e-02]],\n\n        [[ 3.33749838e-02, -8.61387372e-01, -4.53242987e-01],\n         [-1.88598776e+00, -1.56759024e-01, -1.09226441e+00],\n         [ 7.22959757e-01,  2.32336426e+00, -5.47200263e-01],\n         ...,\n         [-1.25789940e+00,  3.11079651e-01,  5.67597449e-01],\n         [-1.16354525e+00,  3.21216762e-01,  6.90057337e-01],\n         [ 2.21724010e+00,  1.07691419e+00,  1.99437022e+00]],\n\n        [[ 1.48175865e-01,  1.25995457e+00, -5.54383844e-02],\n         [ 8.87300253e-01,  3.40220124e-01, -5.63537419e-01],\n         [ 6.30946815e-01,  1.00983047e+00, -8.57168496e-01],\n         ...,\n         [-1.53066742e+00, -7.30207324e-01,  1.09001148e+00],\n         [-6.43378496e-01,  1.79218397e-01,  7.91379213e-01],\n         [ 4.34421927e-01, -9.23263967e-01,  7.00964555e-02]],\n\n        ...,\n\n        [[-8.58913422e-01, -4.17846590e-01, -5.35850465e-01],\n         [ 1.08721748e-03, -2.39410233e+00, -1.37849641e+00],\n         [-1.19642591e+00,  2.41442251e+00, -1.17564034e+00],\n         ...,\n         [ 4.45567608e-01,  1.95131049e-01, -6.48768961e-01],\n         [ 2.55585909e-01, -1.29096448e+00,  9.63189185e-01],\n         [-8.06669176e-01,  5.98918855e-01,  2.47977361e-01]],\n\n        [[-7.30373442e-01, -1.29159063e-01, -5.76349914e-01],\n         [ 1.35043904e-01,  1.94929790e+00, -4.43743885e-01],\n         [-4.33659106e-01,  2.40749493e-01,  1.28504622e+00],\n         ...,\n         [-1.68995723e-01, -1.18830240e+00,  1.06181538e+00],\n         [-4.33532894e-02, -4.54026997e-01,  1.15239048e+00],\n         [ 9.76894617e-01, -1.38040495e+00, -1.37490487e+00]],\n\n        [[-6.28584087e-01, -1.49521306e-01, -7.50335157e-01],\n         [-2.26407576e+00,  1.70867348e+00,  9.29860830e-01],\n         [-4.49878424e-01,  4.85023081e-01, -2.64962763e-01],\n         ...,\n         [-5.16163349e-01,  8.98374438e-01,  2.96835124e-01],\n         [-8.65525424e-01,  1.73760784e+00, -1.96034551e-01],\n         [ 8.08328450e-01, -9.32948530e-01, -1.76231012e-01]]]],\n      dtype=float32)>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取第 2,3 张图片\n",
    "x[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(32, 32, 3), dtype=float32, numpy=\narray([[[-1.7450261 , -0.7572388 , -1.0334352 ],\n        [-1.1375818 , -0.24446957,  0.65341866],\n        [-0.6467867 , -0.33060476,  0.20179671],\n        ...,\n        [-0.4285335 ,  1.9864025 , -1.030697  ],\n        [-0.3670462 ,  0.62237525, -1.158764  ],\n        [ 0.926135  , -0.09735158, -0.6583162 ]],\n\n       [[ 0.7422131 , -0.05145269, -0.75104904],\n        [-0.21416299, -1.5760541 ,  0.179844  ],\n        [ 1.1409987 ,  0.21907268,  0.25540105],\n        ...,\n        [-0.5650806 , -0.03417177,  0.60237026],\n        [ 0.22042844, -0.43259314,  0.7654637 ],\n        [ 0.20122151,  1.3466872 ,  1.4180492 ]],\n\n       [[-0.22506309, -0.71598977,  0.26109946],\n        [-1.3896623 , -0.1084232 ,  1.2113979 ],\n        [ 0.32082868, -1.9174163 , -1.1264993 ],\n        ...,\n        [-1.5208955 ,  0.8980872 , -1.0759847 ],\n        [ 0.38827342,  0.00699212, -0.9972251 ],\n        [ 1.6310918 ,  1.2874713 , -1.3846053 ]],\n\n       ...,\n\n       [[-1.1634533 , -0.18452547, -0.34046653],\n        [ 0.9975529 ,  1.9456109 ,  0.2774178 ],\n        [ 0.77721006,  0.7728076 , -1.1344324 ],\n        ...,\n        [-0.49568617, -1.1677974 ,  0.02051311],\n        [ 0.28934243,  2.245025  ,  0.21593052],\n        [ 0.4263347 , -0.12201909,  2.5278049 ]],\n\n       [[ 0.7475556 , -1.6608233 , -0.20252326],\n        [-0.65272206,  0.21155125,  0.9266878 ],\n        [ 1.1438402 ,  2.1340575 , -1.3823898 ],\n        ...,\n        [ 1.4297782 , -0.63303506,  0.08336689],\n        [ 0.03379599, -0.5688773 ,  1.1053498 ],\n        [-0.47816986, -0.774703  , -0.67739844]],\n\n       [[-0.20204139, -1.1368082 , -1.0731658 ],\n        [-1.3716999 , -1.3257134 ,  0.35282165],\n        [-1.3553604 ,  1.128853  , -1.2206942 ],\n        ...,\n        [ 0.23753197,  1.2050335 ,  1.9654385 ],\n        [ 2.1084867 ,  0.17265609,  1.6043708 ],\n        [ 0.99037576, -1.0338455 ,  0.2889374 ]]], dtype=float32)>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取第一张图片\n",
    "x[0,::] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 14, 14, 3), dtype=float32, numpy=\narray([[[[-1.74502611e+00, -7.57238805e-01, -1.03343523e+00],\n         [-6.46786690e-01, -3.30604762e-01,  2.01796710e-01],\n         [-1.39652684e-01,  1.11349261e+00, -4.37843531e-01],\n         ...,\n         [ 2.33928308e-01, -8.38892758e-01, -5.08989036e-01],\n         [ 9.19142902e-01, -1.48180306e+00,  1.48225129e+00],\n         [-1.08102119e+00, -1.12764382e+00, -1.01000130e+00]],\n\n        [[-2.25063086e-01, -7.15989769e-01,  2.61099458e-01],\n         [ 3.20828676e-01, -1.91741633e+00, -1.12649930e+00],\n         [ 4.44881290e-01,  2.03384209e+00,  5.05309924e-03],\n         ...,\n         [ 4.73196000e-01,  2.53800249e+00,  2.55634880e+00],\n         [-7.71026373e-01, -1.09348893e-01, -1.78558254e+00],\n         [ 2.87946105e-01,  2.13401303e-01,  1.79187641e-01]],\n\n        [[-3.96388382e-01, -7.97443032e-01,  7.98904955e-01],\n         [ 1.31878877e+00,  1.75256097e+00, -4.03931320e-01],\n         [-5.42645037e-01, -1.58776566e-01,  8.23694348e-01],\n         ...,\n         [-3.79926227e-02, -1.06619918e+00, -2.06373245e-01],\n         [-1.74949133e+00,  3.37535709e-01,  5.38648367e-01],\n         [ 3.62287313e-01, -1.20560813e+00,  1.73424339e+00]],\n\n        ...,\n\n        [[-1.23496614e-01, -1.41460165e-01, -1.62972760e+00],\n         [-3.63690734e-01, -1.52531481e+00,  1.61612964e+00],\n         [ 1.14194497e-01, -7.14620709e-01,  6.30565226e-01],\n         ...,\n         [-1.66396058e+00,  1.42727032e-01,  1.10658395e+00],\n         [ 2.86386982e-02, -6.59188509e-01, -1.54915512e+00],\n         [ 1.95692644e-01,  1.01617002e+00,  3.02565157e-01]],\n\n        [[-1.92178524e+00,  1.90818810e+00,  1.52382538e-01],\n         [ 8.39675777e-04, -1.01184309e+00, -2.12523222e+00],\n         [ 1.34872913e+00,  6.63923919e-01, -7.06229687e-01],\n         ...,\n         [ 7.06065670e-02, -2.75145602e+00, -5.36329091e-01],\n         [ 1.98146775e-01,  7.29382634e-01, -1.87306285e-01],\n         [ 9.26657796e-01, -8.99836123e-01,  2.81738192e-01]],\n\n        [[-1.69703752e-01,  1.25846577e+00,  8.17708313e-01],\n         [-9.23389077e-01, -1.84059471e-01, -8.49456489e-02],\n         [-7.92866111e-01,  5.03651679e-01,  8.99565101e-01],\n         ...,\n         [-2.84700125e-01,  2.31652960e-01,  9.12625909e-01],\n         [ 2.25649327e-02, -2.26812124e+00, -1.31486487e+00],\n         [ 4.34622943e-01, -5.47618091e-01, -1.78708565e+00]]],\n\n\n       [[[ 3.75269502e-01,  1.08738494e+00, -1.19178498e+00],\n         [-3.82422864e-01,  7.30894744e-01,  1.61891490e-01],\n         [ 4.17857796e-01,  9.16643858e-01,  1.27873600e-01],\n         ...,\n         [ 1.37858689e+00, -1.85938251e+00, -7.83107221e-01],\n         [-4.22152489e-01, -4.37780023e-02, -5.51597476e-01],\n         [ 1.65938258e+00, -1.10287523e+00, -2.09873319e+00]],\n\n        [[ 2.30238819e+00, -8.31172168e-01, -2.40907431e+00],\n         [ 4.72356826e-02, -3.10419559e+00,  5.57069123e-01],\n         [ 1.04094662e-01,  4.21399117e-01,  2.05310011e+00],\n         ...,\n         [-1.14668083e+00, -4.28685665e-01, -1.52066529e+00],\n         [-1.05430984e+00, -1.79603174e-01,  6.87166631e-01],\n         [-7.87059307e-01,  1.11838174e+00,  2.55290955e-01]],\n\n        [[ 4.68301922e-01, -2.40062959e-02, -1.09508240e+00],\n         [-9.42723513e-01, -1.92003191e-01, -1.15947556e+00],\n         [-2.05402064e+00,  6.98693693e-02,  1.83687136e-01],\n         ...,\n         [ 3.35820615e-01, -7.29455352e-01,  7.74884999e-01],\n         [ 1.02976692e+00,  1.45754457e-01,  1.27362502e+00],\n         [ 5.46450198e-01,  1.13605452e+00, -1.68037206e-01]],\n\n        ...,\n\n        [[-5.26495337e-01,  1.28981805e+00, -1.29059076e+00],\n         [-7.61717856e-01,  1.14649355e+00, -1.33695042e+00],\n         [ 1.47955346e+00,  2.16376662e+00, -7.52129376e-01],\n         ...,\n         [-1.08255112e+00,  6.53616428e-01, -2.17040324e+00],\n         [ 1.54640901e+00, -1.01700461e+00,  7.03062773e-01],\n         [-7.29504049e-01, -3.00595045e-01, -1.04446614e+00]],\n\n        [[-4.66552585e-01, -1.58926636e-01, -6.43119812e-01],\n         [-1.11304796e+00, -9.36366200e-01, -7.42403150e-01],\n         [ 2.06086770e-01, -6.28968179e-01, -7.35117793e-01],\n         ...,\n         [ 7.03681052e-01, -7.72932231e-01,  8.02351534e-01],\n         [-3.06681365e-01,  4.85167699e-03, -7.19640791e-01],\n         [ 1.96860179e-01, -2.08315134e-01, -5.07511318e-01]],\n\n        [[ 1.34347391e+00,  1.22579443e+00, -1.22401464e+00],\n         [-9.29328382e-01, -1.96884885e-01, -8.11368763e-01],\n         [-1.55185238e-01,  9.96397138e-01,  1.48272187e-01],\n         ...,\n         [-7.92513192e-01,  2.84817964e-01,  1.54027328e-01],\n         [ 4.11927819e-01,  5.39519310e-01, -2.53914326e-01],\n         [-9.58221912e-01,  2.43092090e-01, -1.01778758e+00]]],\n\n\n       [[[-1.26698047e-01, -1.64240301e-01, -3.33054930e-01],\n         [-1.51751697e-01, -7.89454162e-01, -1.11602592e+00],\n         [-7.24842787e-01, -2.25408465e-01, -7.26864412e-02],\n         ...,\n         [ 6.63035810e-01, -1.94901240e+00,  1.99405532e-02],\n         [ 3.20638865e-01,  1.51380134e+00, -7.01515138e-01],\n         [-1.91384280e+00, -3.94716442e-01,  1.57626554e-01]],\n\n        [[ 1.48175865e-01,  1.25995457e+00, -5.54383844e-02],\n         [ 6.30946815e-01,  1.00983047e+00, -8.57168496e-01],\n         [ 9.31474924e-01,  9.68183815e-01, -4.33764786e-01],\n         ...,\n         [ 1.46623254e+00,  1.18558371e+00,  8.89442205e-01],\n         [-2.45063424e+00,  8.36928248e-01, -2.14474462e-02],\n         [-5.38859427e-01, -1.38368928e+00,  1.57105458e+00]],\n\n        [[-5.81369460e-01,  1.58955194e-02, -2.67704844e-01],\n         [ 6.53480113e-01, -7.53907263e-01, -4.00812417e-01],\n         [-2.58729964e-01,  3.94358367e-01,  5.03527343e-01],\n         ...,\n         [-1.77283084e+00, -4.33115184e-01,  6.28688872e-01],\n         [-8.31943631e-01, -1.62598813e+00,  1.80074692e+00],\n         [ 9.87738848e-01, -1.18462598e+00, -4.35975760e-01]],\n\n        ...,\n\n        [[-1.19490635e+00,  8.11410129e-01,  5.93426049e-01],\n         [-1.76390612e+00,  6.96156025e-01,  9.37996209e-01],\n         [ 5.20256996e-01,  1.79825175e+00,  4.37548310e-01],\n         ...,\n         [ 4.38595265e-02, -2.58227849e+00, -6.84576571e-01],\n         [ 1.88349450e+00,  1.31522715e-01,  3.88191700e-01],\n         [-6.25347793e-01,  1.87836039e+00, -4.82960254e-01]],\n\n        [[ 9.99362826e-01,  1.07096255e+00,  1.29761910e+00],\n         [ 6.28995419e-01, -1.38692570e+00, -2.12051344e+00],\n         [ 1.31062925e+00,  6.17060721e-01, -1.67982727e-01],\n         ...,\n         [ 1.05864549e+00,  9.69526291e-01, -8.00894797e-01],\n         [-1.04233086e+00, -6.08833075e-01, -2.42537394e-01],\n         [-2.01534343e+00,  9.60750282e-01,  4.37222570e-01]],\n\n        [[ 4.79100406e-01, -2.07751155e+00, -1.84455454e+00],\n         [ 2.64001787e-01,  1.92922637e-01,  1.09444186e-01],\n         [ 1.13006651e+00, -1.28343582e+00,  9.58279967e-01],\n         ...,\n         [ 1.55396438e+00,  6.22747719e-01, -1.06412506e+00],\n         [-8.67795765e-01, -2.18734264e+00,  1.28450143e+00],\n         [ 9.06593144e-01, -3.34807724e-01, -7.61970103e-01]]],\n\n\n       [[[-1.30583572e+00,  2.36029601e+00, -5.02960265e-01],\n         [-3.97810221e-01, -3.47525239e-01,  4.12569970e-01],\n         [-1.60229230e+00, -1.59714198e+00, -1.39352095e+00],\n         ...,\n         [ 9.61619914e-01,  4.09075469e-01, -3.13718095e-02],\n         [ 5.68548441e-02,  5.49263477e-01, -6.10852182e-01],\n         [-2.04682422e+00, -5.79602003e-01, -1.79196370e+00]],\n\n        [[ 6.71143532e-01,  2.10571334e-01,  1.14191365e+00],\n         [ 2.32412741e-01,  1.84922791e+00, -1.33634722e+00],\n         [-1.09682643e+00,  3.04826319e-01, -1.30019403e+00],\n         ...,\n         [ 1.80075347e+00, -2.45119646e-01, -2.23658490e+00],\n         [ 4.83075887e-01,  4.15558845e-01,  3.42334241e-01],\n         [ 1.28444195e-01, -2.16942295e-01,  1.95918247e-01]],\n\n        [[-1.04757845e+00, -1.09424040e-01, -2.83970213e+00],\n         [ 6.82496488e-01,  3.40875417e-01, -9.02708352e-01],\n         [-2.22961783e+00, -7.92944282e-02, -1.84121466e+00],\n         ...,\n         [-5.81198990e-01, -6.11872673e-02,  1.31530330e-01],\n         [-7.11228549e-02,  5.69661915e-01, -9.22314286e-01],\n         [-4.56026644e-01,  3.24881896e-02, -1.60945046e+00]],\n\n        ...,\n\n        [[ 3.70487690e-01,  4.48663056e-01,  3.58599164e-02],\n         [ 4.64692146e-01,  3.41929257e-01, -1.30442178e+00],\n         [-4.51213360e-01, -8.16990342e-03,  5.14237463e-01],\n         ...,\n         [-1.30716369e-01, -1.03419209e+00, -1.89625338e-01],\n         [ 6.08992040e-01, -3.05415932e-02,  1.37765670e+00],\n         [-1.27315557e+00,  6.46934748e-01, -2.18462896e+00]],\n\n        [[-1.08259964e+00,  9.62446332e-01,  2.25218192e-01],\n         [-6.61421299e-01,  1.63983428e+00, -4.81051058e-01],\n         [ 3.64447534e-01,  1.03590477e+00,  1.93618071e+00],\n         ...,\n         [ 9.59021986e-01,  9.49575365e-01,  6.76626563e-01],\n         [ 6.78603828e-01,  5.72354853e-01,  9.39876661e-02],\n         [ 1.91637315e-02,  1.52149415e+00,  2.00798705e-01]],\n\n        [[ 1.00794137e+00,  9.25407335e-02, -5.78984559e-01],\n         [-1.14916813e+00,  7.23430991e-01,  1.22527027e+00],\n         [ 6.90768361e-01, -1.05048501e+00, -8.83992255e-01],\n         ...,\n         [-1.29333639e+00, -6.19280398e-01,  2.22426462e+00],\n         [ 1.11541653e+00,  5.14710784e-01, -8.31380010e-01],\n         [ 3.61641914e-01,  2.54786420e+00, -6.11593500e-02]]]],\n      dtype=float32)>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0:28:2,0:28:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(8,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1])>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 考虑一个 0~9 的简单序列向量， 逆序取到第 1 号元素，不包含第 1 号\n",
    "# 创建 0~9 向量\n",
    "x = tf.range(9) \n",
    "# 从 8 取到 0，逆序，不包含 0\n",
    "x[8:0:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1, 0])>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逆序全部元素\n",
    "x[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([8, 6, 4, 2, 0])>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逆序间隔采样\n",
    "x[::-2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取每张图片的所有通道，其中行按着逆序隔行采样，列按着逆序隔行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(16, 16, 3), dtype=float32, numpy=\narray([[[-6.09962761e-01,  1.93407446e-01,  5.28300941e-01],\n        [-2.32661462e+00,  1.08571970e+00,  5.59375823e-01],\n        [-4.00491327e-01, -3.57767165e-01,  4.20534499e-02],\n        [-1.21397384e-01,  1.58362687e+00, -5.19303679e-01],\n        [ 1.46465704e-01, -1.35310754e-01, -2.45350704e-01],\n        [-5.32628477e-01,  7.85642087e-01,  4.84743297e-01],\n        [ 5.31589150e-01,  2.98292041e-01, -3.53698224e-01],\n        [-1.60514355e+00,  1.32932425e+00,  1.44127679e+00],\n        [ 3.02087981e-02,  1.37136793e+00, -1.59377322e-01],\n        [ 1.39672697e-01,  4.23355073e-01,  1.02963710e+00],\n        [ 5.83233312e-02, -5.28961301e-01, -7.11210743e-02],\n        [ 1.02563179e+00,  6.82720304e-01, -6.93476617e-01],\n        [-2.45665073e+00, -1.24394536e+00,  5.97246766e-01],\n        [ 2.38930508e-01,  1.16224027e+00,  2.17213583e+00],\n        [-8.45830142e-01, -3.94775486e-03,  2.72814780e-01],\n        [ 1.62686408e+00, -1.48743868e+00,  1.16808057e+00]],\n\n       [[ 2.29291964e+00,  1.60965145e+00,  2.11432949e-01],\n        [ 8.56684670e-02, -2.86358353e-02, -5.10614038e-01],\n        [ 1.44733322e+00, -2.22628379e+00, -8.31095576e-01],\n        [-2.79751003e-01, -8.65134418e-01,  9.62367415e-01],\n        [ 2.46503308e-01,  1.21411994e-01,  1.59499729e+00],\n        [ 2.56251788e+00, -1.61023474e+00,  1.94438964e-01],\n        [-9.14400458e-01, -8.76610219e-01, -1.35175556e-01],\n        [ 9.12332773e-01,  3.84871632e-01, -6.85345173e-01],\n        [-1.13637257e+00,  9.10985991e-02,  1.43764853e-01],\n        [ 1.34382808e+00,  7.89693594e-02, -4.19807136e-01],\n        [ 1.53216660e+00, -7.04443991e-01, -1.94444984e-01],\n        [ 1.49469852e-01, -1.15772259e+00,  6.40338242e-01],\n        [ 7.12744415e-01,  2.40493312e-01, -9.81914580e-01],\n        [ 1.09397876e+00, -1.91052759e+00, -1.23927546e+00],\n        [-9.50776517e-01,  5.83250582e-01,  1.43676013e-01],\n        [-2.12307662e-01, -1.91970658e+00, -1.85657769e-01]],\n\n       [[ 1.02243990e-01, -1.16199625e+00, -4.13687527e-01],\n        [ 2.11004734e+00, -4.05073091e-02, -8.58253300e-01],\n        [-1.31433392e+00,  7.85335660e-01,  1.06510568e+00],\n        [-4.91488487e-01, -3.68863404e-01, -5.97413301e-01],\n        [ 2.50438309e+00,  9.81444955e-01, -1.23209786e+00],\n        [-7.50824809e-01,  2.00116813e-01,  1.10473387e-01],\n        [-5.70222199e-01,  7.14561701e-01,  7.93468475e-01],\n        [ 2.89265156e-01, -1.14270973e+00, -2.44319960e-01],\n        [-6.10359982e-02,  4.19305146e-01, -8.90576303e-01],\n        [-1.27009070e+00,  1.50976419e-01,  1.40996262e-01],\n        [-1.07724950e-01,  7.04931989e-02, -2.57381946e-01],\n        [ 6.87591195e-01,  1.97883956e-02, -5.98830581e-01],\n        [-1.74831614e-01,  4.78617042e-01,  1.75524309e-01],\n        [ 6.21794015e-02,  6.44479871e-01, -8.35447311e-01],\n        [-1.02735043e+00, -2.55708039e-01,  1.63580573e+00],\n        [-2.59235203e-01,  3.26217949e-01,  3.71585190e-01]],\n\n       [[ 5.86429119e-01,  2.01633549e+00,  2.57330924e-01],\n        [-6.99316144e-01,  1.33657724e-01,  2.10860300e+00],\n        [ 2.76027977e-01, -2.43498668e-01, -1.27182221e+00],\n        [ 3.62211168e-01, -8.77298117e-01,  8.74517918e-01],\n        [ 2.91336775e-01,  4.23974395e-01,  3.15016657e-01],\n        [-5.97319543e-01, -9.94719446e-01, -1.77373123e+00],\n        [-2.09060475e-01, -9.79142487e-01, -1.95070878e-01],\n        [-1.52244616e+00,  1.34830490e-01,  4.82949555e-01],\n        [ 6.34600163e-01, -1.32292378e+00, -2.83246279e-01],\n        [ 1.47149399e-01, -2.92227939e-02, -6.77915335e-01],\n        [-1.80163407e+00, -8.86371195e-01,  1.50583601e+00],\n        [ 8.13352764e-01,  2.27820024e-01, -1.35058272e+00],\n        [-5.68725646e-01,  1.78573406e+00,  1.62740958e+00],\n        [-5.16694546e-01, -6.30749106e-01, -4.64103103e-01],\n        [ 2.05698061e+00, -4.93474841e-01,  1.49215341e+00],\n        [ 5.15110493e-01, -3.19866121e-01,  6.69659495e-01]],\n\n       [[-7.21651793e-01, -2.75502533e-01,  8.35817903e-02],\n        [-5.88800013e-02,  3.32608894e-02, -7.52362490e-01],\n        [ 1.07840347e+00, -1.68894976e-01,  8.45585823e-01],\n        [ 5.41643679e-01, -9.80273843e-01, -1.38534284e+00],\n        [-5.67038357e-01, -9.66246665e-01,  1.34989595e+00],\n        [-5.36187530e-01, -1.87479270e+00, -1.79807484e+00],\n        [-3.72170538e-01, -3.43611687e-01, -1.32657528e+00],\n        [ 3.45467217e-02, -1.56163916e-01,  7.68278539e-01],\n        [-1.31080449e+00, -1.69205248e-01, -1.11619604e+00],\n        [-4.59615797e-01,  5.90215862e-01,  5.57465374e-01],\n        [ 1.30869246e+00,  3.60490978e-01, -5.01087844e-01],\n        [ 8.26622963e-01,  3.79517198e-01,  9.61418569e-01],\n        [-7.09882736e-01, -1.90872574e+00, -1.14884818e+00],\n        [-4.27847862e-01, -6.61031842e-01,  1.04534853e+00],\n        [ 2.24274024e-01, -7.82465562e-02,  9.14372444e-01],\n        [-7.11440265e-01,  1.06292439e+00,  8.47286105e-01]],\n\n       [[-1.38612419e-01, -4.15532887e-01, -8.66320014e-01],\n        [-2.30413377e-01,  1.65990603e+00, -1.05594561e-01],\n        [-5.21958709e-01,  1.46385431e+00, -2.93280035e-01],\n        [ 8.49062026e-01, -8.97742689e-01,  5.34357667e-01],\n        [-1.14632761e+00, -1.16138101e-01, -1.63844582e-02],\n        [ 9.45504904e-01,  7.19710052e-01, -1.16549456e+00],\n        [-8.03523064e-01,  1.04400921e+00,  2.96211481e-01],\n        [ 2.56471723e-01,  3.43980253e-01,  6.39073193e-01],\n        [-4.50205803e-01,  3.87171030e-01,  1.29062667e-01],\n        [-8.88135493e-01, -1.05007219e+00, -1.31615341e-01],\n        [-1.03057492e+00, -1.14261496e+00,  4.56003040e-01],\n        [-4.84866679e-01,  1.54875353e-01,  9.64792132e-01],\n        [-1.00756359e+00, -9.81024265e-01, -1.12351441e+00],\n        [-1.54423460e-01, -9.66707021e-02,  7.19171286e-01],\n        [ 4.59708691e-01,  4.65163231e-01, -8.29814792e-01],\n        [ 1.29395157e-01, -7.98084736e-01, -1.41754818e+00]],\n\n       [[-4.00461733e-01, -9.71560955e-01, -1.40184331e+00],\n        [-4.46988612e-01, -9.16826248e-01, -2.76988125e+00],\n        [ 1.45536903e-02,  7.06412494e-01, -1.90841699e+00],\n        [-1.16750884e+00, -6.22001231e-01, -1.38497758e+00],\n        [-2.76413977e-01,  5.56278527e-01, -3.75934362e-01],\n        [ 1.08494051e-01, -1.44018546e-01,  5.21216393e-01],\n        [-1.05979955e+00, -2.72904813e-01,  1.01126862e+00],\n        [ 1.24131572e+00, -3.51085454e-01, -7.60873199e-01],\n        [ 2.02576563e-01,  5.02010882e-01, -6.46585166e-01],\n        [ 1.78252086e-02, -1.45064735e+00,  1.02413595e+00],\n        [ 8.06900799e-01, -1.48675573e+00,  5.04719257e-01],\n        [-8.87810230e-01, -2.00045633e+00,  7.36112833e-01],\n        [ 2.83603787e-01,  2.13715702e-01, -3.37197691e-01],\n        [ 2.78359699e+00, -1.23374975e+00, -8.97768795e-01],\n        [ 2.11484402e-01,  2.44904548e-01, -1.13019764e+00],\n        [ 8.18382084e-01, -1.93398282e-01,  7.36131847e-01]],\n\n       [[ 1.01415956e+00,  2.67240644e-01, -3.54593284e-02],\n        [ 2.32535094e-01,  1.34366259e-01, -7.70151794e-01],\n        [-6.86726421e-02,  6.00570560e-01, -1.77882576e+00],\n        [-6.67746305e-01, -1.83810722e-02, -7.30498433e-01],\n        [ 1.11880176e-01, -8.39936495e-01,  3.89041781e-01],\n        [ 1.28598607e+00, -1.86858937e-01,  1.98337257e-01],\n        [-3.43389511e-02,  6.07174516e-01, -1.15845847e+00],\n        [-6.34665370e-01, -2.23352969e-01,  8.36698890e-01],\n        [-5.64087212e-01,  1.70846534e+00,  6.25630379e-01],\n        [-8.61177295e-02, -4.78427321e-01, -5.68838418e-01],\n        [-2.09416366e+00, -5.26858985e-01,  4.08477217e-01],\n        [ 1.34583250e-01, -1.73634279e+00, -1.22787225e+00],\n        [-1.15117800e+00,  6.94978058e-01, -9.47058126e-02],\n        [-2.97101289e-01, -7.39648104e-01, -1.92872560e+00],\n        [ 2.11818147e+00, -4.90293026e-01, -1.30741096e+00],\n        [-7.74599135e-01, -5.66328578e-02,  1.17148137e+00]],\n\n       [[ 9.41463649e-01, -1.14823067e+00,  3.34143668e-01],\n        [ 1.48935008e+00, -5.29970646e-01,  4.23973471e-01],\n        [ 8.51957858e-01,  1.44227326e+00, -1.40061051e-01],\n        [-4.59211051e-01,  5.48704378e-02, -2.42481053e-01],\n        [ 1.17337477e+00,  7.68723190e-01,  6.05203807e-01],\n        [ 5.08459508e-01, -6.37977421e-01, -1.27414513e+00],\n        [-1.02747035e+00, -9.46997479e-02,  3.01649719e-01],\n        [-5.00229716e-01, -1.69220400e+00, -6.50108337e-01],\n        [ 2.83585000e-03, -4.36995089e-01,  5.08221865e-01],\n        [ 9.18273211e-01,  7.69669414e-01, -8.17589700e-01],\n        [-8.14286888e-01, -3.95182639e-01,  1.00929046e+00],\n        [ 4.22907501e-01, -1.01323426e+00, -1.20839190e+00],\n        [-2.54630506e-01, -7.20338643e-01,  4.78756189e-01],\n        [ 2.35095516e-01,  2.10481822e-01, -1.16966856e+00],\n        [-1.16494846e+00,  7.69918784e-02,  5.25165915e-01],\n        [-7.34854955e-03,  4.76388872e-01, -7.60002017e-01]],\n\n       [[-5.80004871e-01, -4.12324041e-01, -8.80743563e-01],\n        [-1.33985293e+00, -8.99206698e-01,  4.38950181e-01],\n        [-1.84506750e+00, -1.17798281e+00,  8.95845711e-01],\n        [-1.43922856e-02,  8.57675314e-01,  1.37893248e+00],\n        [-2.09812015e-01, -1.83552039e+00, -2.11125398e+00],\n        [ 1.13896155e+00,  1.78198099e-01, -4.93213862e-01],\n        [ 8.43650758e-01,  6.52105927e-01,  1.54522464e-01],\n        [-3.75710845e-01,  8.08694839e-01, -1.06148370e-01],\n        [ 8.86659026e-01, -1.28950775e+00, -8.35264683e-01],\n        [ 2.95530021e-01, -1.03471172e+00,  9.78227079e-01],\n        [-2.46673122e-01,  1.05744958e+00,  1.26452494e+00],\n        [-1.66627988e-01,  1.19978011e+00,  6.67424083e-01],\n        [ 7.36203119e-02,  9.62136745e-01,  1.32716250e+00],\n        [ 1.57201350e-01, -4.96576697e-01, -8.02535713e-02],\n        [-2.34463024e+00,  1.25929359e-02,  1.72452402e+00],\n        [ 5.66158354e-01, -1.56417799e+00, -2.38994703e-01]],\n\n       [[ 6.00509524e-01, -7.54986644e-01,  6.19422674e-01],\n        [-2.15505704e-01, -3.69084209e-01,  3.54287267e-01],\n        [-6.25391543e-01,  5.00179350e-01, -1.55479109e+00],\n        [-7.20546365e-01, -2.24045530e-01, -6.60456777e-01],\n        [-1.11818767e+00,  2.70960867e-01,  8.01718652e-01],\n        [ 1.85651720e+00,  7.05976710e-02, -1.20104051e+00],\n        [-1.40629396e-01, -1.01791704e+00,  1.12889528e+00],\n        [-7.06983387e-01,  1.33089781e+00,  8.35808396e-01],\n        [ 4.32872087e-01, -1.99304685e-01, -3.34855407e-01],\n        [ 4.03529257e-01,  1.60488650e-01,  1.59411025e+00],\n        [ 6.70274794e-01, -1.28023076e+00,  5.42968512e-01],\n        [ 2.95385942e-02,  7.41011277e-03, -1.28082037e+00],\n        [ 1.49575663e+00, -1.15833676e+00, -9.27688703e-02],\n        [ 1.67100477e+00, -1.25596315e-01,  3.07665974e-01],\n        [ 2.61053294e-01, -5.49359143e-01, -1.14029959e-01],\n        [ 1.21913165e-01, -9.99613106e-01,  1.41938329e-01]],\n\n       [[ 2.25635791e+00, -1.32744694e+00,  8.91603351e-01],\n        [-8.22531998e-01,  5.70932567e-01, -1.20212042e+00],\n        [ 3.58550906e-01,  7.23773479e-01,  4.16804820e-01],\n        [-1.63256204e+00, -2.76262730e-01,  7.29403615e-01],\n        [-8.52773488e-01,  3.12177926e-01,  1.67440563e-01],\n        [-1.36486733e+00,  7.83977032e-01, -6.74644768e-01],\n        [ 1.40515006e+00,  9.99483943e-01,  1.67114413e+00],\n        [ 1.42544699e+00, -6.81527555e-01, -2.18596506e+00],\n        [ 1.42320490e+00,  1.07563579e+00, -1.60063016e+00],\n        [ 2.07653570e+00,  6.23711646e-01, -4.24144000e-01],\n        [ 5.14218867e-01,  1.76152730e+00, -3.58589441e-01],\n        [-1.21955991e+00, -2.51055509e-02,  9.96203303e-01],\n        [-5.12784660e-01, -1.10536516e-01,  7.69274771e-01],\n        [-3.69298548e-01,  1.00733435e+00,  1.13687277e+00],\n        [ 1.11001587e+00, -3.30866337e-01,  1.35661209e+00],\n        [ 2.39735264e-02, -9.96456504e-01,  4.56763953e-01]],\n\n       [[-7.94763684e-01, -4.17096853e-01,  5.49790263e-01],\n        [-6.96504056e-01,  4.82257605e-01, -3.30573767e-01],\n        [ 4.11124021e-01, -1.22248225e-01, -4.98830110e-01],\n        [-3.77403021e-01,  3.64484042e-01,  3.72844636e-01],\n        [-1.22133501e-01, -4.49611604e-01, -3.87389630e-01],\n        [-4.17898297e-01, -6.03361130e-01,  3.55201006e-01],\n        [-2.25867319e+00,  1.41222966e+00, -4.70457047e-01],\n        [-9.05309692e-02, -1.76858872e-01, -5.08123577e-01],\n        [ 3.61806750e-01, -1.36169672e+00, -7.27705896e-01],\n        [-9.78688121e-01, -3.31451297e-02,  1.14858016e-01],\n        [ 7.47695327e-01,  7.50423253e-01,  4.02304947e-01],\n        [-7.73913980e-01, -7.46218801e-01,  1.87644708e+00],\n        [-2.77818322e-01, -2.22866178e+00,  6.46523118e-01],\n        [ 5.31582415e-01,  1.31047654e+00, -1.41658843e+00],\n        [ 3.46690595e-01,  6.80484951e-01,  1.86111462e+00],\n        [-3.62897658e+00,  9.96002734e-01, -2.25274786e-01]],\n\n       [[-1.57546091e+00, -4.55100119e-01,  1.35428774e+00],\n        [-6.00746870e-01, -3.89882959e-02,  4.66398120e-01],\n        [ 5.34168661e-01,  3.77757311e-01,  1.22699666e+00],\n        [ 9.66661572e-02,  1.23992240e+00, -5.92969477e-01],\n        [-2.58067995e-01, -1.00050688e+00, -4.92997527e-01],\n        [-2.44878456e-01,  3.39742929e-01,  8.03185701e-01],\n        [-1.54541776e-01,  9.61190283e-01,  6.65675282e-01],\n        [-1.37055862e+00,  7.05989897e-01,  1.09457694e-01],\n        [ 1.49711585e+00,  2.40189791e-01,  1.21694028e+00],\n        [-1.04724661e-01, -8.06483686e-01, -1.14411272e-01],\n        [-3.18776876e-01, -1.35501310e-01,  4.23421830e-01],\n        [-9.88411784e-01,  4.82788950e-01, -4.47910339e-01],\n        [-1.10396254e+00, -1.51587522e+00,  1.93214655e-01],\n        [ 3.99750561e-01,  1.00739157e+00, -5.54041743e-01],\n        [-1.29758701e-01,  1.08521724e+00, -6.99515194e-02],\n        [-2.45304063e-01, -1.24223016e-01,  4.10112053e-01]],\n\n       [[-9.22701538e-01,  1.80368972e+00, -1.71283102e+00],\n        [ 5.82276285e-01, -2.52988124e+00,  9.60701287e-01],\n        [-5.21522403e-01,  3.53837132e-01,  1.00581312e+00],\n        [-2.39266872e-01, -6.38955712e-01,  7.86911309e-01],\n        [ 7.59129345e-01, -9.11083102e-01, -9.42715228e-01],\n        [-8.67362082e-01,  1.08949971e+00, -7.70313442e-01],\n        [ 5.00550866e-01, -1.12562203e+00,  1.31833121e-01],\n        [-6.06069505e-01, -1.19267023e+00,  4.83691216e-01],\n        [-2.52213430e+00,  1.33964670e+00, -2.94284940e-01],\n        [ 6.73781872e-01, -8.75309765e-01,  1.15784812e+00],\n        [-1.72888666e-01, -2.99765859e-02,  1.39793187e-01],\n        [ 1.12306446e-01, -4.17278081e-01,  7.68329084e-01],\n        [ 1.46165836e+00, -7.88740098e-01,  1.08808005e+00],\n        [-1.52099466e+00, -1.64264902e-01, -1.08656728e+00],\n        [ 3.53372276e-01,  4.01673168e-01,  1.62442410e+00],\n        [-7.44260192e-01, -4.83518153e-01, -3.28593045e-01]],\n\n       [[-4.77834970e-01,  1.00186217e+00, -1.77949500e+00],\n        [-1.00408971e+00, -9.39922035e-01, -6.69159651e-01],\n        [-4.42706496e-01,  3.18630010e-01,  1.79561806e+00],\n        [ 1.68410882e-01, -6.89573050e-01,  6.34647369e-01],\n        [ 2.39595398e-01, -1.23246574e+00, -6.56483412e-01],\n        [ 8.86283815e-01, -3.07222509e+00,  6.63102508e-01],\n        [ 2.33172297e+00,  9.41533744e-01,  4.54823315e-01],\n        [-2.97792315e-01,  1.16830993e+00,  1.07849836e+00],\n        [-9.61277187e-01,  2.79442072e-01,  1.30477488e+00],\n        [ 1.28245652e-01,  4.57378805e-01,  7.53342211e-01],\n        [ 7.49582350e-01,  9.69808578e-01,  6.30855262e-01],\n        [ 1.19972277e+00, -1.23795497e+00,  1.07738376e+00],\n        [-5.87708235e-01, -9.67163205e-01,  2.80967426e+00],\n        [ 2.80746043e-01, -1.29579377e+00, -6.11281216e-01],\n        [ 1.23084843e+00, -5.55305660e-01, -6.22898221e-01],\n        [ 1.16467953e+00, -2.97643900e-01, -6.04024410e-01]]],\n      dtype=float32)>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,32,32,3])\n",
    "# 行、列逆序间隔采样\n",
    "x[0,::-2,::-2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 32, 32), dtype=float32, numpy=\narray([[[-0.38865417,  0.26907903,  0.43410304, ...,  1.3125119 ,\n          0.9562874 , -0.6185431 ],\n        [ 0.44053298, -0.2976439 ,  2.6388676 , ..., -0.93992203,\n         -0.6754544 ,  1.0018622 ],\n        [-0.4158239 , -0.6978231 , -2.1026795 , ..., -0.8645744 ,\n          0.66367435,  0.22734646],\n        ...,\n        [-0.7535494 , -1.9197066 ,  2.6120846 , ..., -0.02863584,\n          0.4768737 ,  1.6096514 ],\n        [ 0.48834637,  2.2084682 , -0.15018792, ..., -0.3563923 ,\n         -1.7897338 , -1.7991705 ],\n        [-1.6766123 , -1.4874387 ,  0.25269464, ...,  1.0857197 ,\n         -0.4512363 ,  0.19340745]],\n\n       [[-2.1271038 ,  0.17787853,  0.5725525 , ..., -0.11537506,\n          0.09877823, -1.0606889 ],\n        [-0.06741264, -1.8304873 , -0.9258254 , ..., -1.2561408 ,\n         -0.46134752,  1.6232399 ],\n        [-0.9505743 ,  1.893499  ,  1.6757499 , ...,  0.9129512 ,\n         -1.2663449 ,  0.00658072],\n        ...,\n        [ 0.54888326, -0.6251108 , -0.8025694 , ...,  1.2295495 ,\n         -0.68486   ,  0.24919164],\n        [-0.4397251 ,  1.3611548 , -1.3058542 , ..., -1.9013196 ,\n         -0.34865904, -1.9866322 ],\n        [-1.441417  ,  1.9206321 , -0.8329543 , ...,  0.85816956,\n          1.4044895 ,  0.14645977]],\n\n       [[-1.8836851 , -0.12760457,  1.0338131 , ..., -1.2913526 ,\n          0.8222232 , -1.5497249 ],\n        [-0.29010096,  1.0283756 , -1.2735304 , ...,  1.3423188 ,\n         -1.1819873 , -0.73674494],\n        [-0.67041564, -2.8871713 , -0.7574314 , ..., -2.2917757 ,\n         -0.7868152 ,  3.138899  ],\n        ...,\n        [-0.332977  , -0.8957866 ,  0.5829299 , ...,  0.52293795,\n          0.7515308 ,  0.91608274],\n        [-0.8187882 ,  1.0012285 , -2.2528348 , ..., -0.60804504,\n          1.2832967 ,  1.0473089 ],\n        [ 1.2297137 , -0.03595312, -0.2679272 , ..., -0.11831775,\n          0.1105719 ,  1.0020522 ]],\n\n       [[-1.5482236 , -0.51168734, -0.23644722, ..., -0.66938514,\n          1.1147264 , -2.051984  ],\n        [ 0.99371403,  0.8092166 ,  0.58491385, ..., -0.95584226,\n         -1.4773011 , -0.36944544],\n        [ 1.3369302 , -0.04413425, -0.9082594 , ..., -1.2106758 ,\n         -0.54261583,  0.8663294 ],\n        ...,\n        [ 0.63444895, -0.18070252, -0.91517013, ...,  0.57424265,\n         -1.0666261 , -1.2625911 ],\n        [ 1.5030216 , -1.2419842 , -0.7460404 , ...,  1.779116  ,\n         -0.72769266,  0.37643543],\n        [-0.46825862, -0.13616778, -0.45317352, ...,  0.20254155,\n         -1.2050035 , -0.85653377]]], dtype=float32)>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取 G 通道数据\n",
    "x[:,:,:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 32, 32, 2), dtype=float32, numpy=\narray([[[[-0.38865417,  0.09541716],\n         [ 0.26907903, -0.96798986],\n         [ 0.43410304,  0.85659987],\n         ...,\n         [ 1.3125119 , -1.3867877 ],\n         [ 0.9562874 ,  1.896766  ],\n         [-0.6185431 ,  0.6965917 ]],\n\n        [[ 0.44053298, -0.20525137],\n         [-0.2976439 , -0.6040244 ],\n         [ 2.6388676 , -1.6207676 ],\n         ...,\n         [-0.93992203, -0.66915965],\n         [-0.6754544 ,  1.3710521 ],\n         [ 1.0018622 , -1.779495  ]],\n\n        [[-0.4158239 , -0.3536431 ],\n         [-0.6978231 ,  0.14491245],\n         [-2.1026795 ,  1.187475  ],\n         ...,\n         [-0.8645744 ,  0.6424525 ],\n         [ 0.66367435,  1.4718544 ],\n         [ 0.22734646, -0.06782107]],\n\n        ...,\n\n        [[-0.7535494 , -0.34313807],\n         [-1.9197066 , -0.18565777],\n         [ 2.6120846 ,  0.42992735],\n         ...,\n         [-0.02863584, -0.51061404],\n         [ 0.4768737 , -2.5116677 ],\n         [ 1.6096514 ,  0.21143295]],\n\n        [[ 0.48834637, -2.6703486 ],\n         [ 2.2084682 ,  0.09877031],\n         [-0.15018792,  1.9628097 ],\n         ...,\n         [-0.3563923 , -0.48479128],\n         [-1.7897338 , -0.04491667],\n         [-1.7991705 , -1.5563499 ]],\n\n        [[-1.6766123 , -0.5939453 ],\n         [-1.4874387 ,  1.1680806 ],\n         [ 0.25269464, -0.6257426 ],\n         ...,\n         [ 1.0857197 ,  0.5593758 ],\n         [-0.4512363 ,  0.10208303],\n         [ 0.19340745,  0.52830094]]],\n\n\n       [[[-2.1271038 , -0.458287  ],\n         [ 0.17787853,  0.4061854 ],\n         [ 0.5725525 , -0.044214  ],\n         ...,\n         [-0.11537506,  0.1143399 ],\n         [ 0.09877823,  1.0252581 ],\n         [-1.0606889 ,  0.5689987 ]],\n\n        [[-0.06741264, -2.084647  ],\n         [-1.8304873 ,  0.7240348 ],\n         [-0.9258254 , -1.5267845 ],\n         ...,\n         [-1.2561408 ,  2.000523  ],\n         [-0.46134752, -0.83454025],\n         [ 1.6232399 , -1.0901115 ]],\n\n        [[-0.9505743 , -0.5487562 ],\n         [ 1.893499  ,  0.7479876 ],\n         [ 1.6757499 , -2.067665  ],\n         ...,\n         [ 0.9129512 ,  0.4523242 ],\n         [-1.2663449 ,  0.40370786],\n         [ 0.00658072,  1.1247917 ]],\n\n        ...,\n\n        [[ 0.54888326,  0.35175002],\n         [-0.6251108 , -0.5656735 ],\n         [-0.8025694 , -0.3420058 ],\n         ...,\n         [ 1.2295495 , -0.49143347],\n         [-0.68486   , -0.3938646 ],\n         [ 0.24919164,  0.63061756]],\n\n        [[-0.4397251 ,  0.5060607 ],\n         [ 1.3611548 , -0.27467203],\n         [-1.3058542 , -0.8821341 ],\n         ...,\n         [-1.9013196 ,  0.02570426],\n         [-0.34865904,  0.2897054 ],\n         [-1.9866322 , -0.43927836]],\n\n        [[-1.441417  , -2.2414663 ],\n         [ 1.9206321 ,  0.6092544 ],\n         [-0.8329543 ,  0.81186444],\n         ...,\n         [ 0.85816956,  0.08612759],\n         [ 1.4044895 , -0.58077425],\n         [ 0.14645977, -0.03285845]]]], dtype=float32)>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取第 1~2 张图片的 G/B 通道数据\n",
    "# 高宽维度全部采集\n",
    "x[0:2,...,1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 32, 32, 3), dtype=float32, numpy=\narray([[[[ 6.74123883e-01, -1.88368511e+00, -8.89203072e-01],\n         [ 8.38038027e-02, -1.27604574e-01,  1.58988729e-01],\n         [-4.41695720e-01,  1.03381312e+00, -1.01159029e-01],\n         ...,\n         [-7.16900170e-01, -1.29135263e+00,  1.56265855e+00],\n         [ 1.16747844e+00,  8.22223186e-01, -2.48018071e-01],\n         [ 2.49376774e-01, -1.54972494e+00, -6.98982537e-01]],\n\n        [[-5.15505791e-01, -2.90100962e-01,  1.37397456e+00],\n         [ 1.62653875e+00,  1.02837563e+00,  1.28304017e+00],\n         [ 8.17742586e-01, -1.27353036e+00, -1.29380333e+00],\n         ...,\n         [-2.23944235e+00,  1.34231877e+00, -5.94248891e-01],\n         [-1.26369643e+00, -1.18198729e+00, -2.81738080e-02],\n         [ 4.75413352e-01, -7.36744940e-01, -8.91730845e-01]],\n\n        [[ 1.99938849e-01, -6.70415640e-01,  9.14317548e-01],\n         [-3.14006031e-01, -2.88717127e+00, -2.33328342e-01],\n         [ 7.91864097e-01, -7.57431388e-01,  8.33404303e-01],\n         ...,\n         [ 1.10445201e+00, -2.29177570e+00,  1.41397700e-01],\n         [ 6.61541522e-01, -7.86815226e-01,  3.41089249e-01],\n         [ 1.28044140e+00,  3.13889909e+00, -3.37034553e-01]],\n\n        ...,\n\n        [[-6.76532328e-01, -3.32976997e-01,  1.13113987e+00],\n         [-2.15178037e+00, -8.95786583e-01, -1.26274991e+00],\n         [-3.65310423e-02,  5.82929909e-01, -1.37371659e-01],\n         ...,\n         [-2.94706678e+00,  5.22937953e-01,  8.04446042e-02],\n         [-1.13250697e+00,  7.51530826e-01,  1.43067610e+00],\n         [ 2.08194804e+00,  9.16082740e-01,  1.37472615e-01]],\n\n        [[ 2.60845013e-02, -8.18788171e-01,  7.58701265e-01],\n         [-1.20919609e+00,  1.00122845e+00,  5.97506762e-01],\n         [ 1.13658883e-01, -2.25283480e+00, -1.01327365e-02],\n         ...,\n         [ 2.09335566e+00, -6.08045042e-01, -5.57661057e-01],\n         [-5.15182137e-01,  1.28329670e+00,  1.04593050e+00],\n         [-7.18316376e-01,  1.04730892e+00,  2.98322830e-03]],\n\n        [[ 9.42163169e-01,  1.22971368e+00,  6.26068473e-01],\n         [ 1.48261881e+00, -3.59531157e-02, -8.75833094e-01],\n         [ 9.28269148e-01, -2.67927200e-01, -5.33923090e-01],\n         ...,\n         [ 1.19961873e-01, -1.18317746e-01,  1.11980379e+00],\n         [ 5.93705177e-01,  1.10571899e-01,  2.68238097e-01],\n         [ 1.30792081e+00,  1.00205219e+00, -4.29300487e-01]]],\n\n\n       [[[ 4.47613624e-04, -1.54822361e+00, -7.40464926e-02],\n         [ 8.18368122e-02, -5.11687338e-01, -6.84324324e-01],\n         [ 2.01384258e-02, -2.36447215e-01, -8.64046693e-01],\n         ...,\n         [-1.36924493e+00, -6.69385135e-01, -8.99548352e-01],\n         [ 1.62134126e-01,  1.11472642e+00, -1.94836576e-02],\n         [ 8.44385624e-02, -2.05198407e+00, -8.86822790e-02]],\n\n        [[ 3.73829603e-01,  9.93714035e-01, -9.90193009e-01],\n         [-8.01198423e-01,  8.09216619e-01,  3.87230873e-01],\n         [ 1.44021964e+00,  5.84913850e-01,  1.36116207e+00],\n         ...,\n         [-1.38699400e+00, -9.55842257e-01,  1.58734024e+00],\n         [ 3.43991011e-01, -1.47730112e+00, -3.32765013e-01],\n         [ 1.52731264e+00, -3.69445443e-01, -9.67378080e-01]],\n\n        [[ 9.34277654e-01,  1.33693016e+00,  9.97579157e-01],\n         [ 1.61205018e+00, -4.41342480e-02, -2.26055324e-01],\n         [-8.78753424e-01, -9.08259392e-01,  8.74866784e-01],\n         ...,\n         [ 1.33671892e+00, -1.21067584e+00, -1.02042079e+00],\n         [-1.05024850e+00, -5.42615831e-01,  2.43301734e-01],\n         [-1.22167313e+00,  8.66329372e-01,  8.29756737e-01]],\n\n        ...,\n\n        [[-7.89559841e-01,  6.34448946e-01,  2.00538158e+00],\n         [-1.36779606e+00, -1.80702522e-01,  4.19214457e-01],\n         [ 1.61699235e+00, -9.15170133e-01, -1.97542846e-01],\n         ...,\n         [-1.43394589e+00,  5.74242651e-01,  6.94455564e-01],\n         [-2.75501937e-01, -1.06662607e+00,  3.96460779e-02],\n         [ 1.36953878e+00, -1.26259112e+00, -6.04714274e-01]],\n\n        [[-7.10881770e-01,  1.50302160e+00,  3.13761123e-02],\n         [-1.11554849e+00, -1.24198425e+00, -7.54298866e-01],\n         [ 1.51278126e+00, -7.46040404e-01, -1.69679296e+00],\n         ...,\n         [-8.15785527e-01,  1.77911603e+00, -5.64076658e-03],\n         [ 5.31468809e-01, -7.27692664e-01, -1.85736525e+00],\n         [-3.10446072e+00,  3.76435429e-01,  4.23945002e-02]],\n\n        [[ 1.09711692e-01, -4.68258619e-01, -2.64915347e-01],\n         [-1.35383070e+00, -1.36167780e-01,  1.36342895e+00],\n         [ 1.68717337e+00, -4.53173518e-01, -1.54652923e-01],\n         ...,\n         [-4.87826496e-01,  2.02541545e-01,  1.78301525e+00],\n         [-1.05204475e+00, -1.20500350e+00, -6.39765739e-01],\n         [ 2.03632760e+00, -8.56533766e-01,  7.81275749e-01]]]],\n      dtype=float32)>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取最后 2 张图片\n",
    "# 高、宽、通道维度全部采集，等价于 x[2:]\n",
    "x[2:,...] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 32, 32, 2), dtype=float32, numpy=\narray([[[[ 1.19780111e+00, -3.88654172e-01],\n         [ 1.14581382e+00,  2.69079030e-01],\n         [-2.77974272e+00,  4.34103042e-01],\n         ...,\n         [ 4.63154674e-01,  1.31251192e+00],\n         [-1.61533272e+00,  9.56287384e-01],\n         [ 2.03971431e-01, -6.18543088e-01]],\n\n        [[-1.49999931e-01,  4.40532982e-01],\n         [ 1.16467953e+00, -2.97643900e-01],\n         [-5.78408480e-01,  2.63886762e+00],\n         ...,\n         [-1.00408971e+00, -9.39922035e-01],\n         [-6.99904919e-01, -6.75454378e-01],\n         [-4.77834970e-01,  1.00186217e+00]],\n\n        [[-2.11601400e+00, -4.15823907e-01],\n         [-1.28382933e+00, -6.97823107e-01],\n         [-1.24438286e+00, -2.10267949e+00],\n         ...,\n         [-1.48504436e+00, -8.64574373e-01],\n         [-4.81069267e-01,  6.63674355e-01],\n         [ 2.36261353e-01,  2.27346465e-01]],\n\n        ...,\n\n        [[ 3.57793421e-02, -7.53549397e-01],\n         [-2.12307662e-01, -1.91970658e+00],\n         [ 5.64808786e-01,  2.61208463e+00],\n         ...,\n         [ 8.56684670e-02, -2.86358353e-02],\n         [ 2.38730926e-02,  4.76873696e-01],\n         [ 2.29291964e+00,  1.60965145e+00]],\n\n        [[-8.21604729e-01,  4.88346368e-01],\n         [ 3.82990725e-02,  2.20846820e+00],\n         [ 3.77793193e-01, -1.50187925e-01],\n         ...,\n         [-1.34853864e+00, -3.56392294e-01],\n         [-2.14692235e+00, -1.78973377e+00],\n         [ 4.11962897e-01, -1.79917049e+00]],\n\n        [[ 5.50423097e-03, -1.67661226e+00],\n         [ 1.62686408e+00, -1.48743868e+00],\n         [-5.93195140e-01,  2.52694637e-01],\n         ...,\n         [-2.32661462e+00,  1.08571970e+00],\n         [-5.09012759e-01, -4.51236308e-01],\n         [-6.09962761e-01,  1.93407446e-01]]],\n\n\n       [[[ 1.60140085e+00, -2.12710381e+00],\n         [ 6.90486133e-01,  1.77878529e-01],\n         [ 5.57245791e-01,  5.72552502e-01],\n         ...,\n         [ 1.18150795e+00, -1.15375064e-01],\n         [-2.46511030e+00,  9.87782329e-02],\n         [-6.58204734e-01, -1.06068885e+00]],\n\n        [[ 1.23570895e+00, -6.74126372e-02],\n         [-8.66269469e-01, -1.83048725e+00],\n         [-4.89664823e-01, -9.25825417e-01],\n         ...,\n         [ 2.22237778e+00, -1.25614083e+00],\n         [ 9.87829387e-01, -4.61347520e-01],\n         [ 7.79775500e-01,  1.62323987e+00]],\n\n        [[-5.76833606e-01, -9.50574279e-01],\n         [-1.00079727e+00,  1.89349902e+00],\n         [ 1.07150280e+00,  1.67574990e+00],\n         ...,\n         [-4.85427648e-01,  9.12951171e-01],\n         [-3.51156622e-01, -1.26634490e+00],\n         [ 2.64205337e-01,  6.58072345e-03]],\n\n        ...,\n\n        [[ 1.15718436e+00,  5.48883259e-01],\n         [-4.17351991e-01, -6.25110805e-01],\n         [ 1.74596727e+00, -8.02569389e-01],\n         ...,\n         [-2.55833209e-01,  1.22954953e+00],\n         [ 3.50676328e-01, -6.84859991e-01],\n         [ 1.09021866e+00,  2.49191642e-01]],\n\n        [[ 1.06129122e+00, -4.39725101e-01],\n         [-3.12004834e-02,  1.36115479e+00],\n         [-1.26250637e+00, -1.30585420e+00],\n         ...,\n         [-1.21074331e+00, -1.90131962e+00],\n         [ 5.30233264e-01, -3.48659039e-01],\n         [-1.53394735e+00, -1.98663223e+00]],\n\n        [[-1.77158284e+00, -1.44141698e+00],\n         [ 3.24392378e-01,  1.92063212e+00],\n         [-9.82580900e-01, -8.32954288e-01],\n         ...,\n         [ 5.34562588e-01,  8.58169556e-01],\n         [ 8.88075456e-02,  1.40448952e+00],\n         [ 4.00518805e-01,  1.46459773e-01]]],\n\n\n       [[[ 6.74123883e-01, -1.88368511e+00],\n         [ 8.38038027e-02, -1.27604574e-01],\n         [-4.41695720e-01,  1.03381312e+00],\n         ...,\n         [-7.16900170e-01, -1.29135263e+00],\n         [ 1.16747844e+00,  8.22223186e-01],\n         [ 2.49376774e-01, -1.54972494e+00]],\n\n        [[-5.15505791e-01, -2.90100962e-01],\n         [ 1.62653875e+00,  1.02837563e+00],\n         [ 8.17742586e-01, -1.27353036e+00],\n         ...,\n         [-2.23944235e+00,  1.34231877e+00],\n         [-1.26369643e+00, -1.18198729e+00],\n         [ 4.75413352e-01, -7.36744940e-01]],\n\n        [[ 1.99938849e-01, -6.70415640e-01],\n         [-3.14006031e-01, -2.88717127e+00],\n         [ 7.91864097e-01, -7.57431388e-01],\n         ...,\n         [ 1.10445201e+00, -2.29177570e+00],\n         [ 6.61541522e-01, -7.86815226e-01],\n         [ 1.28044140e+00,  3.13889909e+00]],\n\n        ...,\n\n        [[-6.76532328e-01, -3.32976997e-01],\n         [-2.15178037e+00, -8.95786583e-01],\n         [-3.65310423e-02,  5.82929909e-01],\n         ...,\n         [-2.94706678e+00,  5.22937953e-01],\n         [-1.13250697e+00,  7.51530826e-01],\n         [ 2.08194804e+00,  9.16082740e-01]],\n\n        [[ 2.60845013e-02, -8.18788171e-01],\n         [-1.20919609e+00,  1.00122845e+00],\n         [ 1.13658883e-01, -2.25283480e+00],\n         ...,\n         [ 2.09335566e+00, -6.08045042e-01],\n         [-5.15182137e-01,  1.28329670e+00],\n         [-7.18316376e-01,  1.04730892e+00]],\n\n        [[ 9.42163169e-01,  1.22971368e+00],\n         [ 1.48261881e+00, -3.59531157e-02],\n         [ 9.28269148e-01, -2.67927200e-01],\n         ...,\n         [ 1.19961873e-01, -1.18317746e-01],\n         [ 5.93705177e-01,  1.10571899e-01],\n         [ 1.30792081e+00,  1.00205219e+00]]],\n\n\n       [[[ 4.47613624e-04, -1.54822361e+00],\n         [ 8.18368122e-02, -5.11687338e-01],\n         [ 2.01384258e-02, -2.36447215e-01],\n         ...,\n         [-1.36924493e+00, -6.69385135e-01],\n         [ 1.62134126e-01,  1.11472642e+00],\n         [ 8.44385624e-02, -2.05198407e+00]],\n\n        [[ 3.73829603e-01,  9.93714035e-01],\n         [-8.01198423e-01,  8.09216619e-01],\n         [ 1.44021964e+00,  5.84913850e-01],\n         ...,\n         [-1.38699400e+00, -9.55842257e-01],\n         [ 3.43991011e-01, -1.47730112e+00],\n         [ 1.52731264e+00, -3.69445443e-01]],\n\n        [[ 9.34277654e-01,  1.33693016e+00],\n         [ 1.61205018e+00, -4.41342480e-02],\n         [-8.78753424e-01, -9.08259392e-01],\n         ...,\n         [ 1.33671892e+00, -1.21067584e+00],\n         [-1.05024850e+00, -5.42615831e-01],\n         [-1.22167313e+00,  8.66329372e-01]],\n\n        ...,\n\n        [[-7.89559841e-01,  6.34448946e-01],\n         [-1.36779606e+00, -1.80702522e-01],\n         [ 1.61699235e+00, -9.15170133e-01],\n         ...,\n         [-1.43394589e+00,  5.74242651e-01],\n         [-2.75501937e-01, -1.06662607e+00],\n         [ 1.36953878e+00, -1.26259112e+00]],\n\n        [[-7.10881770e-01,  1.50302160e+00],\n         [-1.11554849e+00, -1.24198425e+00],\n         [ 1.51278126e+00, -7.46040404e-01],\n         ...,\n         [-8.15785527e-01,  1.77911603e+00],\n         [ 5.31468809e-01, -7.27692664e-01],\n         [-3.10446072e+00,  3.76435429e-01]],\n\n        [[ 1.09711692e-01, -4.68258619e-01],\n         [-1.35383070e+00, -1.36167780e-01],\n         [ 1.68717337e+00, -4.53173518e-01],\n         ...,\n         [-4.87826496e-01,  2.02541545e-01],\n         [-1.05204475e+00, -1.20500350e+00],\n         [ 2.03632760e+00, -8.56533766e-01]]]], dtype=float32)>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取 R/G 通道数据\n",
    "# 所有样本，所有高、宽的前 2 个通道\n",
    "x[...,:2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 维度变换\n",
    "\n",
    "### 改变视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4, 4, 3), dtype=int32, numpy=\narray([[[[ 0,  1,  2],\n         [ 3,  4,  5],\n         [ 6,  7,  8],\n         [ 9, 10, 11]],\n\n        [[12, 13, 14],\n         [15, 16, 17],\n         [18, 19, 20],\n         [21, 22, 23]],\n\n        [[24, 25, 26],\n         [27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44],\n         [45, 46, 47]]],\n\n\n       [[[48, 49, 50],\n         [51, 52, 53],\n         [54, 55, 56],\n         [57, 58, 59]],\n\n        [[60, 61, 62],\n         [63, 64, 65],\n         [66, 67, 68],\n         [69, 70, 71]],\n\n        [[72, 73, 74],\n         [75, 76, 77],\n         [78, 79, 80],\n         [81, 82, 83]],\n\n        [[84, 85, 86],\n         [87, 88, 89],\n         [90, 91, 92],\n         [93, 94, 95]]]])>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成向量\n",
    "x=tf.range(96)\n",
    "# 改变 x 的视图，获得 4D 张量，存储并未改变\n",
    "x=tf.reshape(x,[2,4,4,3]) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变视图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通过 tf.range()模拟生成一个向量数据，并通过 tf.reshape 视图改变函数产生不同的视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4, 4, 3), dtype=int32, numpy=\narray([[[[ 0,  1,  2],\n         [ 3,  4,  5],\n         [ 6,  7,  8],\n         [ 9, 10, 11]],\n\n        [[12, 13, 14],\n         [15, 16, 17],\n         [18, 19, 20],\n         [21, 22, 23]],\n\n        [[24, 25, 26],\n         [27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44],\n         [45, 46, 47]]],\n\n\n       [[[48, 49, 50],\n         [51, 52, 53],\n         [54, 55, 56],\n         [57, 58, 59]],\n\n        [[60, 61, 62],\n         [63, 64, 65],\n         [66, 67, 68],\n         [69, 70, 71]],\n\n        [[72, 73, 74],\n         [75, 76, 77],\n         [78, 79, 80],\n         [81, 82, 83]],\n\n        [[84, 85, 86],\n         [87, 88, 89],\n         [90, 91, 92],\n         [93, 94, 95]]]])>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成向量\n",
    "x = tf.range(96) \n",
    "# 改变 x 的视图，获得 4D 张量，存储并未改变\n",
    "x = tf.reshape(x,[2,4,4,3]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(4, TensorShape([2, 4, 4, 3]))"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取张量的维度数和形状列表\n",
    "x.ndim,x.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.reshape(x, new_shape)，可以将张量的视图任意地合法改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 48), dtype=int32, numpy=\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n       [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]])>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,[2,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4, 12), dtype=int32, numpy=\narray([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]],\n\n       [[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71],\n        [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83],\n        [84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]]])>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,[2,4,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 16, 3), dtype=int32, numpy=\narray([[[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11],\n        [12, 13, 14],\n        [15, 16, 17],\n        [18, 19, 20],\n        [21, 22, 23],\n        [24, 25, 26],\n        [27, 28, 29],\n        [30, 31, 32],\n        [33, 34, 35],\n        [36, 37, 38],\n        [39, 40, 41],\n        [42, 43, 44],\n        [45, 46, 47]],\n\n       [[48, 49, 50],\n        [51, 52, 53],\n        [54, 55, 56],\n        [57, 58, 59],\n        [60, 61, 62],\n        [63, 64, 65],\n        [66, 67, 68],\n        [69, 70, 71],\n        [72, 73, 74],\n        [75, 76, 77],\n        [78, 79, 80],\n        [81, 82, 83],\n        [84, 85, 86],\n        [87, 88, 89],\n        [90, 91, 92],\n        [93, 94, 95]]])>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,[2,-1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增、删维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28), dtype=int32, numpy=\narray([[9, 9, 1, 9, 8, 0, 0, 4, 5, 7, 4, 9, 1, 7, 0, 1, 2, 3, 4, 9, 3, 8,\n        4, 0, 0, 2, 1, 1],\n       [5, 7, 5, 2, 5, 9, 8, 5, 8, 3, 7, 9, 7, 9, 9, 1, 3, 3, 8, 0, 8, 4,\n        1, 2, 3, 5, 8, 1],\n       [3, 3, 1, 7, 6, 4, 6, 2, 8, 0, 4, 6, 1, 9, 7, 3, 8, 1, 1, 3, 6, 5,\n        3, 9, 3, 2, 4, 2],\n       [6, 9, 9, 1, 2, 7, 7, 8, 8, 3, 1, 8, 4, 1, 7, 4, 6, 5, 5, 8, 4, 2,\n        3, 6, 6, 4, 1, 8],\n       [8, 0, 5, 5, 6, 6, 8, 6, 6, 0, 3, 2, 0, 9, 2, 1, 5, 6, 5, 3, 8, 4,\n        0, 5, 8, 6, 7, 8],\n       [2, 1, 4, 1, 4, 1, 2, 5, 1, 5, 0, 3, 8, 4, 0, 7, 3, 9, 3, 5, 3, 8,\n        9, 9, 0, 1, 6, 4],\n       [3, 4, 6, 8, 5, 9, 9, 8, 0, 2, 2, 3, 8, 9, 3, 3, 8, 7, 0, 0, 7, 0,\n        1, 7, 3, 0, 0, 0],\n       [8, 8, 6, 8, 0, 7, 4, 1, 2, 9, 2, 7, 9, 0, 2, 3, 4, 9, 9, 5, 4, 9,\n        1, 9, 8, 1, 5, 7],\n       [7, 1, 7, 9, 3, 9, 3, 9, 1, 0, 8, 6, 6, 7, 5, 5, 5, 9, 8, 7, 2, 2,\n        5, 7, 5, 8, 9, 5],\n       [8, 2, 8, 5, 4, 9, 0, 9, 3, 9, 9, 9, 9, 1, 5, 0, 5, 7, 9, 4, 4, 2,\n        0, 3, 0, 1, 7, 4],\n       [5, 4, 4, 0, 1, 0, 6, 4, 5, 5, 2, 6, 6, 7, 2, 3, 0, 5, 0, 9, 7, 7,\n        7, 0, 2, 4, 7, 8],\n       [5, 0, 8, 3, 8, 3, 4, 5, 0, 9, 2, 6, 5, 2, 1, 5, 8, 3, 8, 3, 3, 7,\n        9, 7, 9, 3, 0, 2],\n       [2, 0, 8, 3, 6, 6, 1, 2, 4, 6, 3, 5, 0, 9, 3, 1, 6, 7, 9, 4, 4, 2,\n        2, 9, 4, 4, 8, 8],\n       [5, 2, 9, 9, 9, 3, 3, 8, 1, 4, 0, 3, 1, 6, 0, 2, 7, 7, 5, 9, 5, 6,\n        5, 4, 6, 3, 2, 2],\n       [1, 2, 2, 6, 0, 2, 7, 5, 5, 9, 1, 4, 0, 9, 9, 2, 1, 7, 6, 1, 0, 1,\n        5, 4, 5, 4, 1, 7],\n       [9, 6, 9, 8, 4, 8, 1, 6, 5, 4, 2, 2, 6, 7, 1, 6, 2, 0, 8, 5, 4, 4,\n        1, 4, 4, 1, 4, 1],\n       [1, 0, 8, 5, 4, 3, 6, 4, 4, 1, 5, 8, 4, 4, 0, 8, 0, 7, 9, 1, 0, 0,\n        0, 3, 9, 4, 5, 1],\n       [2, 5, 9, 9, 4, 6, 1, 3, 3, 3, 7, 4, 1, 6, 6, 6, 2, 0, 5, 1, 0, 7,\n        9, 5, 6, 4, 1, 2],\n       [8, 3, 1, 8, 3, 3, 3, 5, 0, 6, 1, 6, 8, 5, 2, 5, 9, 9, 5, 9, 0, 8,\n        5, 1, 9, 9, 4, 9],\n       [0, 2, 6, 3, 5, 8, 4, 2, 4, 9, 1, 4, 6, 3, 4, 6, 1, 5, 5, 8, 7, 7,\n        0, 7, 5, 7, 2, 4],\n       [4, 3, 3, 6, 6, 5, 2, 7, 0, 4, 9, 0, 3, 8, 4, 4, 4, 9, 9, 2, 9, 2,\n        8, 5, 5, 9, 7, 9],\n       [6, 4, 1, 4, 3, 5, 5, 5, 8, 0, 3, 5, 8, 9, 0, 4, 8, 5, 0, 9, 0, 5,\n        8, 6, 5, 1, 3, 8],\n       [3, 5, 1, 9, 5, 1, 0, 5, 7, 4, 4, 3, 1, 0, 3, 8, 5, 8, 2, 9, 8, 3,\n        6, 2, 9, 9, 5, 5],\n       [8, 4, 3, 6, 9, 5, 1, 9, 2, 3, 7, 9, 7, 4, 9, 6, 0, 7, 9, 7, 7, 8,\n        9, 5, 8, 0, 0, 8],\n       [6, 2, 5, 4, 4, 6, 6, 7, 2, 5, 0, 8, 0, 3, 0, 5, 9, 8, 0, 5, 6, 3,\n        1, 0, 0, 8, 2, 2],\n       [1, 7, 3, 3, 2, 8, 4, 8, 5, 9, 5, 6, 9, 4, 4, 2, 2, 6, 6, 4, 3, 6,\n        3, 4, 5, 9, 7, 7],\n       [9, 7, 5, 0, 1, 4, 1, 6, 0, 6, 5, 3, 7, 0, 4, 4, 7, 0, 1, 0, 8, 0,\n        9, 6, 0, 3, 4, 5],\n       [0, 5, 1, 9, 2, 7, 4, 6, 2, 3, 0, 2, 4, 9, 9, 7, 5, 4, 0, 8, 4, 7,\n        5, 9, 2, 1, 3, 0]])>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 产生矩阵\n",
    "x = tf.random.uniform([28,28],maxval=10,dtype=tf.int32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.expand_dims(x, axis)可在指定的 axis 轴前可以插入一个新的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28, 1), dtype=int32, numpy=\narray([[[9],\n        [9],\n        [1],\n        [9],\n        [8],\n        [0],\n        [0],\n        [4],\n        [5],\n        [7],\n        [4],\n        [9],\n        [1],\n        [7],\n        [0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [9],\n        [3],\n        [8],\n        [4],\n        [0],\n        [0],\n        [2],\n        [1],\n        [1]],\n\n       [[5],\n        [7],\n        [5],\n        [2],\n        [5],\n        [9],\n        [8],\n        [5],\n        [8],\n        [3],\n        [7],\n        [9],\n        [7],\n        [9],\n        [9],\n        [1],\n        [3],\n        [3],\n        [8],\n        [0],\n        [8],\n        [4],\n        [1],\n        [2],\n        [3],\n        [5],\n        [8],\n        [1]],\n\n       [[3],\n        [3],\n        [1],\n        [7],\n        [6],\n        [4],\n        [6],\n        [2],\n        [8],\n        [0],\n        [4],\n        [6],\n        [1],\n        [9],\n        [7],\n        [3],\n        [8],\n        [1],\n        [1],\n        [3],\n        [6],\n        [5],\n        [3],\n        [9],\n        [3],\n        [2],\n        [4],\n        [2]],\n\n       [[6],\n        [9],\n        [9],\n        [1],\n        [2],\n        [7],\n        [7],\n        [8],\n        [8],\n        [3],\n        [1],\n        [8],\n        [4],\n        [1],\n        [7],\n        [4],\n        [6],\n        [5],\n        [5],\n        [8],\n        [4],\n        [2],\n        [3],\n        [6],\n        [6],\n        [4],\n        [1],\n        [8]],\n\n       [[8],\n        [0],\n        [5],\n        [5],\n        [6],\n        [6],\n        [8],\n        [6],\n        [6],\n        [0],\n        [3],\n        [2],\n        [0],\n        [9],\n        [2],\n        [1],\n        [5],\n        [6],\n        [5],\n        [3],\n        [8],\n        [4],\n        [0],\n        [5],\n        [8],\n        [6],\n        [7],\n        [8]],\n\n       [[2],\n        [1],\n        [4],\n        [1],\n        [4],\n        [1],\n        [2],\n        [5],\n        [1],\n        [5],\n        [0],\n        [3],\n        [8],\n        [4],\n        [0],\n        [7],\n        [3],\n        [9],\n        [3],\n        [5],\n        [3],\n        [8],\n        [9],\n        [9],\n        [0],\n        [1],\n        [6],\n        [4]],\n\n       [[3],\n        [4],\n        [6],\n        [8],\n        [5],\n        [9],\n        [9],\n        [8],\n        [0],\n        [2],\n        [2],\n        [3],\n        [8],\n        [9],\n        [3],\n        [3],\n        [8],\n        [7],\n        [0],\n        [0],\n        [7],\n        [0],\n        [1],\n        [7],\n        [3],\n        [0],\n        [0],\n        [0]],\n\n       [[8],\n        [8],\n        [6],\n        [8],\n        [0],\n        [7],\n        [4],\n        [1],\n        [2],\n        [9],\n        [2],\n        [7],\n        [9],\n        [0],\n        [2],\n        [3],\n        [4],\n        [9],\n        [9],\n        [5],\n        [4],\n        [9],\n        [1],\n        [9],\n        [8],\n        [1],\n        [5],\n        [7]],\n\n       [[7],\n        [1],\n        [7],\n        [9],\n        [3],\n        [9],\n        [3],\n        [9],\n        [1],\n        [0],\n        [8],\n        [6],\n        [6],\n        [7],\n        [5],\n        [5],\n        [5],\n        [9],\n        [8],\n        [7],\n        [2],\n        [2],\n        [5],\n        [7],\n        [5],\n        [8],\n        [9],\n        [5]],\n\n       [[8],\n        [2],\n        [8],\n        [5],\n        [4],\n        [9],\n        [0],\n        [9],\n        [3],\n        [9],\n        [9],\n        [9],\n        [9],\n        [1],\n        [5],\n        [0],\n        [5],\n        [7],\n        [9],\n        [4],\n        [4],\n        [2],\n        [0],\n        [3],\n        [0],\n        [1],\n        [7],\n        [4]],\n\n       [[5],\n        [4],\n        [4],\n        [0],\n        [1],\n        [0],\n        [6],\n        [4],\n        [5],\n        [5],\n        [2],\n        [6],\n        [6],\n        [7],\n        [2],\n        [3],\n        [0],\n        [5],\n        [0],\n        [9],\n        [7],\n        [7],\n        [7],\n        [0],\n        [2],\n        [4],\n        [7],\n        [8]],\n\n       [[5],\n        [0],\n        [8],\n        [3],\n        [8],\n        [3],\n        [4],\n        [5],\n        [0],\n        [9],\n        [2],\n        [6],\n        [5],\n        [2],\n        [1],\n        [5],\n        [8],\n        [3],\n        [8],\n        [3],\n        [3],\n        [7],\n        [9],\n        [7],\n        [9],\n        [3],\n        [0],\n        [2]],\n\n       [[2],\n        [0],\n        [8],\n        [3],\n        [6],\n        [6],\n        [1],\n        [2],\n        [4],\n        [6],\n        [3],\n        [5],\n        [0],\n        [9],\n        [3],\n        [1],\n        [6],\n        [7],\n        [9],\n        [4],\n        [4],\n        [2],\n        [2],\n        [9],\n        [4],\n        [4],\n        [8],\n        [8]],\n\n       [[5],\n        [2],\n        [9],\n        [9],\n        [9],\n        [3],\n        [3],\n        [8],\n        [1],\n        [4],\n        [0],\n        [3],\n        [1],\n        [6],\n        [0],\n        [2],\n        [7],\n        [7],\n        [5],\n        [9],\n        [5],\n        [6],\n        [5],\n        [4],\n        [6],\n        [3],\n        [2],\n        [2]],\n\n       [[1],\n        [2],\n        [2],\n        [6],\n        [0],\n        [2],\n        [7],\n        [5],\n        [5],\n        [9],\n        [1],\n        [4],\n        [0],\n        [9],\n        [9],\n        [2],\n        [1],\n        [7],\n        [6],\n        [1],\n        [0],\n        [1],\n        [5],\n        [4],\n        [5],\n        [4],\n        [1],\n        [7]],\n\n       [[9],\n        [6],\n        [9],\n        [8],\n        [4],\n        [8],\n        [1],\n        [6],\n        [5],\n        [4],\n        [2],\n        [2],\n        [6],\n        [7],\n        [1],\n        [6],\n        [2],\n        [0],\n        [8],\n        [5],\n        [4],\n        [4],\n        [1],\n        [4],\n        [4],\n        [1],\n        [4],\n        [1]],\n\n       [[1],\n        [0],\n        [8],\n        [5],\n        [4],\n        [3],\n        [6],\n        [4],\n        [4],\n        [1],\n        [5],\n        [8],\n        [4],\n        [4],\n        [0],\n        [8],\n        [0],\n        [7],\n        [9],\n        [1],\n        [0],\n        [0],\n        [0],\n        [3],\n        [9],\n        [4],\n        [5],\n        [1]],\n\n       [[2],\n        [5],\n        [9],\n        [9],\n        [4],\n        [6],\n        [1],\n        [3],\n        [3],\n        [3],\n        [7],\n        [4],\n        [1],\n        [6],\n        [6],\n        [6],\n        [2],\n        [0],\n        [5],\n        [1],\n        [0],\n        [7],\n        [9],\n        [5],\n        [6],\n        [4],\n        [1],\n        [2]],\n\n       [[8],\n        [3],\n        [1],\n        [8],\n        [3],\n        [3],\n        [3],\n        [5],\n        [0],\n        [6],\n        [1],\n        [6],\n        [8],\n        [5],\n        [2],\n        [5],\n        [9],\n        [9],\n        [5],\n        [9],\n        [0],\n        [8],\n        [5],\n        [1],\n        [9],\n        [9],\n        [4],\n        [9]],\n\n       [[0],\n        [2],\n        [6],\n        [3],\n        [5],\n        [8],\n        [4],\n        [2],\n        [4],\n        [9],\n        [1],\n        [4],\n        [6],\n        [3],\n        [4],\n        [6],\n        [1],\n        [5],\n        [5],\n        [8],\n        [7],\n        [7],\n        [0],\n        [7],\n        [5],\n        [7],\n        [2],\n        [4]],\n\n       [[4],\n        [3],\n        [3],\n        [6],\n        [6],\n        [5],\n        [2],\n        [7],\n        [0],\n        [4],\n        [9],\n        [0],\n        [3],\n        [8],\n        [4],\n        [4],\n        [4],\n        [9],\n        [9],\n        [2],\n        [9],\n        [2],\n        [8],\n        [5],\n        [5],\n        [9],\n        [7],\n        [9]],\n\n       [[6],\n        [4],\n        [1],\n        [4],\n        [3],\n        [5],\n        [5],\n        [5],\n        [8],\n        [0],\n        [3],\n        [5],\n        [8],\n        [9],\n        [0],\n        [4],\n        [8],\n        [5],\n        [0],\n        [9],\n        [0],\n        [5],\n        [8],\n        [6],\n        [5],\n        [1],\n        [3],\n        [8]],\n\n       [[3],\n        [5],\n        [1],\n        [9],\n        [5],\n        [1],\n        [0],\n        [5],\n        [7],\n        [4],\n        [4],\n        [3],\n        [1],\n        [0],\n        [3],\n        [8],\n        [5],\n        [8],\n        [2],\n        [9],\n        [8],\n        [3],\n        [6],\n        [2],\n        [9],\n        [9],\n        [5],\n        [5]],\n\n       [[8],\n        [4],\n        [3],\n        [6],\n        [9],\n        [5],\n        [1],\n        [9],\n        [2],\n        [3],\n        [7],\n        [9],\n        [7],\n        [4],\n        [9],\n        [6],\n        [0],\n        [7],\n        [9],\n        [7],\n        [7],\n        [8],\n        [9],\n        [5],\n        [8],\n        [0],\n        [0],\n        [8]],\n\n       [[6],\n        [2],\n        [5],\n        [4],\n        [4],\n        [6],\n        [6],\n        [7],\n        [2],\n        [5],\n        [0],\n        [8],\n        [0],\n        [3],\n        [0],\n        [5],\n        [9],\n        [8],\n        [0],\n        [5],\n        [6],\n        [3],\n        [1],\n        [0],\n        [0],\n        [8],\n        [2],\n        [2]],\n\n       [[1],\n        [7],\n        [3],\n        [3],\n        [2],\n        [8],\n        [4],\n        [8],\n        [5],\n        [9],\n        [5],\n        [6],\n        [9],\n        [4],\n        [4],\n        [2],\n        [2],\n        [6],\n        [6],\n        [4],\n        [3],\n        [6],\n        [3],\n        [4],\n        [5],\n        [9],\n        [7],\n        [7]],\n\n       [[9],\n        [7],\n        [5],\n        [0],\n        [1],\n        [4],\n        [1],\n        [6],\n        [0],\n        [6],\n        [5],\n        [3],\n        [7],\n        [0],\n        [4],\n        [4],\n        [7],\n        [0],\n        [1],\n        [0],\n        [8],\n        [0],\n        [9],\n        [6],\n        [0],\n        [3],\n        [4],\n        [5]],\n\n       [[0],\n        [5],\n        [1],\n        [9],\n        [2],\n        [7],\n        [4],\n        [6],\n        [2],\n        [3],\n        [0],\n        [2],\n        [4],\n        [9],\n        [9],\n        [7],\n        [5],\n        [4],\n        [0],\n        [8],\n        [4],\n        [7],\n        [5],\n        [9],\n        [2],\n        [1],\n        [3],\n        [0]]])>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis=2 表示宽维度后面的一个维度\n",
    "x = tf.expand_dims(x,axis=2) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 28, 28, 1), dtype=int32, numpy=\narray([[[[9],\n         [9],\n         [1],\n         [9],\n         [8],\n         [0],\n         [0],\n         [4],\n         [5],\n         [7],\n         [4],\n         [9],\n         [1],\n         [7],\n         [0],\n         [1],\n         [2],\n         [3],\n         [4],\n         [9],\n         [3],\n         [8],\n         [4],\n         [0],\n         [0],\n         [2],\n         [1],\n         [1]],\n\n        [[5],\n         [7],\n         [5],\n         [2],\n         [5],\n         [9],\n         [8],\n         [5],\n         [8],\n         [3],\n         [7],\n         [9],\n         [7],\n         [9],\n         [9],\n         [1],\n         [3],\n         [3],\n         [8],\n         [0],\n         [8],\n         [4],\n         [1],\n         [2],\n         [3],\n         [5],\n         [8],\n         [1]],\n\n        [[3],\n         [3],\n         [1],\n         [7],\n         [6],\n         [4],\n         [6],\n         [2],\n         [8],\n         [0],\n         [4],\n         [6],\n         [1],\n         [9],\n         [7],\n         [3],\n         [8],\n         [1],\n         [1],\n         [3],\n         [6],\n         [5],\n         [3],\n         [9],\n         [3],\n         [2],\n         [4],\n         [2]],\n\n        [[6],\n         [9],\n         [9],\n         [1],\n         [2],\n         [7],\n         [7],\n         [8],\n         [8],\n         [3],\n         [1],\n         [8],\n         [4],\n         [1],\n         [7],\n         [4],\n         [6],\n         [5],\n         [5],\n         [8],\n         [4],\n         [2],\n         [3],\n         [6],\n         [6],\n         [4],\n         [1],\n         [8]],\n\n        [[8],\n         [0],\n         [5],\n         [5],\n         [6],\n         [6],\n         [8],\n         [6],\n         [6],\n         [0],\n         [3],\n         [2],\n         [0],\n         [9],\n         [2],\n         [1],\n         [5],\n         [6],\n         [5],\n         [3],\n         [8],\n         [4],\n         [0],\n         [5],\n         [8],\n         [6],\n         [7],\n         [8]],\n\n        [[2],\n         [1],\n         [4],\n         [1],\n         [4],\n         [1],\n         [2],\n         [5],\n         [1],\n         [5],\n         [0],\n         [3],\n         [8],\n         [4],\n         [0],\n         [7],\n         [3],\n         [9],\n         [3],\n         [5],\n         [3],\n         [8],\n         [9],\n         [9],\n         [0],\n         [1],\n         [6],\n         [4]],\n\n        [[3],\n         [4],\n         [6],\n         [8],\n         [5],\n         [9],\n         [9],\n         [8],\n         [0],\n         [2],\n         [2],\n         [3],\n         [8],\n         [9],\n         [3],\n         [3],\n         [8],\n         [7],\n         [0],\n         [0],\n         [7],\n         [0],\n         [1],\n         [7],\n         [3],\n         [0],\n         [0],\n         [0]],\n\n        [[8],\n         [8],\n         [6],\n         [8],\n         [0],\n         [7],\n         [4],\n         [1],\n         [2],\n         [9],\n         [2],\n         [7],\n         [9],\n         [0],\n         [2],\n         [3],\n         [4],\n         [9],\n         [9],\n         [5],\n         [4],\n         [9],\n         [1],\n         [9],\n         [8],\n         [1],\n         [5],\n         [7]],\n\n        [[7],\n         [1],\n         [7],\n         [9],\n         [3],\n         [9],\n         [3],\n         [9],\n         [1],\n         [0],\n         [8],\n         [6],\n         [6],\n         [7],\n         [5],\n         [5],\n         [5],\n         [9],\n         [8],\n         [7],\n         [2],\n         [2],\n         [5],\n         [7],\n         [5],\n         [8],\n         [9],\n         [5]],\n\n        [[8],\n         [2],\n         [8],\n         [5],\n         [4],\n         [9],\n         [0],\n         [9],\n         [3],\n         [9],\n         [9],\n         [9],\n         [9],\n         [1],\n         [5],\n         [0],\n         [5],\n         [7],\n         [9],\n         [4],\n         [4],\n         [2],\n         [0],\n         [3],\n         [0],\n         [1],\n         [7],\n         [4]],\n\n        [[5],\n         [4],\n         [4],\n         [0],\n         [1],\n         [0],\n         [6],\n         [4],\n         [5],\n         [5],\n         [2],\n         [6],\n         [6],\n         [7],\n         [2],\n         [3],\n         [0],\n         [5],\n         [0],\n         [9],\n         [7],\n         [7],\n         [7],\n         [0],\n         [2],\n         [4],\n         [7],\n         [8]],\n\n        [[5],\n         [0],\n         [8],\n         [3],\n         [8],\n         [3],\n         [4],\n         [5],\n         [0],\n         [9],\n         [2],\n         [6],\n         [5],\n         [2],\n         [1],\n         [5],\n         [8],\n         [3],\n         [8],\n         [3],\n         [3],\n         [7],\n         [9],\n         [7],\n         [9],\n         [3],\n         [0],\n         [2]],\n\n        [[2],\n         [0],\n         [8],\n         [3],\n         [6],\n         [6],\n         [1],\n         [2],\n         [4],\n         [6],\n         [3],\n         [5],\n         [0],\n         [9],\n         [3],\n         [1],\n         [6],\n         [7],\n         [9],\n         [4],\n         [4],\n         [2],\n         [2],\n         [9],\n         [4],\n         [4],\n         [8],\n         [8]],\n\n        [[5],\n         [2],\n         [9],\n         [9],\n         [9],\n         [3],\n         [3],\n         [8],\n         [1],\n         [4],\n         [0],\n         [3],\n         [1],\n         [6],\n         [0],\n         [2],\n         [7],\n         [7],\n         [5],\n         [9],\n         [5],\n         [6],\n         [5],\n         [4],\n         [6],\n         [3],\n         [2],\n         [2]],\n\n        [[1],\n         [2],\n         [2],\n         [6],\n         [0],\n         [2],\n         [7],\n         [5],\n         [5],\n         [9],\n         [1],\n         [4],\n         [0],\n         [9],\n         [9],\n         [2],\n         [1],\n         [7],\n         [6],\n         [1],\n         [0],\n         [1],\n         [5],\n         [4],\n         [5],\n         [4],\n         [1],\n         [7]],\n\n        [[9],\n         [6],\n         [9],\n         [8],\n         [4],\n         [8],\n         [1],\n         [6],\n         [5],\n         [4],\n         [2],\n         [2],\n         [6],\n         [7],\n         [1],\n         [6],\n         [2],\n         [0],\n         [8],\n         [5],\n         [4],\n         [4],\n         [1],\n         [4],\n         [4],\n         [1],\n         [4],\n         [1]],\n\n        [[1],\n         [0],\n         [8],\n         [5],\n         [4],\n         [3],\n         [6],\n         [4],\n         [4],\n         [1],\n         [5],\n         [8],\n         [4],\n         [4],\n         [0],\n         [8],\n         [0],\n         [7],\n         [9],\n         [1],\n         [0],\n         [0],\n         [0],\n         [3],\n         [9],\n         [4],\n         [5],\n         [1]],\n\n        [[2],\n         [5],\n         [9],\n         [9],\n         [4],\n         [6],\n         [1],\n         [3],\n         [3],\n         [3],\n         [7],\n         [4],\n         [1],\n         [6],\n         [6],\n         [6],\n         [2],\n         [0],\n         [5],\n         [1],\n         [0],\n         [7],\n         [9],\n         [5],\n         [6],\n         [4],\n         [1],\n         [2]],\n\n        [[8],\n         [3],\n         [1],\n         [8],\n         [3],\n         [3],\n         [3],\n         [5],\n         [0],\n         [6],\n         [1],\n         [6],\n         [8],\n         [5],\n         [2],\n         [5],\n         [9],\n         [9],\n         [5],\n         [9],\n         [0],\n         [8],\n         [5],\n         [1],\n         [9],\n         [9],\n         [4],\n         [9]],\n\n        [[0],\n         [2],\n         [6],\n         [3],\n         [5],\n         [8],\n         [4],\n         [2],\n         [4],\n         [9],\n         [1],\n         [4],\n         [6],\n         [3],\n         [4],\n         [6],\n         [1],\n         [5],\n         [5],\n         [8],\n         [7],\n         [7],\n         [0],\n         [7],\n         [5],\n         [7],\n         [2],\n         [4]],\n\n        [[4],\n         [3],\n         [3],\n         [6],\n         [6],\n         [5],\n         [2],\n         [7],\n         [0],\n         [4],\n         [9],\n         [0],\n         [3],\n         [8],\n         [4],\n         [4],\n         [4],\n         [9],\n         [9],\n         [2],\n         [9],\n         [2],\n         [8],\n         [5],\n         [5],\n         [9],\n         [7],\n         [9]],\n\n        [[6],\n         [4],\n         [1],\n         [4],\n         [3],\n         [5],\n         [5],\n         [5],\n         [8],\n         [0],\n         [3],\n         [5],\n         [8],\n         [9],\n         [0],\n         [4],\n         [8],\n         [5],\n         [0],\n         [9],\n         [0],\n         [5],\n         [8],\n         [6],\n         [5],\n         [1],\n         [3],\n         [8]],\n\n        [[3],\n         [5],\n         [1],\n         [9],\n         [5],\n         [1],\n         [0],\n         [5],\n         [7],\n         [4],\n         [4],\n         [3],\n         [1],\n         [0],\n         [3],\n         [8],\n         [5],\n         [8],\n         [2],\n         [9],\n         [8],\n         [3],\n         [6],\n         [2],\n         [9],\n         [9],\n         [5],\n         [5]],\n\n        [[8],\n         [4],\n         [3],\n         [6],\n         [9],\n         [5],\n         [1],\n         [9],\n         [2],\n         [3],\n         [7],\n         [9],\n         [7],\n         [4],\n         [9],\n         [6],\n         [0],\n         [7],\n         [9],\n         [7],\n         [7],\n         [8],\n         [9],\n         [5],\n         [8],\n         [0],\n         [0],\n         [8]],\n\n        [[6],\n         [2],\n         [5],\n         [4],\n         [4],\n         [6],\n         [6],\n         [7],\n         [2],\n         [5],\n         [0],\n         [8],\n         [0],\n         [3],\n         [0],\n         [5],\n         [9],\n         [8],\n         [0],\n         [5],\n         [6],\n         [3],\n         [1],\n         [0],\n         [0],\n         [8],\n         [2],\n         [2]],\n\n        [[1],\n         [7],\n         [3],\n         [3],\n         [2],\n         [8],\n         [4],\n         [8],\n         [5],\n         [9],\n         [5],\n         [6],\n         [9],\n         [4],\n         [4],\n         [2],\n         [2],\n         [6],\n         [6],\n         [4],\n         [3],\n         [6],\n         [3],\n         [4],\n         [5],\n         [9],\n         [7],\n         [7]],\n\n        [[9],\n         [7],\n         [5],\n         [0],\n         [1],\n         [4],\n         [1],\n         [6],\n         [0],\n         [6],\n         [5],\n         [3],\n         [7],\n         [0],\n         [4],\n         [4],\n         [7],\n         [0],\n         [1],\n         [0],\n         [8],\n         [0],\n         [9],\n         [6],\n         [0],\n         [3],\n         [4],\n         [5]],\n\n        [[0],\n         [5],\n         [1],\n         [9],\n         [2],\n         [7],\n         [4],\n         [6],\n         [2],\n         [3],\n         [0],\n         [2],\n         [4],\n         [9],\n         [9],\n         [7],\n         [5],\n         [4],\n         [0],\n         [8],\n         [4],\n         [7],\n         [5],\n         [9],\n         [2],\n         [1],\n         [3],\n         [0]]]])>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.expand_dims(x,axis=0) # 高维度之前插入新维度\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28, 1), dtype=int32, numpy=\narray([[[9],\n        [9],\n        [1],\n        [9],\n        [8],\n        [0],\n        [0],\n        [4],\n        [5],\n        [7],\n        [4],\n        [9],\n        [1],\n        [7],\n        [0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [9],\n        [3],\n        [8],\n        [4],\n        [0],\n        [0],\n        [2],\n        [1],\n        [1]],\n\n       [[5],\n        [7],\n        [5],\n        [2],\n        [5],\n        [9],\n        [8],\n        [5],\n        [8],\n        [3],\n        [7],\n        [9],\n        [7],\n        [9],\n        [9],\n        [1],\n        [3],\n        [3],\n        [8],\n        [0],\n        [8],\n        [4],\n        [1],\n        [2],\n        [3],\n        [5],\n        [8],\n        [1]],\n\n       [[3],\n        [3],\n        [1],\n        [7],\n        [6],\n        [4],\n        [6],\n        [2],\n        [8],\n        [0],\n        [4],\n        [6],\n        [1],\n        [9],\n        [7],\n        [3],\n        [8],\n        [1],\n        [1],\n        [3],\n        [6],\n        [5],\n        [3],\n        [9],\n        [3],\n        [2],\n        [4],\n        [2]],\n\n       [[6],\n        [9],\n        [9],\n        [1],\n        [2],\n        [7],\n        [7],\n        [8],\n        [8],\n        [3],\n        [1],\n        [8],\n        [4],\n        [1],\n        [7],\n        [4],\n        [6],\n        [5],\n        [5],\n        [8],\n        [4],\n        [2],\n        [3],\n        [6],\n        [6],\n        [4],\n        [1],\n        [8]],\n\n       [[8],\n        [0],\n        [5],\n        [5],\n        [6],\n        [6],\n        [8],\n        [6],\n        [6],\n        [0],\n        [3],\n        [2],\n        [0],\n        [9],\n        [2],\n        [1],\n        [5],\n        [6],\n        [5],\n        [3],\n        [8],\n        [4],\n        [0],\n        [5],\n        [8],\n        [6],\n        [7],\n        [8]],\n\n       [[2],\n        [1],\n        [4],\n        [1],\n        [4],\n        [1],\n        [2],\n        [5],\n        [1],\n        [5],\n        [0],\n        [3],\n        [8],\n        [4],\n        [0],\n        [7],\n        [3],\n        [9],\n        [3],\n        [5],\n        [3],\n        [8],\n        [9],\n        [9],\n        [0],\n        [1],\n        [6],\n        [4]],\n\n       [[3],\n        [4],\n        [6],\n        [8],\n        [5],\n        [9],\n        [9],\n        [8],\n        [0],\n        [2],\n        [2],\n        [3],\n        [8],\n        [9],\n        [3],\n        [3],\n        [8],\n        [7],\n        [0],\n        [0],\n        [7],\n        [0],\n        [1],\n        [7],\n        [3],\n        [0],\n        [0],\n        [0]],\n\n       [[8],\n        [8],\n        [6],\n        [8],\n        [0],\n        [7],\n        [4],\n        [1],\n        [2],\n        [9],\n        [2],\n        [7],\n        [9],\n        [0],\n        [2],\n        [3],\n        [4],\n        [9],\n        [9],\n        [5],\n        [4],\n        [9],\n        [1],\n        [9],\n        [8],\n        [1],\n        [5],\n        [7]],\n\n       [[7],\n        [1],\n        [7],\n        [9],\n        [3],\n        [9],\n        [3],\n        [9],\n        [1],\n        [0],\n        [8],\n        [6],\n        [6],\n        [7],\n        [5],\n        [5],\n        [5],\n        [9],\n        [8],\n        [7],\n        [2],\n        [2],\n        [5],\n        [7],\n        [5],\n        [8],\n        [9],\n        [5]],\n\n       [[8],\n        [2],\n        [8],\n        [5],\n        [4],\n        [9],\n        [0],\n        [9],\n        [3],\n        [9],\n        [9],\n        [9],\n        [9],\n        [1],\n        [5],\n        [0],\n        [5],\n        [7],\n        [9],\n        [4],\n        [4],\n        [2],\n        [0],\n        [3],\n        [0],\n        [1],\n        [7],\n        [4]],\n\n       [[5],\n        [4],\n        [4],\n        [0],\n        [1],\n        [0],\n        [6],\n        [4],\n        [5],\n        [5],\n        [2],\n        [6],\n        [6],\n        [7],\n        [2],\n        [3],\n        [0],\n        [5],\n        [0],\n        [9],\n        [7],\n        [7],\n        [7],\n        [0],\n        [2],\n        [4],\n        [7],\n        [8]],\n\n       [[5],\n        [0],\n        [8],\n        [3],\n        [8],\n        [3],\n        [4],\n        [5],\n        [0],\n        [9],\n        [2],\n        [6],\n        [5],\n        [2],\n        [1],\n        [5],\n        [8],\n        [3],\n        [8],\n        [3],\n        [3],\n        [7],\n        [9],\n        [7],\n        [9],\n        [3],\n        [0],\n        [2]],\n\n       [[2],\n        [0],\n        [8],\n        [3],\n        [6],\n        [6],\n        [1],\n        [2],\n        [4],\n        [6],\n        [3],\n        [5],\n        [0],\n        [9],\n        [3],\n        [1],\n        [6],\n        [7],\n        [9],\n        [4],\n        [4],\n        [2],\n        [2],\n        [9],\n        [4],\n        [4],\n        [8],\n        [8]],\n\n       [[5],\n        [2],\n        [9],\n        [9],\n        [9],\n        [3],\n        [3],\n        [8],\n        [1],\n        [4],\n        [0],\n        [3],\n        [1],\n        [6],\n        [0],\n        [2],\n        [7],\n        [7],\n        [5],\n        [9],\n        [5],\n        [6],\n        [5],\n        [4],\n        [6],\n        [3],\n        [2],\n        [2]],\n\n       [[1],\n        [2],\n        [2],\n        [6],\n        [0],\n        [2],\n        [7],\n        [5],\n        [5],\n        [9],\n        [1],\n        [4],\n        [0],\n        [9],\n        [9],\n        [2],\n        [1],\n        [7],\n        [6],\n        [1],\n        [0],\n        [1],\n        [5],\n        [4],\n        [5],\n        [4],\n        [1],\n        [7]],\n\n       [[9],\n        [6],\n        [9],\n        [8],\n        [4],\n        [8],\n        [1],\n        [6],\n        [5],\n        [4],\n        [2],\n        [2],\n        [6],\n        [7],\n        [1],\n        [6],\n        [2],\n        [0],\n        [8],\n        [5],\n        [4],\n        [4],\n        [1],\n        [4],\n        [4],\n        [1],\n        [4],\n        [1]],\n\n       [[1],\n        [0],\n        [8],\n        [5],\n        [4],\n        [3],\n        [6],\n        [4],\n        [4],\n        [1],\n        [5],\n        [8],\n        [4],\n        [4],\n        [0],\n        [8],\n        [0],\n        [7],\n        [9],\n        [1],\n        [0],\n        [0],\n        [0],\n        [3],\n        [9],\n        [4],\n        [5],\n        [1]],\n\n       [[2],\n        [5],\n        [9],\n        [9],\n        [4],\n        [6],\n        [1],\n        [3],\n        [3],\n        [3],\n        [7],\n        [4],\n        [1],\n        [6],\n        [6],\n        [6],\n        [2],\n        [0],\n        [5],\n        [1],\n        [0],\n        [7],\n        [9],\n        [5],\n        [6],\n        [4],\n        [1],\n        [2]],\n\n       [[8],\n        [3],\n        [1],\n        [8],\n        [3],\n        [3],\n        [3],\n        [5],\n        [0],\n        [6],\n        [1],\n        [6],\n        [8],\n        [5],\n        [2],\n        [5],\n        [9],\n        [9],\n        [5],\n        [9],\n        [0],\n        [8],\n        [5],\n        [1],\n        [9],\n        [9],\n        [4],\n        [9]],\n\n       [[0],\n        [2],\n        [6],\n        [3],\n        [5],\n        [8],\n        [4],\n        [2],\n        [4],\n        [9],\n        [1],\n        [4],\n        [6],\n        [3],\n        [4],\n        [6],\n        [1],\n        [5],\n        [5],\n        [8],\n        [7],\n        [7],\n        [0],\n        [7],\n        [5],\n        [7],\n        [2],\n        [4]],\n\n       [[4],\n        [3],\n        [3],\n        [6],\n        [6],\n        [5],\n        [2],\n        [7],\n        [0],\n        [4],\n        [9],\n        [0],\n        [3],\n        [8],\n        [4],\n        [4],\n        [4],\n        [9],\n        [9],\n        [2],\n        [9],\n        [2],\n        [8],\n        [5],\n        [5],\n        [9],\n        [7],\n        [9]],\n\n       [[6],\n        [4],\n        [1],\n        [4],\n        [3],\n        [5],\n        [5],\n        [5],\n        [8],\n        [0],\n        [3],\n        [5],\n        [8],\n        [9],\n        [0],\n        [4],\n        [8],\n        [5],\n        [0],\n        [9],\n        [0],\n        [5],\n        [8],\n        [6],\n        [5],\n        [1],\n        [3],\n        [8]],\n\n       [[3],\n        [5],\n        [1],\n        [9],\n        [5],\n        [1],\n        [0],\n        [5],\n        [7],\n        [4],\n        [4],\n        [3],\n        [1],\n        [0],\n        [3],\n        [8],\n        [5],\n        [8],\n        [2],\n        [9],\n        [8],\n        [3],\n        [6],\n        [2],\n        [9],\n        [9],\n        [5],\n        [5]],\n\n       [[8],\n        [4],\n        [3],\n        [6],\n        [9],\n        [5],\n        [1],\n        [9],\n        [2],\n        [3],\n        [7],\n        [9],\n        [7],\n        [4],\n        [9],\n        [6],\n        [0],\n        [7],\n        [9],\n        [7],\n        [7],\n        [8],\n        [9],\n        [5],\n        [8],\n        [0],\n        [0],\n        [8]],\n\n       [[6],\n        [2],\n        [5],\n        [4],\n        [4],\n        [6],\n        [6],\n        [7],\n        [2],\n        [5],\n        [0],\n        [8],\n        [0],\n        [3],\n        [0],\n        [5],\n        [9],\n        [8],\n        [0],\n        [5],\n        [6],\n        [3],\n        [1],\n        [0],\n        [0],\n        [8],\n        [2],\n        [2]],\n\n       [[1],\n        [7],\n        [3],\n        [3],\n        [2],\n        [8],\n        [4],\n        [8],\n        [5],\n        [9],\n        [5],\n        [6],\n        [9],\n        [4],\n        [4],\n        [2],\n        [2],\n        [6],\n        [6],\n        [4],\n        [3],\n        [6],\n        [3],\n        [4],\n        [5],\n        [9],\n        [7],\n        [7]],\n\n       [[9],\n        [7],\n        [5],\n        [0],\n        [1],\n        [4],\n        [1],\n        [6],\n        [0],\n        [6],\n        [5],\n        [3],\n        [7],\n        [0],\n        [4],\n        [4],\n        [7],\n        [0],\n        [1],\n        [0],\n        [8],\n        [0],\n        [9],\n        [6],\n        [0],\n        [3],\n        [4],\n        [5]],\n\n       [[0],\n        [5],\n        [1],\n        [9],\n        [2],\n        [7],\n        [4],\n        [6],\n        [2],\n        [3],\n        [0],\n        [2],\n        [4],\n        [9],\n        [9],\n        [7],\n        [5],\n        [4],\n        [0],\n        [8],\n        [4],\n        [7],\n        [5],\n        [9],\n        [2],\n        [1],\n        [3],\n        [0]]])>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.squeeze(x, axis=0) # 删除图片数量维度\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28), dtype=int32, numpy=\narray([[7, 7, 1, 7, 1, 4, 1, 5, 2, 8, 8, 4, 5, 1, 6, 6, 7, 9, 6, 4, 2, 7,\n        6, 0, 9, 4, 7, 7],\n       [5, 0, 1, 0, 6, 1, 9, 3, 8, 2, 2, 3, 7, 8, 2, 9, 0, 6, 6, 3, 3, 1,\n        6, 6, 3, 7, 9, 3],\n       [1, 5, 7, 1, 9, 9, 3, 5, 2, 3, 4, 5, 3, 8, 4, 8, 1, 4, 6, 1, 1, 5,\n        9, 8, 7, 8, 1, 2],\n       [6, 2, 7, 8, 2, 3, 6, 8, 7, 3, 3, 5, 3, 3, 6, 9, 9, 0, 3, 5, 0, 6,\n        5, 0, 9, 0, 9, 7],\n       [0, 1, 8, 3, 9, 8, 2, 3, 0, 9, 7, 6, 8, 3, 4, 8, 5, 2, 1, 5, 2, 3,\n        8, 1, 1, 3, 0, 4],\n       [3, 4, 9, 1, 1, 2, 7, 8, 2, 1, 5, 5, 1, 6, 5, 8, 6, 9, 7, 3, 2, 7,\n        9, 4, 3, 8, 0, 2],\n       [5, 0, 2, 7, 0, 7, 6, 8, 7, 5, 8, 2, 7, 4, 6, 9, 1, 1, 4, 9, 7, 1,\n        7, 3, 6, 6, 0, 7],\n       [5, 0, 1, 6, 3, 8, 1, 4, 3, 7, 2, 1, 1, 3, 4, 7, 3, 3, 0, 5, 3, 3,\n        5, 3, 0, 3, 5, 0],\n       [6, 8, 2, 7, 7, 2, 9, 9, 3, 5, 6, 0, 6, 4, 9, 0, 4, 1, 3, 4, 5, 8,\n        3, 6, 7, 3, 9, 7],\n       [7, 9, 4, 1, 3, 7, 4, 0, 9, 8, 1, 0, 6, 6, 5, 2, 3, 2, 7, 3, 0, 5,\n        2, 6, 8, 6, 0, 5],\n       [0, 2, 0, 9, 1, 4, 9, 7, 9, 3, 0, 6, 2, 1, 3, 0, 0, 8, 8, 5, 9, 2,\n        5, 6, 3, 4, 4, 0],\n       [7, 2, 3, 9, 0, 2, 9, 9, 8, 8, 3, 5, 3, 1, 0, 7, 2, 5, 2, 4, 9, 3,\n        6, 8, 2, 7, 8, 5],\n       [2, 1, 2, 9, 2, 3, 9, 4, 9, 2, 0, 5, 6, 1, 2, 9, 8, 1, 6, 4, 9, 2,\n        0, 7, 5, 7, 4, 3],\n       [2, 0, 1, 2, 0, 3, 0, 9, 1, 1, 9, 1, 4, 9, 3, 3, 1, 2, 6, 5, 6, 1,\n        6, 6, 8, 5, 0, 5],\n       [7, 0, 2, 6, 4, 0, 6, 7, 6, 6, 2, 7, 7, 4, 0, 9, 2, 3, 6, 8, 3, 9,\n        6, 1, 9, 5, 2, 1],\n       [9, 2, 8, 9, 4, 7, 7, 4, 8, 4, 1, 3, 7, 8, 2, 8, 9, 0, 2, 0, 8, 4,\n        3, 7, 2, 3, 8, 1],\n       [6, 0, 0, 3, 3, 1, 4, 2, 6, 5, 2, 7, 4, 1, 5, 9, 4, 3, 0, 9, 6, 8,\n        3, 9, 8, 7, 8, 5],\n       [1, 0, 2, 5, 7, 3, 0, 5, 2, 2, 0, 9, 1, 4, 4, 6, 0, 3, 1, 7, 5, 8,\n        8, 8, 8, 9, 0, 2],\n       [4, 8, 4, 2, 4, 7, 9, 2, 4, 2, 8, 9, 5, 3, 9, 1, 4, 3, 7, 7, 1, 4,\n        3, 4, 9, 6, 9, 0],\n       [8, 6, 9, 4, 6, 2, 2, 1, 6, 1, 4, 9, 3, 7, 6, 9, 3, 4, 6, 4, 8, 9,\n        2, 2, 0, 1, 0, 2],\n       [4, 0, 0, 2, 0, 0, 3, 8, 5, 1, 6, 2, 9, 8, 0, 5, 2, 7, 6, 4, 1, 2,\n        1, 8, 0, 3, 5, 2],\n       [5, 6, 9, 4, 4, 9, 8, 8, 9, 0, 9, 7, 8, 7, 8, 5, 0, 3, 8, 4, 5, 8,\n        5, 1, 1, 2, 6, 9],\n       [1, 3, 4, 8, 5, 4, 9, 2, 8, 4, 3, 5, 2, 5, 3, 2, 2, 5, 9, 7, 7, 8,\n        8, 4, 4, 0, 4, 4],\n       [1, 6, 1, 0, 7, 2, 3, 9, 4, 2, 9, 5, 1, 1, 3, 8, 8, 5, 8, 0, 5, 6,\n        1, 1, 7, 1, 7, 4],\n       [9, 4, 3, 6, 9, 2, 6, 2, 4, 4, 8, 6, 0, 8, 3, 9, 2, 8, 4, 2, 3, 2,\n        0, 9, 9, 0, 5, 0],\n       [9, 8, 1, 7, 7, 5, 3, 2, 7, 3, 4, 1, 9, 7, 8, 4, 3, 5, 5, 1, 0, 1,\n        6, 7, 0, 1, 4, 5],\n       [1, 0, 4, 3, 5, 6, 9, 4, 7, 2, 4, 2, 7, 9, 1, 2, 1, 6, 1, 2, 9, 3,\n        4, 9, 1, 4, 8, 1],\n       [8, 2, 8, 8, 3, 1, 5, 0, 9, 5, 1, 7, 1, 6, 2, 1, 4, 0, 5, 5, 6, 7,\n        9, 6, 9, 8, 2, 8]])>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform([1,28,28,1],maxval=10,dtype=tf.int32)\n",
    "tf.squeeze(x) # 删除所有长度为 1 的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交换维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3, 32, 32), dtype=float32, numpy=\narray([[[[ 1.8320396 ,  0.7884572 ,  2.2952375 , ...,  0.99965906,\n           0.47179914, -1.2392385 ],\n         [-0.2790963 , -1.900099  ,  0.9289354 , ...,  1.0846897 ,\n           0.54981846, -1.2396021 ],\n         [ 0.06397729, -0.16979311,  0.20041804, ...,  1.9682915 ,\n           0.12054651, -0.14477237],\n         ...,\n         [-0.7451902 ,  1.0040444 , -0.4640826 , ..., -0.58819354,\n           0.4646075 ,  0.33040848],\n         [-0.7039945 , -0.2871381 , -1.2854329 , ..., -0.5298408 ,\n           1.1984817 , -1.1119671 ],\n         [-0.1400329 ,  0.9748489 ,  0.01694189, ..., -0.5952891 ,\n          -0.08432785,  0.77033824]],\n\n        [[-1.511571  , -0.44614872, -0.5360325 , ..., -2.4405057 ,\n          -0.17982766,  0.55819607],\n         [ 0.22918947, -0.41730398, -0.65216804, ..., -0.86923265,\n          -2.7684152 ,  0.02984187],\n         [ 0.3651999 , -1.50687   ,  0.8671812 , ...,  0.7473599 ,\n          -0.5310433 ,  0.862201  ],\n         ...,\n         [-0.08986995,  0.43805647, -0.03428406, ...,  1.5078567 ,\n          -0.17545958,  0.2811427 ],\n         [-1.4092643 , -0.32124576, -0.33331522, ..., -1.5206296 ,\n           2.2572224 ,  2.3784688 ],\n         [ 0.6664654 ,  1.3087773 ,  2.3139153 , ..., -0.4545077 ,\n           1.5279272 , -0.86306   ]],\n\n        [[-0.66080993, -1.4323633 ,  1.2407733 , ..., -0.03607571,\n          -0.4512815 ,  0.15061082],\n         [ 0.33105037, -0.57749915,  0.2114183 , ..., -1.1894962 ,\n          -0.0699859 , -1.5556381 ],\n         [ 0.24078758,  0.24575946,  0.13469627, ..., -0.15727936,\n          -0.47922847, -1.8717885 ],\n         ...,\n         [ 1.3264333 ,  0.8149812 ,  0.69237655, ...,  0.08404811,\n          -1.3365636 , -0.7599022 ],\n         [-0.2476222 , -0.41234612,  0.14011616, ..., -0.29180375,\n          -0.16875158, -0.6293868 ],\n         [ 1.321286  ,  0.945021  , -0.8955726 , ...,  0.05392488,\n          -0.41107336, -1.058772  ]]],\n\n\n       [[[ 0.17192507,  0.25206128,  0.73875356, ..., -0.32240924,\n           1.8299575 , -0.19237296],\n         [ 1.0329866 ,  0.34676427,  0.5441814 , ...,  0.21846436,\n          -1.0526819 ,  0.07365035],\n         [-1.315697  , -1.6573914 , -0.923356  , ...,  0.10719341,\n          -1.223831  , -1.0617677 ],\n         ...,\n         [-1.4563385 ,  0.41955566, -0.59961385, ..., -2.8440497 ,\n          -0.82717174,  0.3560756 ],\n         [ 1.1821542 , -0.24734494,  0.44528487, ..., -0.45859444,\n          -1.895916  , -1.698295  ],\n         [-0.32894045, -0.14458992,  0.15536687, ..., -0.56803125,\n           0.25857237,  0.53734106]],\n\n        [[ 0.4155109 ,  0.9740406 ,  1.2472438 , ..., -0.28087372,\n          -2.4082747 , -0.96412456],\n         [-1.4414163 , -0.7620917 ,  0.8034655 , ..., -0.7394212 ,\n           0.5223686 , -0.8646938 ],\n         [ 1.61528   , -0.7423497 ,  1.1124748 , ..., -1.8708718 ,\n          -0.3865888 , -1.2689855 ],\n         ...,\n         [ 1.5793105 , -0.88749856, -1.0516688 , ..., -1.0456314 ,\n           1.0461764 ,  0.11153758],\n         [-0.76393265,  1.293674  , -0.400812  , ...,  0.46653613,\n          -0.59415954, -0.39040077],\n         [ 2.602018  , -0.25694692,  1.1974138 , ...,  1.4812068 ,\n          -2.08753   , -0.9146012 ]],\n\n        [[-1.0650314 , -0.14811319,  0.17171748, ..., -0.43222308,\n          -0.4170055 , -0.37510383],\n         [ 0.49612713,  2.4901874 ,  1.8070123 , ..., -0.48046556,\n          -0.5536182 ,  0.06991643],\n         [ 0.4691451 ,  0.835209  ,  1.9271849 , ..., -0.8234254 ,\n          -1.3706429 , -2.6326602 ],\n         ...,\n         [-1.0419749 , -2.864773  , -0.58243555, ...,  0.82557833,\n           0.8258622 ,  0.02097228],\n         [-0.03963053,  1.1496795 ,  1.4628445 , ..., -1.4175591 ,\n           0.79070735, -1.0090722 ],\n         [ 0.45231715, -1.7583847 , -1.1215844 , ...,  0.78440475,\n          -0.31740063,  0.5243637 ]]]], dtype=float32)>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([2,32,32,3])\n",
    "# 交换维度\n",
    "tf.transpose(x,perm=[0,3,1,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 32, 32, 3), dtype=float32, numpy=\narray([[[[-1.205447  ,  0.01185454, -0.0695671 ],\n         [-0.7079914 ,  0.4474336 , -0.4563063 ],\n         [ 1.3185732 , -0.70920324,  1.007479  ],\n         ...,\n         [-0.4879324 , -1.1999311 ,  0.9327969 ],\n         [-0.8036022 ,  1.7053095 ,  0.84966254],\n         [ 1.0679622 , -0.54660314, -0.56089234]],\n\n        [[-0.5643    ,  2.5297205 , -0.80189115],\n         [-0.25300097,  1.8100315 , -0.8000928 ],\n         [-0.49972332, -1.6671408 , -0.34055942],\n         ...,\n         [-0.77833295, -1.6121265 , -0.21863812],\n         [ 2.4235063 ,  0.7339327 , -0.10279572],\n         [ 0.7032747 ,  0.18458733, -0.7139853 ]],\n\n        [[-2.128073  ,  0.44884825,  0.4742213 ],\n         [ 0.3762216 , -2.2422678 , -0.008263  ],\n         [ 1.4176604 , -0.64210755, -0.01787386],\n         ...,\n         [-1.1258729 , -0.90672445, -1.4215    ],\n         [ 0.29224867,  1.0675457 , -1.3440154 ],\n         [ 0.72530466, -1.5519329 , -0.626289  ]],\n\n        ...,\n\n        [[ 0.23733756, -1.0536208 , -1.6519442 ],\n         [ 0.583937  ,  0.46657696,  0.6237751 ],\n         [-0.43435228, -0.3522825 , -2.4458108 ],\n         ...,\n         [-0.00505244, -1.0465865 , -0.31418747],\n         [ 0.17105515, -2.846904  , -0.27555865],\n         [ 1.1757989 ,  1.14523   ,  1.501224  ]],\n\n        [[-1.8264874 ,  0.6517137 , -0.9595078 ],\n         [-0.6285558 ,  0.43688175, -0.03590783],\n         [ 0.28126284, -0.69145155,  2.1837978 ],\n         ...,\n         [-0.7550584 , -0.39674613,  0.76427495],\n         [-0.5073454 , -0.33727646, -0.07811079],\n         [ 0.13248907, -1.3692265 ,  0.46177545]],\n\n        [[-0.69310933, -0.39278984, -0.609534  ],\n         [-0.37765223, -2.2716353 , -0.7846412 ],\n         [ 0.7880113 , -1.3707399 ,  0.02329923],\n         ...,\n         [-1.7859875 , -1.2196147 , -0.12146379],\n         [ 0.1712579 , -1.6149865 ,  1.811399  ],\n         [-0.89564776,  0.44166127,  0.62574786]]],\n\n\n       [[[-1.8164669 ,  0.42986348,  0.60791576],\n         [ 0.6606635 ,  0.9233881 , -0.9854123 ],\n         [-1.2198088 ,  0.96311885, -0.30700585],\n         ...,\n         [-1.3038723 ,  0.33237374, -1.0658127 ],\n         [-0.5425634 , -2.1949167 , -0.4306404 ],\n         [-0.536046  ,  0.9633772 , -0.8853253 ]],\n\n        [[ 0.17430523, -0.1686486 , -0.37567246],\n         [-0.23512203,  0.20028473, -0.7711172 ],\n         [ 0.1367343 ,  1.7415612 , -1.1661325 ],\n         ...,\n         [ 1.1976088 ,  0.10155311, -0.82364553],\n         [ 1.3795047 ,  0.4880808 , -1.3387061 ],\n         [ 0.55129117,  0.48303044,  0.07212861]],\n\n        [[ 0.15209727,  0.7829754 , -1.0420874 ],\n         [-1.3336245 ,  0.06011749, -0.93939275],\n         [ 0.1333824 , -1.0277684 ,  1.1148219 ],\n         ...,\n         [-0.1097494 , -0.04245946, -0.30966893],\n         [-0.59410405, -1.0236986 , -0.79526967],\n         [-1.0212511 , -1.6914642 , -0.26612055]],\n\n        ...,\n\n        [[-0.63744694,  0.11806687,  0.36922744],\n         [ 1.9741201 , -0.41271764,  1.1851996 ],\n         [-0.6860744 ,  0.7068975 , -0.5968613 ],\n         ...,\n         [-0.92380166, -0.7486409 , -0.10807899],\n         [ 0.00650171,  0.63044727,  0.63883746],\n         [-1.4116212 ,  0.6392173 , -0.2897926 ]],\n\n        [[ 0.7180746 , -1.0045216 ,  3.5569444 ],\n         [ 0.19599262,  1.1188388 , -0.4535526 ],\n         [ 1.1807076 ,  1.1385543 , -0.3137602 ],\n         ...,\n         [ 0.5832825 , -1.3071024 ,  0.7459774 ],\n         [ 0.82755494,  0.58057576,  0.31713375],\n         [ 2.0970228 ,  0.63043976,  0.12377708]],\n\n        [[-1.2858043 ,  0.4889622 ,  0.24635933],\n         [-0.4762447 ,  0.16839558, -0.1569709 ],\n         [ 0.72511023, -1.4851716 ,  0.36349997],\n         ...,\n         [-1.2257771 , -0.922617  ,  1.1030767 ],\n         [-0.31562844,  0.07883202, -0.9633753 ],\n         [ 0.06337107,  1.078588  , -2.4922314 ]]]], dtype=float32)>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([2,32,32,3])\n",
    "# 交换维度\n",
    "tf.transpose(x,perm=[0,2,1,3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复制数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[1, 2]])>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建向量 b\n",
    "b = tf.constant([1,2]) \n",
    "# 插入新维度，变成矩阵\n",
    "b = tf.expand_dims(b, axis=0) \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [1, 2]])>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 样本维度上复制一份\n",
    "b = tf.tile(b, multiples=[2,1]) \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[0, 1],\n       [2, 3]])>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4)\n",
    "# 创建 2 行 2 列矩阵\n",
    "x=tf.reshape(x,[2,2]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\narray([[0, 1, 0, 1],\n       [2, 3, 2, 3]])>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列维度复制一份\n",
    "x = tf.tile(x,multiples=[1,2]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\narray([[0, 1, 0, 1],\n       [2, 3, 2, 3],\n       [0, 1, 0, 1],\n       [2, 3, 2, 3]])>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 行维度复制一份\n",
    "x = tf.tile(x,multiples=[2,1]) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 32, 32, 3), dtype=float32, numpy=\narray([[[[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        ...,\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]]],\n\n\n       [[[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        ...,\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]],\n\n        [[ 0.17321725,  0.17321725,  0.17321725],\n         [-0.3266918 , -0.3266918 , -0.3266918 ],\n         [ 1.0556936 ,  1.0556936 ,  1.0556936 ],\n         ...,\n         [-0.83202094, -0.83202094, -0.83202094],\n         [-0.02236545, -0.02236545, -0.02236545],\n         [-0.7924351 , -0.7924351 , -0.7924351 ]]]], dtype=float32)>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建矩阵\n",
    "A = tf.random.normal([32,1]) \n",
    "# 扩展为 4D 张量\n",
    "tf.broadcast_to(A, [2,32,32,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incompatible shapes: [32,2] vs. [2,32,32,4] [Op:BroadcastTo]\n"
     ]
    }
   ],
   "source": [
    "A = tf.random.normal([32,2])\n",
    "# 不符合 Broadcasting 条件\n",
    "try: \n",
    "    tf.broadcast_to(A, [2,32,32,4])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学运算\n",
    "\n",
    "### 加、减、乘、除运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 1, 1, 2])>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(5)\n",
    "b = tf.constant(2)\n",
    "# 整除运算\n",
    "a//b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 1, 0])>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 余除运算\n",
    "a%b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乘方运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 0,  1,  8, 27])>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4)\n",
    "# 乘方运算\n",
    "tf.pow(x,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 4, 9])>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乘方运算符\n",
    "x**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.constant([1.,4.,9.])\n",
    "# 平方根\n",
    "x**(0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(5)\n",
    "# 转换为浮点数\n",
    "x = tf.cast(x, dtype=tf.float32) \n",
    "# 平方\n",
    "x = tf.square(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 2., 3., 4.], dtype=float32)>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平方根\n",
    "tf.sqrt(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指数和对数运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 4., 8.], dtype=float32)>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1.,2.,3.])\n",
    "# 指数运算\n",
    "2**x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=2.7182817>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自然指数运算\n",
    "tf.exp(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.exp(3.)\n",
    "# 对数运算\n",
    "tf.math.log(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1.,2.])\n",
    "x = 10**x\n",
    "# 换底公式\n",
    "tf.math.log(x)/tf.math.log(10.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵相乘运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 3, 28, 2), dtype=float32, numpy=\narray([[[[-4.04387856e+00,  5.13451815e-01],\n         [-4.94071817e+00,  4.73533106e+00],\n         [ 1.91303825e+00,  9.13375854e-01],\n         [ 2.22107410e+00, -4.02837753e-01],\n         [-2.49344969e+00, -3.57752419e+00],\n         [ 4.20251942e+00, -4.13348103e+00],\n         [ 8.72489166e+00, -7.27686310e+00],\n         [ 3.56334257e+00,  4.88149452e+00],\n         [ 6.89522266e-01, -3.96528888e+00],\n         [-4.88785982e-01,  6.47102261e+00],\n         [ 6.83047485e+00, -2.74312592e+00],\n         [ 4.49336910e+00, -2.91878510e+00],\n         [-4.37245321e+00, -1.11508369e-01],\n         [ 4.67279196e-01, -5.81393099e+00],\n         [-1.28973889e+00,  8.30911446e+00],\n         [-8.27802086e+00,  3.41750860e+00],\n         [ 3.38563204e+00, -4.91175270e+00],\n         [-1.35039749e+01,  1.72515798e+00],\n         [-2.76733065e+00, -6.97514057e+00],\n         [ 2.36166596e+00,  7.25847769e+00],\n         [-8.33503962e-01, -2.81930780e+00],\n         [ 1.66659272e+00, -4.76162076e-01],\n         [ 9.59912491e+00,  4.42137861e+00],\n         [-3.70874763e+00,  5.53956509e+00],\n         [ 1.76969194e+00,  3.75838447e+00],\n         [ 3.26750422e+00, -5.07048607e+00],\n         [ 4.85738993e+00,  9.53873634e-01],\n         [-5.28052282e+00,  3.03185678e+00]],\n\n        [[ 3.04487944e-01, -4.99170303e-01],\n         [-8.11731815e-01,  8.69617701e-01],\n         [ 8.63440156e-01, -1.75732088e+00],\n         [ 2.27302265e+00,  5.93805981e+00],\n         [-4.99029303e+00, -6.16071320e+00],\n         [ 1.84543610e+00,  7.93663311e+00],\n         [-3.27709270e+00,  3.13991737e+00],\n         [ 2.24647522e-02, -2.63629198e+00],\n         [-5.97167492e+00, -5.91149998e+00],\n         [-3.23545694e+00,  6.48111296e+00],\n         [ 1.27647400e+00, -6.04140472e+00],\n         [-1.21787977e+00,  2.58918285e+00],\n         [-4.18403149e+00, -7.12159109e+00],\n         [-9.11504459e+00,  7.96617603e+00],\n         [-1.73986638e+00,  2.70868540e+00],\n         [ 3.01789403e+00, -7.81207085e-02],\n         [ 3.36590409e+00, -3.32725430e+00],\n         [-1.68641162e+00, -1.22091055e+00],\n         [ 4.02090931e+00,  1.23801792e+00],\n         [ 1.81803989e+00,  1.37583327e+00],\n         [ 5.37805367e+00, -9.26580715e+00],\n         [-1.59065723e+00,  5.57061911e+00],\n         [-3.49321103e+00, -3.82438850e+00],\n         [ 2.35918403e+00, -1.06033897e+01],\n         [-3.82673049e+00, -1.45548391e+00],\n         [ 7.34739017e+00, -1.87995434e+00],\n         [-4.96734762e+00, -1.69644666e+00],\n         [-2.85527182e+00, -6.78704739e-01]],\n\n        [[-1.30861616e+00, -6.33023262e+00],\n         [ 4.14226723e+00, -3.39995909e+00],\n         [ 2.42648125e+00, -1.85041428e+00],\n         [ 3.43068075e+00, -5.18662643e+00],\n         [ 4.84705830e+00, -2.76597428e+00],\n         [-2.43672085e+00, -3.75050569e+00],\n         [-5.23149824e+00, -3.59998083e+00],\n         [ 1.32574356e+00, -4.32739830e+00],\n         [ 2.94787383e+00, -2.70919800e-01],\n         [-4.29905033e+00,  4.15133572e+00],\n         [-1.21361303e+00,  2.31412268e+00],\n         [-2.37390804e+00, -4.43698168e+00],\n         [ 1.52704227e+00, -5.91217089e+00],\n         [-6.33505106e-01, -1.13706112e+00],\n         [ 9.16762829e-01,  6.97078848e+00],\n         [-7.38855171e+00,  3.12910080e+00],\n         [-1.21733356e+00,  3.80139089e+00],\n         [-2.64028549e+00,  6.32898951e+00],\n         [ 2.02720284e+00, -5.11188841e+00],\n         [-5.72081757e+00,  9.80063248e+00],\n         [-7.80526114e+00,  2.45133352e+00],\n         [ 9.87247849e+00, -3.64515638e+00],\n         [ 1.09451580e+00, -2.63513088e-01],\n         [-1.21843123e+00,  8.69084644e+00],\n         [ 1.43106651e+00,  2.25368595e+00],\n         [-6.57350421e-01,  4.57319736e+00],\n         [ 2.30911016e+00, -3.93412638e+00],\n         [ 2.89126587e+00, -1.15040493e+01]]],\n\n\n       [[[-8.54495525e+00, -4.49720430e+00],\n         [ 6.75844908e+00,  5.91382027e-01],\n         [-8.42395020e+00, -2.04857707e+00],\n         [ 3.68794870e+00, -3.86052012e+00],\n         [-3.77330732e+00, -7.23653889e+00],\n         [ 2.10531592e-01, -3.95984840e+00],\n         [-1.57188344e+00, -1.69319189e+00],\n         [ 1.53295553e+00,  1.14722729e+01],\n         [-3.58610773e+00, -4.30977345e-01],\n         [ 3.40359592e+00, -6.82607365e+00],\n         [-4.29722404e+00, -1.81162357e-02],\n         [-8.71027756e+00,  1.30316114e+00],\n         [-5.86597323e-01, -6.23854756e-01],\n         [ 4.58152175e-01,  4.09058142e+00],\n         [ 3.94702983e+00, -2.73850679e-01],\n         [-4.49771547e+00, -5.53815174e+00],\n         [-2.37757444e+00,  2.54296160e+00],\n         [ 2.41244340e+00,  2.90633869e+00],\n         [ 2.68352365e+00, -7.72255802e+00],\n         [-2.92961502e+00,  5.32139540e+00],\n         [-2.63580918e-01,  1.91175294e+00],\n         [ 1.05234280e+01,  3.24451876e+00],\n         [-3.38481903e-01,  7.74361229e+00],\n         [-1.35360479e+00,  1.19740844e+00],\n         [ 5.87315083e+00,  8.30952454e+00],\n         [-6.95476651e-01, -3.56708574e+00],\n         [-2.09292603e+00,  7.34518814e+00],\n         [ 4.54299116e+00,  8.71800327e+00]],\n\n        [[ 5.62642670e+00,  1.71723986e+00],\n         [ 1.12308848e+00, -5.95623779e+00],\n         [-2.14461422e+00,  2.09980917e+00],\n         [ 4.28174686e+00, -9.54771805e+00],\n         [-1.72475853e+01,  3.60149956e+00],\n         [-2.84256005e+00,  4.47913694e+00],\n         [ 4.47902536e+00, -3.98813748e+00],\n         [-2.56357408e+00,  5.59283209e+00],\n         [-2.28051805e+00,  3.41036582e+00],\n         [-5.72695732e+00, -4.18291569e+00],\n         [ 4.27657413e+00, -9.99418831e+00],\n         [ 3.46686172e+00, -2.36696506e+00],\n         [ 7.94326878e+00, -1.36717434e+01],\n         [ 1.83541155e+00,  1.55165732e+00],\n         [ 4.64391470e+00, -3.80418348e+00],\n         [-7.11464262e+00,  4.33459473e+00],\n         [-4.39248204e-01,  2.57537866e+00],\n         [-2.37243962e+00,  1.13516331e-01],\n         [-7.75464582e+00, -1.65520334e+00],\n         [-7.12861490e+00, -5.40127563e+00],\n         [ 3.64250064e-01, -1.06153965e+00],\n         [-1.23041000e+01,  2.87901068e+00],\n         [-6.42076206e+00,  7.30581617e+00],\n         [-6.11544418e+00,  2.23892212e+00],\n         [-2.04625797e+00, -4.18180037e+00],\n         [-3.99261427e+00, -6.90251541e+00],\n         [-6.16493583e-01,  2.86172032e-01],\n         [-6.20612621e+00,  3.64180565e-01]],\n\n        [[ 1.39687920e+00,  5.58712864e+00],\n         [ 1.12793455e+01, -1.05160351e+01],\n         [ 1.31545234e+00, -2.83481622e+00],\n         [-1.34849441e+00,  2.19231606e-01],\n         [-9.21713591e-01,  1.71769505e+01],\n         [-2.24816620e-01, -7.88941193e+00],\n         [-1.52683091e+00,  3.35468149e+00],\n         [ 6.94688034e+00, -2.66579437e+00],\n         [-5.95775509e+00,  2.33892846e+00],\n         [ 3.08085918e-01, -3.19428205e+00],\n         [-3.58217192e+00, -4.51761723e+00],\n         [-7.33243644e-01,  7.85564065e-01],\n         [ 4.96413589e-01, -6.31442022e+00],\n         [ 1.33388186e+00, -1.28960896e+01],\n         [ 9.82985497e-01, -1.39515162e+00],\n         [-3.80027056e+00,  7.75959682e+00],\n         [ 4.94930267e-01, -9.41547871e-01],\n         [-3.06387401e+00, -5.83236396e-01],\n         [ 5.41067028e+00,  3.26770830e+00],\n         [-7.75923538e+00,  8.62317467e+00],\n         [ 5.03044224e+00,  6.25242424e+00],\n         [ 7.96051025e-01, -1.36461031e+00],\n         [-8.06306648e+00,  3.24605465e-01],\n         [-5.12816811e+00,  9.86656570e+00],\n         [ 2.76141548e+00,  1.25360174e+01],\n         [-4.18441296e-02,  3.13487911e+00],\n         [-1.55822623e+00, -7.45898056e+00],\n         [ 2.85279131e+00, -1.81553924e+00]]],\n\n\n       [[[-4.36361909e-01, -5.27421427e+00],\n         [ 2.11814857e+00, -9.64101911e-01],\n         [-5.93743229e+00, -3.86066437e+00],\n         [-9.64613342e+00,  8.04307747e+00],\n         [-1.78310454e+00,  4.40984964e-03],\n         [ 3.27298164e+00, -8.50151348e+00],\n         [-4.50039148e+00, -6.53238821e+00],\n         [ 7.14957714e-02,  4.51705694e+00],\n         [-1.58188486e+00,  1.99646282e+00],\n         [ 8.06454849e+00, -6.58969498e+00],\n         [ 4.43359566e+00,  2.10669756e-01],\n         [ 1.06707108e+00, -8.24266911e-01],\n         [-1.50328302e+00,  8.52427959e+00],\n         [-2.76197076e+00,  4.26161337e+00],\n         [ 3.74563980e+00, -2.96759486e+00],\n         [ 6.83620453e-01,  6.38290167e-01],\n         [-8.96632671e-01, -9.05987263e-01],\n         [-9.89487410e-01, -6.14190149e+00],\n         [-1.13673604e+00,  6.60982084e+00],\n         [ 6.28127813e-01,  2.95476580e+00],\n         [ 1.59727311e+00, -5.32436848e+00],\n         [-1.55167222e+00,  7.34217072e+00],\n         [-7.45799541e+00,  2.12753677e+00],\n         [ 6.27231789e+00,  1.98110127e+00],\n         [ 1.04365385e+00,  2.07787931e-01],\n         [-3.16725206e+00,  4.94572353e+00],\n         [ 1.09649980e+00, -2.64534235e-01],\n         [-7.15868473e-02,  8.29725266e-01]],\n\n        [[ 6.61670446e+00,  4.42915964e+00],\n         [-5.11705685e+00, -4.32436132e+00],\n         [ 4.26223469e+00,  3.54519105e+00],\n         [-7.55771971e+00, -1.29443932e+01],\n         [-1.29341030e+01,  7.44838238e-01],\n         [ 1.80750358e+00, -6.07805729e-01],\n         [-3.12390733e+00,  4.88068247e+00],\n         [ 1.88125763e+01, -8.88199806e+00],\n         [ 2.03655624e+00, -1.48138103e+01],\n         [-2.73879075e+00,  2.47907567e+00],\n         [ 1.73080063e+00, -4.53311729e+00],\n         [ 4.31316566e+00, -2.07014084e-02],\n         [-3.78134894e+00, -5.76512814e+00],\n         [ 1.00846462e+01, -5.19180584e+00],\n         [-6.97886133e+00, -4.93643236e+00],\n         [ 6.33850288e+00,  1.22420788e-02],\n         [-5.78767395e+00,  5.11787510e+00],\n         [-7.44676924e+00, -5.18658733e+00],\n         [-1.32931113e-01, -6.23471355e+00],\n         [ 4.66688156e+00, -3.33917427e+00],\n         [ 2.55471849e+00,  8.61725807e+00],\n         [-6.73351765e+00, -4.14234352e+00],\n         [ 2.20019889e+00,  1.00862634e+00],\n         [ 2.00120735e+00, -9.71351624e+00],\n         [ 1.18229704e+01, -2.46497631e+00],\n         [-1.03944016e+00,  8.69159317e+00],\n         [ 7.17046881e+00,  6.33086300e+00],\n         [ 7.58946514e+00,  5.60159349e+00]],\n\n        [[ 6.55456305e-01,  1.09134321e+01],\n         [-2.65547252e+00, -4.51535511e+00],\n         [-9.24775124e+00, -8.20732117e-01],\n         [-3.42908454e+00, -1.22947464e+01],\n         [ 9.53163338e+00, -3.50970125e+00],\n         [-1.88620496e+00,  1.79108238e+00],\n         [-9.38612270e+00,  1.13733852e+00],\n         [ 7.43651009e+00, -2.33816051e+00],\n         [ 3.06505775e+00,  6.97089529e+00],\n         [-5.14645004e+00, -6.75225735e+00],\n         [-1.53563547e+00, -1.40829802e+00],\n         [-4.75672150e+00, -1.81127846e+00],\n         [-6.70065022e+00,  1.51589656e+00],\n         [ 4.56133270e+00, -3.95162582e-01],\n         [ 5.27446508e-01, -8.39758873e+00],\n         [-1.10964608e+00,  1.27233660e+00],\n         [-2.89699936e+00,  1.62423587e+00],\n         [ 4.59035492e+00,  4.51498508e+00],\n         [-2.18657446e+00, -4.59474039e+00],\n         [ 5.32468224e+00,  1.78094709e+00],\n         [-5.73142433e+00, -1.11619005e+01],\n         [-4.73516750e+00, -2.44692755e+00],\n         [-3.99778628e+00,  3.24729395e+00],\n         [ 1.92566991e+00, -5.79969025e+00],\n         [ 1.39285755e+00,  1.39845848e-01],\n         [-3.74936914e+00, -7.72212076e+00],\n         [-1.67082369e+00,  2.21262527e+00],\n         [ 2.54406595e+00, -1.65794253e+00]]],\n\n\n       [[[-4.34210300e+00, -2.81554031e+00],\n         [-3.26115155e+00, -9.81897831e-01],\n         [-7.27629709e+00, -6.51828098e+00],\n         [-2.33692169e+00, -6.77544546e+00],\n         [ 2.23866153e+00,  1.79744840e+00],\n         [ 5.97118759e+00,  4.68740463e-01],\n         [-7.37640500e-01,  2.99918771e+00],\n         [-1.21299028e+01, -3.33169508e+00],\n         [-6.60903502e+00, -2.53665638e+00],\n         [ 3.47376609e+00, -5.72743273e+00],\n         [-1.61896658e+00, -6.61942625e+00],\n         [-1.08407860e+01, -8.16231728e+00],\n         [ 3.60031056e+00, -2.13287449e+00],\n         [-4.61802483e-02,  2.67508602e+00],\n         [ 4.86271000e+00, -1.55161631e+00],\n         [-3.39781332e+00, -5.16101074e+00],\n         [ 3.96194148e+00, -2.20678091e-01],\n         [-1.53543353e+00,  1.40691507e+00],\n         [ 5.61933804e+00,  1.53406143e+01],\n         [-2.17727375e+00,  6.09265327e-01],\n         [ 2.70372629e+00,  4.61025381e+00],\n         [-3.08060741e+00, -1.45940328e+00],\n         [ 6.07568407e+00, -1.13852272e+01],\n         [-4.41191292e+00, -2.52972126e+00],\n         [ 2.33340621e+00, -7.02021599e-01],\n         [ 1.09250009e+00, -5.29923725e+00],\n         [-5.84676981e-01,  1.89283371e-01],\n         [ 8.64498234e+00,  7.64597893e+00]],\n\n        [[ 1.71450531e+00, -1.36975884e+00],\n         [ 2.19052005e+00,  4.47556782e+00],\n         [ 7.83602524e+00, -8.42295051e-01],\n         [ 4.48728943e+00,  5.48207569e+00],\n         [ 2.03770041e-01, -6.72411728e+00],\n         [ 2.58394957e+00,  6.22461033e+00],\n         [-1.82045925e+00,  2.52381659e+00],\n         [-3.09340453e+00,  2.61574888e+00],\n         [-6.26279449e+00, -2.44862390e+00],\n         [ 1.83723593e+00, -1.19021988e+00],\n         [-5.29531097e+00, -1.30810583e+00],\n         [ 1.68721437e+00,  4.99863672e+00],\n         [-9.92562056e-01,  1.21750841e+01],\n         [-6.11475229e+00,  4.67864990e+00],\n         [-5.39552689e+00,  6.20371914e+00],\n         [ 2.72979975e-01,  5.31609392e+00],\n         [-1.10147572e+00, -9.36960936e-01],\n         [ 1.05388145e+01, -9.35753059e+00],\n         [-1.24253702e+01,  3.69659328e+00],\n         [ 4.64233208e+00, -2.17119718e+00],\n         [ 6.00245237e+00,  5.08244276e-01],\n         [-3.64880586e+00, -8.82715797e+00],\n         [-5.07330322e+00,  9.25100565e-01],\n         [ 5.56771803e+00, -7.09551477e+00],\n         [-6.22319889e+00,  6.60080051e+00],\n         [ 7.71190071e+00, -1.19158297e+01],\n         [ 5.50230646e+00,  4.67992115e+00],\n         [ 9.19815779e-01,  3.39168549e+00]],\n\n        [[ 1.32412195e+01, -5.03345680e+00],\n         [-4.04906154e-01, -1.49086511e+00],\n         [ 9.31979537e-01, -1.46466913e+01],\n         [-2.88641286e+00, -6.63244009e+00],\n         [-4.72589064e+00,  3.85559750e+00],\n         [-9.17259026e+00, -1.22915516e+01],\n         [-1.77034605e+00,  5.23335934e-01],\n         [ 3.10577393e+00,  7.30658960e+00],\n         [ 8.80548000e-01,  3.52518010e+00],\n         [-5.73248565e-01, -9.39679718e+00],\n         [-1.01846285e+01,  7.28635883e+00],\n         [-1.29067492e+00,  4.40482521e+00],\n         [ 3.18010163e+00, -1.42116380e+00],\n         [ 3.97368741e+00,  1.16389542e+01],\n         [-6.11618137e+00,  4.95076036e+00],\n         [ 5.21603012e+00, -1.33289146e+01],\n         [ 1.72305036e+00,  5.72046757e+00],\n         [-8.94002819e+00,  6.04055929e+00],\n         [-6.78044319e-01, -3.40024900e+00],\n         [ 9.60593128e+00,  1.09602184e+01],\n         [-4.79385519e+00,  5.79201126e+00],\n         [ 5.86271584e-01,  4.72515917e+00],\n         [ 6.84929276e+00,  4.51961136e+00],\n         [-6.37870979e+00, -6.79275751e-01],\n         [ 2.97567225e+00, -5.28557491e+00],\n         [-4.40177202e-01,  3.85327816e+00],\n         [-6.72872496e+00,  4.09484816e+00],\n         [ 3.90386128e+00, -2.64853621e+00]]]], dtype=float32)>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4,3,28,32])\n",
    "b = tf.random.normal([4,3,32,2])\n",
    "# 批量形式的矩阵相乘\n",
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 28, 16), dtype=float32, numpy=\narray([[[ -1.5152458 ,   6.416539  ,  10.756416  , ...,  -3.2177622 ,\n          -4.5234585 ,  -5.7450924 ],\n        [  2.1893308 ,  -7.4541764 ,  -6.263012  , ...,   4.6722593 ,\n           3.1586232 ,  -6.90464   ],\n        [ -4.164972  ,  -0.7755656 ,   3.438631  , ...,  -4.2899127 ,\n          -6.1842113 ,  -6.5201364 ],\n        ...,\n        [  2.9320357 ,  -4.148237  ,   9.926765  , ...,  10.574377  ,\n           5.319163  ,  -2.383402  ],\n        [ -9.30278   ,   1.8573854 ,  -1.2164695 , ...,  -5.2967315 ,\n          -0.36509833,  -8.8077345 ],\n        [ -3.9653437 ,  -9.201802  ,  -0.81898606, ...,   0.767244  ,\n           6.1182785 ,  -2.5330038 ]],\n\n       [[  2.9173808 ,   5.3636684 ,   0.5620442 , ...,  -6.400789  ,\n          -2.383534  ,  -8.20743   ],\n        [ -5.274174  ,   0.14990366,  -0.78210735, ...,  18.354446  ,\n           0.7680195 ,  -0.57744384],\n        [ -1.8672019 ,  -4.2073665 ,  -4.777067  , ...,  -4.1244054 ,\n          -4.3730664 ,   0.21627831],\n        ...,\n        [  0.28267828,   2.5403082 ,  -3.2698524 , ...,  -5.2621617 ,\n           4.1437674 ,   0.2801836 ],\n        [  1.2344459 , -11.419597  ,  -6.879303  , ...,   6.7853923 ,\n          -0.3892987 ,   6.767795  ],\n        [ 12.980536  ,   2.2749681 ,   6.1582017 , ...,  -0.99436146,\n           7.6715965 ,  -2.2820952 ]],\n\n       [[ -5.901935  ,  -7.419619  ,   2.7433274 , ...,   8.435689  ,\n           6.8190613 ,  -1.7533374 ],\n        [ -5.9056215 ,  -2.926565  ,  -6.7716756 , ...,   7.127755  ,\n          -0.6810866 ,   2.5278032 ],\n        [-11.509109  ,   2.1132789 ,   0.91574234, ...,  -5.3399315 ,\n          -7.8832865 ,  -4.214776  ],\n        ...,\n        [ -2.854027  ,   4.492119  ,   3.3031607 , ...,  -5.116609  ,\n         -16.369007  ,   8.589495  ],\n        [  8.217799  ,  -9.345354  ,   2.957765  , ...,  -3.1335895 ,\n           5.3670163 ,   7.139458  ],\n        [ -5.8636417 ,  -2.3021886 ,  -4.355242  , ...,  -8.243745  ,\n           0.17839813,   3.9068737 ]],\n\n       [[ 12.984095  , -10.365837  ,  -5.733601  , ...,  -2.3472476 ,\n          -5.229038  ,   6.393908  ],\n        [  5.5472093 ,   2.645259  ,   3.4479825 , ...,   2.717932  ,\n           2.3611276 ,   0.599488  ],\n        [  3.7891686 ,   1.871851  ,  -9.970615  , ...,   1.4307082 ,\n          -9.407198  ,  10.447187  ],\n        ...,\n        [-11.620679  ,  13.755378  ,   0.79711795, ...,   0.6385014 ,\n          -4.221307  ,   1.4549854 ],\n        [ 13.174004  ,   6.5813336 ,   1.8411744 , ...,   3.194919  ,\n          -1.3813301 ,  -0.401575  ],\n        [  1.8665683 ,   6.0960627 ,  -3.0250769 , ...,  -4.029465  ,\n          10.348285  ,  -5.406391  ]]], dtype=float32)>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4,28,32])\n",
    "b = tf.random.normal([32,16])\n",
    "# 先自动扩展，再矩阵相乘\n",
    "tf.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向传播实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as datasets\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['font.family'] = ['STKaiti']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # 加载 MNIST 数据集\n",
    "    (x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "    # 转换为浮点张量， 并缩放到-1~1\n",
    "    x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "    # 转换为整形张量\n",
    "    y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "    # one-hot 编码\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "\n",
    "    # 改变视图， [b, 28, 28] => [b, 28*28]\n",
    "    x = tf.reshape(x, (-1, 28 * 28))\n",
    "\n",
    "    # 构建数据集对象\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    # 批量训练\n",
    "    train_dataset = train_dataset.batch(200)\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_paramaters():\n",
    "    # 每层的张量都需要被优化，故使用 Variable 类型，并使用截断的正太分布初始化权值张量\n",
    "    # 偏置向量初始化为 0 即可\n",
    "    # 第一层的参数\n",
    "    w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    # 第二层的参数\n",
    "    w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    # 第三层的参数\n",
    "    w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    return w1, b1, w2, b2, w3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001):\n",
    "    for step, (x, y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 第一层计算， [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b,256] + [b, 256]\n",
    "            h1 = x @ w1 + tf.broadcast_to(b1, (x.shape[0], 256))\n",
    "            h1 = tf.nn.relu(h1)  # 通过激活函数\n",
    "\n",
    "            # 第二层计算， [b, 256] => [b, 128]\n",
    "            h2 = h1 @ w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # 输出层计算， [b, 128] => [b, 10]\n",
    "            out = h2 @ w3 + b3\n",
    "\n",
    "            # 计算网络输出与标签之间的均方差， mse = mean(sum(y-out)^2)\n",
    "            # [b, 10]\n",
    "            loss = tf.square(y - out)\n",
    "            # 误差标量， mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "            # 自动梯度，需要求梯度的张量有[w1, b1, w2, b2, w3, b3]\n",
    "            grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "\n",
    "        # 梯度更新， assign_sub 将当前值减去参数值，原地更新\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])    \n",
    "    \n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    losses = []\n",
    "    train_dataset = load_data()\n",
    "    w1, b1, w2, b2, w3, b3 = init_paramaters()\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001)\n",
    "        print('epoch:', epoch, 'loss:', loss)\n",
    "        losses.append(loss)\n",
    "\n",
    "    x = [i for i in range(0, epochs)]\n",
    "    # 绘制曲线\n",
    "    plt.plot(x, losses, color='blue', marker='s', label='训练')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.1729061\n",
      "epoch: 1 loss: 0.15295327\n",
      "epoch: 2 loss: 0.13959596\n",
      "epoch: 3 loss: 0.12936044\n",
      "epoch: 4 loss: 0.12125424\n",
      "epoch: 5 loss: 0.11465827\n",
      "epoch: 6 loss: 0.1091523\n",
      "epoch: 7 loss: 0.104499325\n",
      "epoch: 8 loss: 0.100515746\n",
      "epoch: 9 loss: 0.09705984\n",
      "epoch: 10 loss: 0.09403569\n",
      "epoch: 11 loss: 0.091375075\n",
      "epoch: 12 loss: 0.08899269\n",
      "epoch: 13 loss: 0.08684196\n",
      "epoch: 14 loss: 0.084888175\n",
      "epoch: 15 loss: 0.08311877\n",
      "epoch: 16 loss: 0.08149795\n",
      "epoch: 17 loss: 0.08000113\n",
      "epoch: 18 loss: 0.07861913\n",
      "epoch: 19 loss: 0.077341385\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}