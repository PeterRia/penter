{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "https://pandas.pydata.org/docs/user_guide/io.html\n",
    "\n",
    "pandas I / O API是一组顶级读取器函数，如pandas.read_csv（）一样访问，这些函数通常返回pandas对象。\n",
    "相应的编写器函数是对象方法，可以像DataFrame.to_csv（）一样进行访问。\n",
    "\n",
    "pandas能读取的数据来源非常丰富，请参见上述地址\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "(  col1 col2  col3\n 0    a    b     1\n 1    a    b     2\n 2    c    d     3,\n   col1  col3\n 0    a     1\n 1    a     2\n 2    c     3)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  %%time # %%time 将会给出cell的代码运行一次所花费的时间。\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO\n",
    "data = ('col1,col2,col3\\n'\n",
    "        'a,b,1\\n'\n",
    "        'a,b,2\\n'\n",
    "        'c,d,3')\n",
    "# %time 将会给出当前行的代码运行一次所花费的时间。\n",
    "# %timeit 使用Python的timeit模块，它将会执行一个语句100，000次(默认情况下)，然后给出运行最快3次的平均值。\n",
    "%time pd.read_csv(StringIO(data)),\\\n",
    "    pd.read_csv(StringIO(data), usecols=lambda x: x.upper() in ['COL1', 'COL3'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(   a   b   c    d\n 0  1   2   3    4\n 1  5   6   7    8\n 2  9  10  11  NaN,\n    a   b     c     d\n 0  1   2   3.0     4\n 1  5   6   7.0     8\n 2  9  10  11.0  <NA>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ('a,b,c,d\\n'\n",
    "        '1,2,3,4\\n'\n",
    "        '5,6,7,8\\n'\n",
    "        '9,10,11')\n",
    "df1 = pd.read_csv(StringIO(data), dtype=object)\n",
    "\n",
    "df2 = pd.read_csv(StringIO(data),dtype={'b': object, 'c': np.float64, 'd': 'Int64'})\n",
    "df1,df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 介绍下pandas SQL querie\n",
    "pandas.io.sql模块提供了查询包装的集合，以促进数据检索并减少对特定于数据库的API的依赖性。\n",
    "如果安装了SQLAlchemy，则提供数据库抽象。 另外，您将需要数据库的驱动程序库。\n",
    "此类驱动程序的示例是用于PostgreSQL的[psycopg2](http://initd.org/psycopg/)或用于MySQL的[pymysql](https://github.com/PyMySQL/PyMySQL)。\n",
    "对于[SQLite](https://docs.python.org/3/library/sqlite3.html)，默认情况下，它包含在Python的标准库中。\n",
    "您可以在[SQLAlchemy文档](https://docs.sqlalchemy.org/en/latest/dialects/index.html)中找到每种SQL方言支持的驱动程序的概述。\n",
    "\n",
    "[ Python DB-API](https://www.python.org/dev/peps/pep-0249/)\n",
    "\n",
    "```\n",
    "read_sql_table(table_name, con[, schema, …])  Read SQL database table into a DataFrame.\n",
    "\n",
    "read_sql_query(sql, con[, index_col, …])      Read SQL query into a DataFrame.\n",
    "\n",
    "read_sql(sql, con[, index_col, …])              Read SQL query or database table into a DataFrame.\n",
    "\n",
    "DataFrame.to_sql(self, name, con[, schema, …])  Write records stored in a DataFrame to a SQL database.\n",
    "```\n",
    "\n",
    "要与SQLAlchemy连接，请使用create_engine（）函数从数据库URI创建引擎对象。\n",
    "您只需为要连接的每个数据库创建一次引擎。\n",
    "有关create_engine（）和URI格式的更多信息，请参见下面的示例和[SQLAlchemy文档](https://docs.sqlalchemy.org/en/latest/core/engines.html)\n",
    "\n",
    "```\n",
    "# dialect+driver://username:password@host:port/database\n",
    "\n",
    "更多\n",
    "https://docs.sqlalchemy.org/en/13/dialects/index.html\n",
    "\n",
    "# sqlite://<nohostname>/<path>\n",
    "# where <path> is relative:\n",
    "engine = create_engine('sqlite:///foo.db')\n",
    "# Unix/Mac - 4 initial slashes in total\n",
    "engine = create_engine('sqlite:////absolute/path/to/foo.db')\n",
    "\n",
    "# Windows\n",
    "engine = create_engine('sqlite:///C:\\\\path\\\\to\\\\foo.db')\n",
    "\n",
    "# Windows alternative using raw string\n",
    "engine = create_engine(r'sqlite:///C:\\path\\to\\foo.db')\n",
    "To use a SQLite :memory: database, specify an empty URL:\n",
    "engine = create_engine('sqlite://')\n",
    "\n",
    "\n",
    "# default\n",
    "engine = create_engine('postgresql://scott:tiger@localhost/mydatabase')\n",
    "# psycopg2\n",
    "engine = create_engine('postgresql+psycopg2://scott:tiger@localhost/mydatabase')\n",
    "# pg8000\n",
    "engine = create_engine('postgresql+pg8000://scott:tiger@localhost/mydatabase')\n",
    "\n",
    "# default\n",
    "engine = create_engine('mysql://scott:tiger@localhost/foo')\n",
    "# mysqlclient (a maintained fork of MySQL-Python)\n",
    "engine = create_engine('mysql+mysqldb://scott:tiger@localhost/foo')\n",
    "# PyMySQL\n",
    "engine = create_engine('mysql+pymysql://scott:tiger@localhost/foo')\n",
    "\n",
    "\n",
    "engine = create_engine('oracle://scott:tiger@127.0.0.1:1521/sidname')\n",
    "engine = create_engine('oracle+cx_oracle://scott:tiger@tnsname')\n",
    "\n",
    "# pyodbc\n",
    "engine = create_engine('mssql+pyodbc://scott:tiger@mydsn')\n",
    "# pymssql\n",
    "engine = create_engine('mssql+pymssql://scott:tiger@hostname:port/dbname')\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  a   b   c     d\n",
      "0      0  1   2   3     4\n",
      "1      1  5   6   7     8\n",
      "2      2  9  10  11  None\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "\n",
    "\n",
    "data = ('a,b,c,d\\n'\n",
    "        '1,2,3,4\\n'\n",
    "        '5,6,7,8\\n'\n",
    "        '9,10,11')\n",
    "df1 = pd.read_csv(StringIO(data), dtype=object)\n",
    "df1.to_sql('table1', engine)\n",
    "# , chunksize=1000 批量一次1000条数据\n",
    "# , dtype={'Col_1': String} 指定字段类型\n",
    "with engine.connect() as conn, conn.begin():\n",
    "    data = pd.read_sql_table('table1', conn)\n",
    "    print(data)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c     d\n",
      "0   3     4\n",
      "1   7     8\n",
      "2  11  None\n",
      "       a   b   c     d\n",
      "index                 \n",
      "0      1   2   3     4\n",
      "1      5   6   7     8\n",
      "2      9  10  11  None\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\npd.read_sql_table('data', engine, parse_dates={'Date': '%Y-%m-%d'})\\npd.read_sql_table('data', engine,\\n                  parse_dates={'Date': {'format': '%Y-%m-%d %H:%M:%S'}})\\n\\ndf.to_sql('table', engine, schema='other_schema')\\npd.read_sql_table('table', engine, schema='other_schema')\\n\\n\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.read_sql_table('table1', engine, columns=['c', 'd']))\n",
    "\n",
    "print(pd.read_sql_table('table1', engine, index_col='index'))\n",
    "\n",
    "\"\"\"\n",
    "pd.read_sql_table('data', engine, parse_dates={'Date': '%Y-%m-%d'})\n",
    "pd.read_sql_table('data', engine,\n",
    "                  parse_dates={'Date': {'format': '%Y-%m-%d %H:%M:%S'}})\n",
    "\n",
    "df.to_sql('table', engine, schema='other_schema')\n",
    "pd.read_sql_table('table', engine, schema='other_schema')\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\npd.read_sql_query(\"SELECT id, Col_1, Col_2 FROM data WHERE id = 42;\", engine)\\n'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('SELECT * FROM table1', engine)\n",
    "\"\"\"\n",
    "pd.read_sql_query(\"SELECT id, Col_1, Col_2 FROM data WHERE id = 42;\", engine)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b         c\n",
      "0  1.125272 -0.188451 -0.755178\n",
      "1 -2.311971  0.839500  0.669326\n",
      "2  0.984494  1.775829 -0.270684\n",
      "3 -0.432524  0.775081  0.552522\n",
      "4  1.205757  0.573801 -1.521674\n",
      "          a         b         c\n",
      "0 -0.524590 -0.187393 -0.688880\n",
      "1  0.533987  0.580544  0.543838\n",
      "2 -0.333328 -0.127018  0.614370\n",
      "3  0.873983  1.037206  0.290153\n",
      "4 -0.017883 -0.756667  0.258249\n",
      "          a         b         c\n",
      "0 -1.389420  1.111020  0.322583\n",
      "1  0.324308  0.600641  0.720963\n",
      "2 -0.584621 -1.613667  1.176166\n",
      "3 -0.711260 -0.618531 -0.086868\n",
      "4 -2.145058 -0.537651 -0.771267\n",
      "          a         b         c\n",
      "0  0.203181 -0.504853  0.811791\n",
      "1  2.202667 -1.423331 -1.529771\n",
      "2 -0.091568 -0.225243 -0.192290\n",
      "3  0.193669 -1.029652 -0.024456\n",
      "4  0.627670  0.520279 -0.632384\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(20, 3), columns=list('abc'))\n",
    "df.to_sql('data_chunks', engine, index=False)\n",
    "\"\"\"\n",
    " chunksize : int, default None\n",
    "        If specified, return an iterator where `chunksize` is the number of\n",
    "        rows to include in each chunk.\n",
    "\"\"\"\n",
    "for chunk in pd.read_sql_query(\"SELECT * FROM data_chunks\",engine, chunksize=5):\n",
    "        print(chunk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.result.ResultProxy at 0x1d8ecf51ec8>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.io import sql\n",
    "\n",
    "sql.execute('INSERT INTO data_chunks VALUES(?, ?, ?)', engine,\n",
    "            params=[(1, 12.2, 2)])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1252723159966966, -0.18845098012272612, -0.7551782053106644)\n",
      "(-2.3119707623159154, 0.8395000345026027, 0.669326353008125)\n",
      "(0.9844936604106937, 1.7758289250221637, -0.27068424341546804)\n",
      "(-0.4325237858789535, 0.775081270459533, 0.5525219070984076)\n",
      "(1.2057567671919194, 0.5738007195833363, -1.5216741247426415)\n",
      "(-0.5245897623287465, -0.18739313930062676, -0.688880228942171)\n",
      "(0.5339874336781417, 0.580543808136233, 0.5438381482228221)\n",
      "(-0.3333275866425767, -0.12701815584463474, 0.6143702582248568)\n",
      "(0.8739827231918734, 1.0372064343112035, 0.2901527487197623)\n",
      "(-0.017883337267388107, -0.7566666593273992, 0.2582486891718538)\n",
      "(-1.3894195063933414, 1.1110201665789332, 0.3225831061030947)\n",
      "(0.3243083503841419, 0.6006414697388488, 0.720962684202747)\n",
      "(-0.5846212009089183, -1.6136669555660963, 1.1761661009394901)\n",
      "(-0.7112598568186012, -0.6185306480649218, -0.08686755310385563)\n",
      "(-2.1450578804409948, -0.5376510145964956, -0.7712672804441887)\n",
      "(0.20318104595734687, -0.5048529268828995, 0.8117907931358713)\n",
      "(2.202667312196563, -1.4233313038631605, -1.5297710054123694)\n",
      "(-0.09156826734959407, -0.22524261162883746, -0.19228981513401827)\n",
      "(0.19366880619138355, -1.0296518420154823, -0.024456125435513152)\n",
      "(0.6276697584879694, 0.5202792652576719, -0.6323844595847712)\n",
      "(1.0, 12.2, 2.0)\n"
     ]
    }
   ],
   "source": [
    "for chunk in sql.execute('SELECT * FROM data_chunks', engine):\n",
    "        print(chunk)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}